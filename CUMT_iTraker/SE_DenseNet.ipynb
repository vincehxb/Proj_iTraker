{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017年11月21日20:07:05\n",
    "# 利用DenseNet+Squeeze-and-Excitation Networks 结构改进原CNN网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from cumt_variant import densenet\n",
    "sess=tf.InteractiveSession()\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**修改DenseNet参数，希望能够减小参数，希望能用1k的数据集训练出一个ACC接近1的网络**\n",
    "* CUMT_ori: 4.25 million,  acc=0.85\n",
    "* DenseNet_ori:  k=12,  L=5,  dense block=4,  theta=0.5   ->  0.197 million,  acc=0.95\n",
    "* 1: k=8 ,L=4 ,dense block=3,theta=0.3,reg=4e-4,drop out=0.5,data size =2048   ->0.042 million,acc=0.95  \n",
    "改变conv block的顺序，由 conv-bn-relu 变成 bn-relu-conv,在tail的最后两个conv层加drop out\n",
    "* 2: k=8 ,L=4 ,dense block=3,theta=0.3,reg=4e-4,all layer drop out=0.5,data size =1024   ->0.042 million,acc=0.95  \n",
    "改变conv block的顺序，由 conv-bn-relu 变成 bn-relu-conv,所有bottle neck layer 加上drop out\n",
    "* 3: k=12 ,L=12 ,dense block=4,theta=0.5,data size =1024   ->0.728 million,acc=0.978  \n",
    "conv block的顺序任然为conv-bn-relu，去除所有dropout和正则\n",
    "* 4: k=12 ,L=20 ,dense block=4,theta=0.5,data size =1024   ->1.704 million,acc=0.985  \n",
    "conv block的顺序任然为conv-bn-relu，去除所有dropout和正则  \n",
    "权值文件路径为 'densenet_dump/bigmodel_acc985.pkl',模型文件在 ‘model_save/DenseNet/big_model_on_cumt_acc985-10085’  \n",
    "  \n",
    "**减小深度，生长率，希望降低参数值**\n",
    "* 5: k=3 ,L=3 ,dense block=3,theta=0.5,data size =1024   ->0.0052 million,acc=0.63  \n",
    "* 6: k=3 ,L=20,dense block=4,theta=0.1,data size =1024   ->0.064 million,acc=0.8 \n",
    "* 7: k=2 ,L=2,dense block=4,theta=0.8,data size =all   ->0.00263 million,acc=1.0  \n",
    "  **只用了差不多10KB大小的参数，完成了CUMT的分类任务**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*总结：*\n",
    "* *减少L,theta对准确率的影响最小，但是减少的参数也少*\n",
    "* *减小K,dense block数量能大量的减小参数，但是同时也会比较大程度的影响ACC*\n",
    "* *增加正则和drop out能稍微增加一点准确率，但不是关键的因素*\n",
    "* *从V6可以看到，对于参数很少的网络，即使网络很深，其效果也不理想。猜测是因为若将所有W看做一个解  \n",
    "  空间，更多的参数意味着更高的维度。而在这个高维空间中更容易找点局部极点或者是全局最优点。*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building DenseNet....\n",
      "(?, 64, 64, 24)\n",
      "(?, 64, 64, 264)\n",
      "(?, 32, 32, 132)\n",
      "(?, 32, 32, 372)\n",
      "(?, 16, 16, 186)\n",
      "(?, 16, 16, 426)\n",
      "(?, 8, 8, 213)\n",
      "(?, 8, 8, 453)\n",
      "(?, 4, 4, 226)\n"
     ]
    }
   ],
   "source": [
    "log_name='cumt_small/densenet_v0'\n",
    "with tf.variable_scope('Placehloder'):\n",
    "    X=tf.placeholder(dtype=tf.float32,shape=[None,128,128,3],name='X')\n",
    "    Y=tf.placeholder(dtype=tf.float32,shape=[None,10],name='Y')\n",
    "    bn_train=tf.placeholder(dtype=tf.bool,name='BN_FLAG')\n",
    "    LR=tf.placeholder(dtype=tf.float32,name='lr')\n",
    "#     DROPOUT=tf.placeholder(dtype=tf.float32,name='DROPOUT')\n",
    "with tf.name_scope('DenseNet'):\n",
    "    model=densenet(K=12,L=20,theta=0.5,denseblock_num=4,output_class=10,\\\n",
    "                   sess=sess,Images=X,bn_istraining=bn_train)\n",
    "    y_score=model.y_score\n",
    "with tf.name_scope('LOSS'):\n",
    "    LOSS=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_score,labels=Y))#+4e-4*(model.get_l2loss())\n",
    "    tf.summary.scalar('loss',LOSS)\n",
    "with tf.name_scope('TRAIN'):\n",
    "    TRAIN=tf.train.AdamOptimizer(LR).minimize(LOSS)\n",
    "with tf.name_scope('ACCURACY'):\n",
    "    acc_count=tf.equal(tf.arg_max(y_score,1),tf.arg_max(Y,1))\n",
    "    ACCURACY=tf.reduce_mean(tf.cast(acc_count,tf.float32))\n",
    "    tf.summary.scalar('acc',ACCURACY)\n",
    "bn_ops=tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "writer_te=tf.summary.FileWriter(r'./mylog/'+log_name+r'/test')\n",
    "writer_tr=tf.summary.FileWriter(r'./mylog/'+log_name+r'/train')\n",
    "writer_val=tf.summary.FileWriter(r'./mylog/'+log_name+r'/val')\n",
    "merge=tf.summary.merge_all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training params: 1.70442 Million,6.50185 Mb\n"
     ]
    }
   ],
   "source": [
    "model.count_trainable_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n"
     ]
    }
   ],
   "source": [
    "#cumt rgb 相片均值\n",
    "cumt_picmean=[103.939, 116.779, 123.68]\n",
    "cumt_data=np.load('cumt_data.pkl')\n",
    "index=np.arange(cumt_data['data'].shape[0])\n",
    "np.random.shuffle(index)\n",
    "data=cumt_data['data'][index]\n",
    "label=cumt_data['labels'][index]\n",
    "del cumt_data\n",
    "resize_img=[]\n",
    "for i in range(data.shape[0]):\n",
    "    img=data[i]+cumt_picmean\n",
    "    img=cv2.resize(img.astype('uint8'),(128,128))\n",
    "    resize_img.append(img.astype('uint8'))\n",
    "    if i%10000==0:\n",
    "        print (i)\n",
    "data=None\n",
    "resize_img=np.array(resize_img).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67346, 128, 128, 3) (7483, 128, 128, 3)\n",
      "(966, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "data_size=1024*1\n",
    "\n",
    "data=resize_img\n",
    "\n",
    "index=np.arange(data.shape[0])\n",
    "np.random.shuffle(index)\n",
    "# tr_index=index[:data_size]\n",
    "# te_index=index[data_size:]\n",
    "tr_index=index[:int(data.shape[0]*0.9)]\n",
    "te_index=index[int(data.shape[0]*0.9):]\n",
    "tr_data,tr_label=data[tr_index],label[tr_index]\n",
    "te_data,te_label=data[te_index],label[te_index]\n",
    "del data\n",
    "del label\n",
    "del resize_img\n",
    "print(tr_data.shape,te_data.shape)\n",
    "\n",
    "\n",
    "val_d=np.load('valimg1k_1109.pkl')\n",
    "val_data=[]\n",
    "for v in range(val_d['data'].shape[0]):\n",
    "    img_=cv2.resize(val_d['data'][v],(128,128))\n",
    "    \n",
    "    val_data.append(img_)\n",
    "val_data=np.array(val_data)\n",
    "val_label=val_d['label']\n",
    "del val_d\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saver=tf.train.Saver()\n",
    "# saver.restore(sess,r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\Proj_iTraker\\CUMT_iTraker\\model_save\\DenseNet\\big_model_on_cumt_acc985-10085')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "# saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#开始正式训练\n",
    "batchsize=128\n",
    "best_acc=0\n",
    "lr_=1e-4\n",
    "dp_=1.\n",
    "test_acc_his=[]\n",
    "best_test=0\n",
    "for i in range(32180,1000*6*12*1000):\n",
    "    mask=np.random.choice(tr_data.shape[0],batchsize,replace=False)\n",
    "    x_,y_=tr_data[mask]-cumt_picmean,tr_label[mask]\n",
    "    feed_dict={X:x_,Y:y_,bn_train:True,LR:lr_}\n",
    "    sess.run([TRAIN,bn_ops],feed_dict=feed_dict)\n",
    "    if i%10==0:\n",
    "        feed_dict={X:x_,Y:y_,bn_train:False}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_tr.add_summary(m_,i)\n",
    "        print('epoch:{},train loss:{:.4f},train accuracy:{:.4f}'.format(i,loss_,acc_))\n",
    "    if i%20==0:\n",
    "        mask=np.random.choice(te_data.shape[0],128,replace=False)\n",
    "        x_,y_=te_data[mask]-cumt_picmean,te_label[mask]\n",
    "        feed_dict={X:x_,Y:y_,bn_train:False}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        test_acc_his.append(acc_)\n",
    "        mean_acc=np.mean(test_acc_his[-20:])\n",
    "        best_test=max(best_test,mean_acc)\n",
    "        writer_te.add_summary(m_,i)\n",
    "        \n",
    "        print('--epoch:{},test loss:{:.4f},test accuracy:{:.4f},mean acc:{:.4f},best test acc:{:.4f}'\\\n",
    "              .format(i,loss_,acc_,mean_acc,best_test))\n",
    "    if i%30==0:\n",
    "        mask=np.random.choice(val_data.shape[0],128,replace=False)\n",
    "        x_,y_=val_data[mask]-cumt_picmean,val_label[mask]\n",
    "        feed_dict={X:x_,Y:y_,bn_train:False}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        best_acc=max(best_acc,acc_)\n",
    "        writer_val.add_summary(m_,i)\n",
    "        print('@@epoch:{},val loss:{:.4f},val accuracy:{:.4f},best val acc:{:.4f}'.format(i,loss_,acc_,best_acc))\n",
    "    if i%500==0:\n",
    "        lr_=max(lr_*0.7,9e-5)\n",
    "        print('$$$ lr change:{}'.format(lr_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save_network_weight('densenet_dump/smallv7_acc969.pkl',sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()\n",
    "saver.save(sess,'model_save/DenseNet/small_model_on_cumtv7_acc949',global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 ms ± 2.85 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mask=np.random.choice(te_data.shape[0],1,replace=False)\n",
    "x_,y_=te_data[mask],te_label[mask]\n",
    "feed_dict={X:x_,Y:y_,bn_train:False}\n",
    "sess.run(y_score,feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用CUMT训练好的模型进行迁移 学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**利用DenseNet结构加Cumt数据训练出的模型，进行webcam的gaze estimate**\n",
    "* DenseNet_V0_trans762: 根据CUMT数据训练出的模型进行迁移学习，5X5 分类，准确率为95%左右 \n",
    "* DenseNet_V0_zeros762: 从0开始训练，5X5 分类，准确率为95%左右  \n",
    "* DenseNet_V7_trans762: 根据CUMT数据训练出的模型进行迁移学习，5X5 分类，准确率为80%左右   \n",
    "  V7（k=2 ,L=2,dense block=4,theta=0.8）参数为10KB,要比较多的训练数据才能出好的效果\n",
    "  \n",
    "    \n",
    "      \n",
    "* DenseNet_V0_trans256: 根据CUMT数据训练出的模型进行迁移学习，5X5 分类，准确率为88%左右 \n",
    "* DenseNet_V0_zeros256: 从0开始训练，5X5 分类，准确率为68%左右  \n",
    "### 结论：\n",
    "** 1.在1K数据量左右不管是从0还是迁移，都能得到差不多好的效果，迁移学习收敛稍微快一些**  \n",
    "** 2.在极少数据量（256）迁移学习发挥的作用大很多，收敛更快，准确率更高  **  \n",
    "** 3.数据量越多网络的表现越好，迁移学习总是比从0开始训练要好  **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from cumt_variant import densenet\n",
    "cumt_picmean=[103.939, 116.779, 123.68]\n",
    "sess=tf.InteractiveSession()\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_class=36\n",
    "log_name='6X6/densenet_v0trans_18951'\n",
    "with tf.variable_scope('Placehloder'):\n",
    "    X=tf.placeholder(dtype=tf.float32,shape=[None,128,128,3],name='X')\n",
    "    Y=tf.placeholder(dtype=tf.float32,shape=[None,output_class],name='Y')\n",
    "    bn_train=tf.placeholder(dtype=tf.bool,name='BN_FLAG')\n",
    "    LR=tf.placeholder(dtype=tf.float32,name='lr')\n",
    "with tf.name_scope('DenseNet'):\n",
    "    model=densenet(Images=X,bn_istraining=bn_train,K=12,L=5,theta=0.5,output_class=output_class,sess=sess,denseblock_num=4)\n",
    "    y_score=model.y_score\n",
    "with tf.name_scope('LOSS'):\n",
    "    LOSS=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_score,labels=Y))\n",
    "    tf.summary.scalar('loss',LOSS)\n",
    "with tf.name_scope('TRAIN'):\n",
    "    TRAIN=tf.train.AdamOptimizer(LR).minimize(LOSS)\n",
    "with tf.name_scope('ACCURACY'):\n",
    "    acc_count=tf.equal(tf.arg_max(y_score,1),tf.arg_max(Y,1))\n",
    "    ACCURACY=tf.reduce_mean(tf.cast(acc_count,tf.float32))\n",
    "    tf.summary.scalar('acc',ACCURACY)\n",
    "bn_ops=tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "writer_te=tf.summary.FileWriter(r'./mylog/'+log_name+r'/test')\n",
    "writer_tr=tf.summary.FileWriter(r'./mylog/'+log_name+r'/train')\n",
    "writer_val=tf.summary.FileWriter(r'./mylog/'+log_name+r'/val')\n",
    "merge=tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tf.Variable 'Tail/conv_class/weight:0' shape=(1, 1, 57, 10) dtype=float32_ref>\n",
    "# <tf.Variable 'Tail/conv_class/biases:0' shape=(10,) dtype=float32_ref>\n",
    "# <tf.Variable 'Tail/conv_class/BN/beta:0' shape=(10,) dtype=float32_ref>\n",
    "# <tf.Variable 'Tail/conv_class/BN/gamma:0' shape=(10,) dtype=float32_ref>\n",
    "model.init_network(sess=sess,weight_addr='densenet_dump/midV0_acc949.pkl',\n",
    "                   skip_layer=['Tail/conv_class/weight','Tail/conv_class/biases','Tail/conv_class/BN/beta','Tail/conv_class/BN/gamma'],\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  'img4X4_1006.pkl'   'img5X5_240.pkl'\n",
    "# d=np.load('img4X4_1006.pkl')\n",
    "d=np.load('image_pklfile/img6X6_18951.pkl')\n",
    "index_=np.arange(d['data'].shape[0])\n",
    "np.random.shuffle(index_)\n",
    "tr_index=index_[:int(d['data'].shape[0]*0.9)]\n",
    "te_index=index_[int(d['data'].shape[0]*0.9):]\n",
    "# tr_index=index_[:256]\n",
    "# te_index=index_[256:]\n",
    "tr_data,tr_label=d['data'][tr_index],d['label'][tr_index]\n",
    "te_data,te_label=d['data'][te_index],d['label'][te_index]\n",
    "print(tr_data.shape,te_data.shape)\n",
    "del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_argment(image_batch,label_batch):\n",
    "    map_dict={0:5,1:4,2:3,\n",
    "         3:2,4:1,5:0}\n",
    "    h_img=image_batch[:,:,::-1,:]\n",
    "    new_label=[]\n",
    "    for lab_ in label_batch:\n",
    "        label_=np.argmax(lab_)\n",
    "        n_=map_dict[label_%6]+(label_//6)*6\n",
    "        nl=[0]*36\n",
    "        nl[n_]=1\n",
    "        new_label.append(nl)\n",
    "    new_label=np.array(new_label)\n",
    "    image_batch=np.vstack((image_batch,h_img))\n",
    "    label_batch=np.vstack((label_batch,new_label))\n",
    "    return image_batch,label_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a,b=data_argment(x_,y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#开始正式训练\n",
    "batchsize=32\n",
    "lr_=6e-6\n",
    "for i in range(16361,10000*6*12):\n",
    "    mask=np.random.choice(tr_data.shape[0],batchsize,replace=False)\n",
    "    x_,y_=tr_data[mask],tr_label[mask]\n",
    "    x_,y_=data_argment(x_,y_)\n",
    "    feed_dict={X:x_-cumt_picmean,Y:y_,bn_train:True,LR:lr_}\n",
    "    sess.run([TRAIN,bn_ops],feed_dict=feed_dict)\n",
    "    if i%10==0:\n",
    "        mask=np.random.choice(tr_data.shape[0],128,replace=False)\n",
    "        x_,y_=tr_data[mask]-cumt_picmean,tr_label[mask]\n",
    "        feed_dict={X:x_,Y:y_,bn_train:False}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_tr.add_summary(m_,i)\n",
    "        print('epoch:{},train loss:{},train accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%20==0:\n",
    "        mask=np.random.choice(te_data.shape[0],128,replace=False)\n",
    "        x_,y_=te_data[mask]-cumt_picmean,te_label[mask]\n",
    "        feed_dict={X:x_,Y:y_,bn_train:False}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_te.add_summary(m_,i)\n",
    "        print('--epoch:{},test loss:{},test accuracy:{}'.format(i,loss_,acc_))\n",
    "#     if i%500==0:\n",
    "#         lr_=max(lr_*0.9,9e-5)\n",
    "#         print('$$$ lr change:{}'.format(lr_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()\n",
    "saver.save(sess,'./model_save/6X6DensNet_v0/v0_937.ckpt',global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save_network_weight('dense4x4_trans991.pkl',sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "mask=np.random.choice(10,1,replace=False)\n",
    "x_,y_=te_data[mask]-cumt_picmean,te_label[mask]\n",
    "feed_dict={X:x_,Y:y_,bn_train:False}\n",
    "sess.run(y_score,feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实测 5X5分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') \n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')  \n",
    "def drawline(img_,line_w=1,line_color=(0,0,0),wandh_num=4):\n",
    "        '''\n",
    "        在图片上格子\n",
    "        :param line_w: 线宽\n",
    "        :param line_color: 线颜色\n",
    "        :param wandh_num:  长宽线的数量\n",
    "        :return:  无\n",
    "        '''\n",
    "        h,w=img_.shape[0],img_.shape[1]\n",
    "        w_num,h_num=wandh_num,wandh_num\n",
    "        h_,w_=h//h_num,w//w_num\n",
    "\n",
    "        # 竖线 (w,h)\n",
    "        for i in range(1,w_num):\n",
    "            #print(i)\n",
    "            cv2.line(img_,(w_*i,0),(w_*i,h),line_color,line_w)\n",
    "        # 横线\n",
    "        for i in range(1,h_num):\n",
    "            cv2.line(img_,(0,h_*i),(w,h_*i),line_color,line_w)\n",
    "        return img_\n",
    "\n",
    "def drawblock(img,line_num,block_id=0,blockcolor=(46,218,255),blockwideth=5,show_rec='fill',rec_shape=None):\n",
    "        '''\n",
    "        选定九宫格，在这个格子上填充矩形表示选定这个格子\n",
    "        :param img_: 图片\n",
    "        :param block: 九宫格序号 0-15\n",
    "        :param blockcolor: 矩形框颜色\n",
    "        :param blockwideth: 框的宽度\n",
    "        :return:\n",
    "        '''\n",
    "        h,w=img.shape[0],img.shape[1]\n",
    "        w_line,h_line=line_num,line_num\n",
    "        h_,w_=h//h_line,w//w_line\n",
    "        cor_h=block_id//line_num\n",
    "        cor_w=block_id%line_num\n",
    "        sx,sy=cor_w*w_,cor_h*h_\n",
    "        \n",
    "        if show_rec=='fill':\n",
    "        #将整个矩形填充为其他颜色\n",
    "            img[sy:sy+h_,sx:sx+w_,:]=blockcolor\n",
    "        elif show_rec=='rec':\n",
    "            #显示矩形轮廓\n",
    "            xe,ye,we,he=rec_shape\n",
    "            cv2.rectangle(img,(xe,ye),(xe+we,ye+he),(255,0,0),10)\n",
    "        elif show_rec=='dot':\n",
    "            #标记一个小点\n",
    "            roi_=img[sy:sy+h_,sx:sx+w_]\n",
    "            cv2.circle(roi_,(roi_.shape[1]//2,roi_.shape[0]//2), 10, (255,128,120), -1)\n",
    "        elif show_rec=='select':\n",
    "            #hight light 矩形区域\n",
    "            #img[sy:sy+h_,sx:sx+w_,0]=255#r\n",
    "            img[sy:sy+h_,sx:sx+w_,1]=255#g\n",
    "            #img[sy:sy+h_,sx:sx+w_,2]=255#b\n",
    "        elif show_rec=='pick':\n",
    "            #返回矩形框内容\n",
    "            return img[sy:sy+h_,sx:sx+w_],(sx,sy,w_,h_)\n",
    "        return img\n",
    "def geteyeimg(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3,5) \n",
    "    if len(faces) !=1:\n",
    "        print(len(faces))\n",
    "        print('bad faces')\n",
    "        return None\n",
    "    for (x,y,w,h) in faces: \n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) \n",
    "            roi_gray = gray[y:y+h, x:x+w] \n",
    "            roi_color = img[y:y+h, x:x+w] \n",
    "            #检测视频中脸部的眼睛，并用vector保存眼睛的坐标、大小（用矩形表示） \n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray,scaleFactor=1.2, minNeighbors=7, minSize=(29, 29),\n",
    "                                     flags=cv2.CASCADE_SCALE_IMAGE) \n",
    "            #眼睛检测 ,对于识别比较差的情况舍弃\n",
    "            if len(eyes)!=2:\n",
    "                print(len(eyes))\n",
    "                print('bad eyes')\n",
    "                return None\n",
    "            if eyes[0][0]>eyes[1][0]:\n",
    "                ex=eyes[1][0]\n",
    "                W=eyes[0][0]-eyes[1][0]+eyes[0][2]\n",
    "            else:\n",
    "                ex=eyes[0][0]\n",
    "                W=eyes[1][0]-eyes[0][0]+eyes[1][2]\n",
    "            \n",
    "            if eyes[0][1]>eyes[1][1]:\n",
    "                ey=eyes[1][1]\n",
    "                H=eyes[0][1]-eyes[1][1]+eyes[0][3]\n",
    "            else:\n",
    "                ey=eyes[0][1]\n",
    "                H=eyes[1][1]-eyes[0][1]+eyes[1][3]\n",
    "    \n",
    "    return roi_color[ey+10:ey+H-2,ex-10:ex+W+10] if roi_color is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "_,frame=cap.read()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob=tf.nn.softmax(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e=geteyeimg(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e=cv2.resize(e,(128,128))[:,:,::-1].reshape((1,128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#e=get_eyeimg(frame)\n",
    "prob_=sess.run(prob,feed_dict={X:e-cumt_picmean,bn_train:False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fps=10\n",
    "fsize_desk=(1920,1080)\n",
    "# save video\n",
    "video_d=cv2.VideoWriter('demo_desk2.flv',cv2.VideoWriter_fourcc('F','L','V','1'),fps,fsize_desk)\n",
    "cap=cv2.VideoCapture(0)\n",
    "s_time=time.time()\n",
    "tar_img=cv2.imread('test.jpg')\n",
    "#设置window 为全屏\n",
    "cv2.namedWindow('Capture001',cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Capture001', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "s_time=time.time()\n",
    "random_show=np.random.randint(0,36,1)[0]\n",
    "\n",
    "#每N帧输出平均预测\n",
    "sum_score=[]\n",
    "sum_counter=0\n",
    "block_id=0\n",
    "ret_counter=0\n",
    "right_frame_counter=0\n",
    "while True:\n",
    "    ret,fram=cap.read()\n",
    "    if ret:\n",
    "        ret_counter+=1\n",
    "        #显示 内窥镜图像\n",
    "        tar_img=cv2.imread('test.jpg')\n",
    "        tar_img=drawline(tar_img,wandh_num=6)\n",
    "        #每30帧换点\n",
    "        if ret_counter%30==0:\n",
    "            random_show=np.random.randint(0,36,1)[0]\n",
    "        tar_img=drawblock(tar_img,line_num=6,block_id=random_show)\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "        e=geteyeimg(fram)\n",
    "        if e is None:\n",
    "            continue\n",
    "        e=cv2.resize(e,(128,128))[:,:,::-1].reshape((1,128,128,3))\n",
    "        y_guess=sess.run(prob,feed_dict={X:e-cumt_picmean,bn_train:False})\n",
    "        sum_score.append(y_guess)\n",
    "        #平均每 N 帧的预测分数\n",
    "        if ret_counter%4==0:\n",
    "            sum_score=np.array(sum_score)\n",
    "            mean_=np.mean(sum_score,0)\n",
    "            block_id=np.argmax(mean_)\n",
    "            sum_score=[]\n",
    "        if block_id<0:block_id=0\n",
    "        elif block_id>35:block_id=35\n",
    "\n",
    "        print(block_id)\n",
    "        if block_id==random_show:\n",
    "             right_frame_counter+=1\n",
    "        tar_img=drawblock(tar_img,line_num=6,block_id=block_id,show_rec='dot')\n",
    "        v_img=tar_img.copy()\n",
    "        fram=cv2.resize(fram,(150,150))\n",
    "        v_img[:150,-150:]=fram\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "\n",
    "\n",
    "#         print('{} sec per frame'.format(time.time()-s_time))\n",
    "        s_time=time.time()\n",
    "        video_d.write(v_img)\n",
    "        if cv2.waitKey(1)&0xff==27:\n",
    "            print('accuracy:{}'.format(right_frame_counter/ret_counter))\n",
    "            print('out')\n",
    "            break\n",
    "    if (time.time()-s_time)>60*5:\n",
    "        print('time out')\n",
    "        break\n",
    "video_d.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_d.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017年12月2日23:22:39\n",
    "## 选中ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img='medical2_big.jpg'\n",
    "\n",
    "fps=10\n",
    "fsize_desk=(1920,1080)\n",
    "# save video\n",
    "video_d=cv2.VideoWriter('demo_pic2.flv',cv2.VideoWriter_fourcc('F','L','V','1'),fps,fsize_desk)\n",
    "cap=cv2.VideoCapture(0)\n",
    "s_time=time.time()\n",
    "tar_img=cv2.imread(target_img)\n",
    "ori_img=cv2.resize(tar_img,(1920,1080))\n",
    "#ori_img0=cv2.resize(tar_img,(1920,1080))\n",
    "#设置window 为全屏\n",
    "cv2.namedWindow('Capture001',cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Capture001', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "s_time=time.time()\n",
    "#random_show=np.random.randint(0,16,1)[0]\n",
    "\n",
    "#每N帧输出平均预测\n",
    "sum_score=[]\n",
    "sum_counter=0\n",
    "block_id=0\n",
    "ret_counter=0\n",
    "right_frame_counter=0\n",
    "#选中矩形框部分的变量\n",
    "change_flag=0\n",
    "block_counter={}\n",
    "rec_x,rec_y,rec_w,rec_h=0,0,0,0\n",
    "while True:\n",
    "    ret,fram=cap.read()\n",
    "    if ret:\n",
    "        #显示 内窥镜图像\n",
    "        tar_img=ori_img.copy()\n",
    "        tar_img=drawline(tar_img,wandh_num=6)\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "        e=geteyeimg(fram)\n",
    "        if e is None:\n",
    "            continue\n",
    "        e=cv2.resize(e,(128,128))[:,:,::-1].reshape((1,128,128,3))\n",
    "        y_guess=sess.run(prob,feed_dict={X:e-cumt_picmean,bn_train:False})[0]\n",
    "        \n",
    "        #平均每 N 帧的预测分数\n",
    "        sum_counter+=1\n",
    "        sum_score.append(y_guess)\n",
    "        if sum_counter==3:\n",
    "            sum_score=np.asarray(sum_score).reshape((-1,36))\n",
    "            mean_score=np.mean(sum_score,0)\n",
    "            block_id=np.argmax(mean_score)\n",
    "            sum_score=[]\n",
    "            sum_counter=0\n",
    "            #print(block_id)\n",
    "            if block_id<0:block_id=0\n",
    "            elif block_id>35:block_id=35\n",
    "        \n",
    "        #假如连续盯着一个地方，放大这部分,只放大两次\n",
    "        if change_flag <2:\n",
    "            if block_id not in block_counter:\n",
    "                block_counter[block_id]=0\n",
    "            block_counter[block_id]+=1\n",
    "            if block_counter[block_id]==30:\n",
    "                roi_rec,rec_shape=drawblock(tar_img,line_num=6,block_id=block_id,show_rec='pick')\n",
    "                s_x,s_y,s_w,s_h=rec_shape\n",
    "                rec_x+=s_x//(6**change_flag)\n",
    "                rec_y+=s_y//(6**change_flag)\n",
    "                #print(rec_x,rec_y,s_x,s_y)\n",
    "                rec_w,rec_h=s_w//6,s_h//6\n",
    "                block_counter={}\n",
    "                ori_img=cv2.resize(roi_rec,(1920,1080))\n",
    "                change_flag+=1\n",
    "        elif change_flag ==2:\n",
    "            change_flag+=1\n",
    "            #将选中的区域标记处来\n",
    "            tar_img=cv2.imread(target_img)\n",
    "            ori_img=cv2.resize(tar_img,(1920,1080))\n",
    "            cv2.rectangle(ori_img,(rec_x,rec_y),(rec_x+rec_w,rec_y+rec_h),(0,0,255),3)\n",
    "            #cv2.circle(ori_img,(ori_img.shape[1]//2,ori_img.shape[0]//2), 10, (255,128,120), -1)\n",
    "            continue\n",
    "        \n",
    "        tar_img=drawblock(tar_img,line_num=6,block_id=block_id,show_rec='select')\n",
    "        v_img=tar_img.copy()\n",
    "        fram=cv2.resize(fram,(200,200))\n",
    "        v_img[:200,-200:]=fram\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "\n",
    "        video_d.write(v_img)\n",
    "        if cv2.waitKey(1)&0xff==27:\n",
    "#             print('accuracy:{}'.format(right_frame_counter/ret_counter))\n",
    "            print('out')\n",
    "            break\n",
    "    if (time.time()-s_time)>60*5:\n",
    "        print('time out')\n",
    "        break\n",
    "video_d.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
