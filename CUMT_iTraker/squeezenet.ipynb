{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用SqueezeNet结构训练cumt数据\n",
    "## 2017年11月8日"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %reload_ext autoreload\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from cumt_eye import Cumt_itraker\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from Cumt_SqueezeNet import squeezenet\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "sess=tf.InteractiveSession()\n",
    "cumt_data=np.load('cumt_data.pkl')\n",
    "index=np.arange(cumt_data['data'].shape[0])\n",
    "np.random.shuffle(index)\n",
    "data=cumt_data['data'][index]\n",
    "label=cumt_data['labels'][index]\n",
    "del cumt_data\n",
    "\n",
    "#cumt rgb 相片均值\n",
    "cumt_picmean=[103.939, 116.779, 123.68]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将图片从 （32,128,3）转换成（128,128,3），有可能会导致精度下降，非必要\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n"
     ]
    }
   ],
   "source": [
    "resize_img=[]\n",
    "for i in range(data.shape[0]):\n",
    "    img=data[i]+cumt_picmean\n",
    "    img=cv2.resize(img.astype('uint8'),(128,128))\n",
    "    resize_img.append(img.astype('uint8'))\n",
    "    if i%10000==0:\n",
    "        print (i)\n",
    "data=None\n",
    "resize_img=np.array(resize_img).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 常规设置占位符，训练节点等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building graph\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('PlaceHolder'):\n",
    "    X=tf.placeholder(shape=[None,128,128,3],dtype=tf.float32)\n",
    "    Y=tf.placeholder(shape=[None,10],dtype=tf.float32)\n",
    "    LR=tf.placeholder(dtype=tf.float32)\n",
    "with tf.name_scope('model'):\n",
    "    model=squeezenet(X,sess)\n",
    "    y_score=model.score\n",
    "with tf.name_scope('LOSS'):\n",
    "    LOSS=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_score,labels=Y))\n",
    "    tf.summary.scalar('loss',LOSS)\n",
    "with tf.name_scope('TRAIN'):\n",
    "    TRAIN=tf.train.AdamOptimizer(LR).minimize(LOSS)\n",
    "with tf.name_scope('ACCURACY'):\n",
    "    acc_count=tf.equal(tf.arg_max(y_score,1),tf.arg_max(Y,1))\n",
    "    ACCURACY=tf.reduce_mean(tf.cast(acc_count,tf.float32))\n",
    "    tf.summary.scalar('acc',ACCURACY)\n",
    "writer_tr=tf.summary.FileWriter('./mylog/squeezenet/train')\n",
    "writer_te=tf.summary.FileWriter('./mylog/squeezenet/test',sess.graph)\n",
    "writer_val=tf.summary.FileWriter('./mylog/squeezenet/val')\n",
    "merge=tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train,test,val数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67346, 128, 128, 3) (7483, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "data=resize_img\n",
    "index=np.arange(data.shape[0])\n",
    "np.random.shuffle(index)\n",
    "tr_index=index[:int(data.shape[0]*0.9)]\n",
    "te_index=index[int(data.shape[0]*0.9):]\n",
    "tr_data,tr_label=data[tr_index],label[tr_index]\n",
    "te_data,te_label=data[te_index],label[te_index]\n",
    "del data\n",
    "del label\n",
    "del resize_img\n",
    "print(tr_data.shape,te_data.shape)\n",
    "\n",
    "addr=r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\Proj_iTraker\\CUMT_iTraker\\test_video\\101603\\101603_z.pkl'\n",
    "val_d=np.load(addr)\n",
    "val_data=[]\n",
    "for v in range(val_d['images'].shape[0]):\n",
    "    img_=cv2.resize(val_d['images'][v],(128,128))\n",
    "    val_data.append(img_)\n",
    "val_data=np.array(val_data)\n",
    "val_label=val_d['labels']\n",
    "del val_d\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,train loss:2.284879684448242,train accuracy:0.140625\n",
      "--epoch:0,test loss:2.313260078430176,test accuracy:0.0625\n",
      "@@epoch:0,val loss:2.2761244773864746,val accuracy:0.171875\n",
      "epoch:10,train loss:2.2994980812072754,train accuracy:0.125\n",
      "epoch:20,train loss:2.29630970954895,train accuracy:0.15625\n",
      "epoch:30,train loss:2.3021130561828613,train accuracy:0.109375\n",
      "--epoch:30,test loss:2.299588203430176,test accuracy:0.140625\n",
      "epoch:40,train loss:2.301260232925415,train accuracy:0.109375\n",
      "epoch:50,train loss:2.302359104156494,train accuracy:0.140625\n",
      "epoch:60,train loss:2.3041205406188965,train accuracy:0.078125\n",
      "--epoch:60,test loss:2.302917957305908,test accuracy:0.09375\n",
      "epoch:70,train loss:2.302932024002075,train accuracy:0.109375\n",
      "epoch:80,train loss:2.302196741104126,train accuracy:0.109375\n",
      "epoch:90,train loss:2.3037943840026855,train accuracy:0.078125\n",
      "--epoch:90,test loss:2.304551362991333,test accuracy:0.0625\n",
      "epoch:100,train loss:2.302884101867676,train accuracy:0.09375\n",
      "@@epoch:100,val loss:2.2963123321533203,val accuracy:0.265625\n",
      "epoch:110,train loss:2.3011369705200195,train accuracy:0.140625\n",
      "epoch:120,train loss:2.3022208213806152,train accuracy:0.109375\n",
      "--epoch:120,test loss:2.302168846130371,test accuracy:0.109375\n",
      "epoch:130,train loss:2.306297540664673,train accuracy:0.046875\n",
      "epoch:140,train loss:2.304243803024292,train accuracy:0.078125\n",
      "epoch:150,train loss:2.3043179512023926,train accuracy:0.0625\n",
      "--epoch:150,test loss:2.3022727966308594,test accuracy:0.109375\n",
      "epoch:160,train loss:2.300673723220825,train accuracy:0.140625\n",
      "epoch:170,train loss:2.302168607711792,train accuracy:0.109375\n",
      "epoch:180,train loss:2.303499698638916,train accuracy:0.09375\n",
      "--epoch:180,test loss:2.3034615516662598,test accuracy:0.09375\n",
      "epoch:190,train loss:2.3036818504333496,train accuracy:0.09375\n",
      "epoch:200,train loss:2.302119255065918,train accuracy:0.109375\n",
      "@@epoch:200,val loss:2.293775796890259,val accuracy:0.1875\n",
      "epoch:210,train loss:2.3021059036254883,train accuracy:0.109375\n",
      "--epoch:210,test loss:2.300258159637451,test accuracy:0.125\n",
      "epoch:220,train loss:2.3010313510894775,train accuracy:0.125\n",
      "epoch:230,train loss:2.303091526031494,train accuracy:0.09375\n",
      "epoch:240,train loss:2.301065444946289,train accuracy:0.140625\n",
      "--epoch:240,test loss:2.3028597831726074,test accuracy:0.09375\n",
      "epoch:250,train loss:2.302274703979492,train accuracy:0.109375\n",
      "epoch:260,train loss:2.301663398742676,train accuracy:0.125\n",
      "epoch:270,train loss:2.3029417991638184,train accuracy:0.09375\n",
      "--epoch:270,test loss:2.302947998046875,test accuracy:0.09375\n",
      "epoch:280,train loss:2.302957534790039,train accuracy:0.09375\n",
      "epoch:290,train loss:2.3036835193634033,train accuracy:0.078125\n",
      "epoch:300,train loss:2.302224636077881,train accuracy:0.109375\n",
      "--epoch:300,test loss:2.3005449771881104,test accuracy:0.140625\n",
      "@@epoch:300,val loss:2.2937495708465576,val accuracy:0.265625\n",
      "epoch:310,train loss:2.3029942512512207,train accuracy:0.09375\n",
      "epoch:320,train loss:2.300574541091919,train accuracy:0.140625\n",
      "epoch:330,train loss:2.3001086711883545,train accuracy:0.140625\n",
      "--epoch:330,test loss:2.307230234146118,test accuracy:0.03125\n",
      "epoch:340,train loss:2.300227165222168,train accuracy:0.140625\n",
      "epoch:350,train loss:2.3061318397521973,train accuracy:0.046875\n",
      "epoch:360,train loss:2.299592971801758,train accuracy:0.15625\n",
      "--epoch:360,test loss:2.3022360801696777,test accuracy:0.109375\n",
      "epoch:370,train loss:2.302172899246216,train accuracy:0.109375\n",
      "epoch:380,train loss:2.2997307777404785,train accuracy:0.140625\n",
      "epoch:390,train loss:2.299889087677002,train accuracy:0.140625\n",
      "--epoch:390,test loss:2.2998387813568115,test accuracy:0.140625\n",
      "epoch:400,train loss:2.301018238067627,train accuracy:0.125\n",
      "@@epoch:400,val loss:2.2963879108428955,val accuracy:0.1875\n",
      "epoch:410,train loss:2.2994332313537598,train accuracy:0.140625\n",
      "epoch:420,train loss:2.3061513900756836,train accuracy:0.0625\n",
      "--epoch:420,test loss:2.307518243789673,test accuracy:0.046875\n",
      "epoch:430,train loss:2.3020665645599365,train accuracy:0.109375\n",
      "epoch:440,train loss:2.299856185913086,train accuracy:0.140625\n",
      "epoch:450,train loss:2.302079677581787,train accuracy:0.109375\n",
      "--epoch:450,test loss:2.3067145347595215,test accuracy:0.046875\n",
      "epoch:460,train loss:2.3030641078948975,train accuracy:0.09375\n",
      "epoch:470,train loss:2.3016014099121094,train accuracy:0.125\n",
      "epoch:480,train loss:2.308466911315918,train accuracy:0.015625\n",
      "--epoch:480,test loss:2.302168369293213,test accuracy:0.109375\n",
      "epoch:490,train loss:2.3095171451568604,train accuracy:0.015625\n",
      "epoch:500,train loss:2.3032641410827637,train accuracy:0.09375\n",
      "@@epoch:500,val loss:2.291093349456787,val accuracy:0.265625\n",
      "epoch:510,train loss:2.3007287979125977,train accuracy:0.125\n",
      "--epoch:510,test loss:2.30086612701416,test accuracy:0.125\n",
      "epoch:520,train loss:2.3004705905914307,train accuracy:0.125\n",
      "epoch:530,train loss:2.300474166870117,train accuracy:0.125\n",
      "epoch:540,train loss:2.2990469932556152,train accuracy:0.140625\n",
      "--epoch:540,test loss:2.3067431449890137,test accuracy:0.0625\n",
      "epoch:550,train loss:2.3003244400024414,train accuracy:0.125\n",
      "epoch:560,train loss:2.300107955932617,train accuracy:0.125\n",
      "epoch:570,train loss:2.3056392669677734,train accuracy:0.078125\n",
      "--epoch:570,test loss:2.3021302223205566,test accuracy:0.109375\n",
      "epoch:580,train loss:2.3035471439361572,train accuracy:0.09375\n",
      "epoch:590,train loss:2.3067734241485596,train accuracy:0.046875\n",
      "epoch:600,train loss:2.2980117797851562,train accuracy:0.171875\n",
      "--epoch:600,test loss:2.307394027709961,test accuracy:0.03125\n",
      "@@epoch:600,val loss:2.2980661392211914,val accuracy:0.171875\n",
      "epoch:610,train loss:2.2983880043029785,train accuracy:0.15625\n",
      "epoch:620,train loss:2.3020968437194824,train accuracy:0.109375\n",
      "epoch:630,train loss:2.3000426292419434,train accuracy:0.140625\n",
      "--epoch:630,test loss:2.3042569160461426,test accuracy:0.078125\n",
      "epoch:640,train loss:2.300947666168213,train accuracy:0.125\n",
      "epoch:650,train loss:2.304745674133301,train accuracy:0.078125\n",
      "epoch:660,train loss:2.305135488510132,train accuracy:0.078125\n",
      "--epoch:660,test loss:2.3066253662109375,test accuracy:0.0625\n",
      "epoch:670,train loss:2.3020992279052734,train accuracy:0.109375\n",
      "epoch:680,train loss:2.2987403869628906,train accuracy:0.140625\n",
      "epoch:690,train loss:2.2970261573791504,train accuracy:0.15625\n",
      "--epoch:690,test loss:2.3020567893981934,test accuracy:0.109375\n",
      "epoch:700,train loss:2.3056888580322266,train accuracy:0.078125\n",
      "@@epoch:700,val loss:2.291337728500366,val accuracy:0.203125\n",
      "epoch:710,train loss:2.3021397590637207,train accuracy:0.109375\n",
      "epoch:720,train loss:2.3041024208068848,train accuracy:0.09375\n",
      "--epoch:720,test loss:2.307929515838623,test accuracy:0.0625\n",
      "epoch:730,train loss:2.3075671195983887,train accuracy:0.0625\n",
      "epoch:740,train loss:2.308964729309082,train accuracy:0.046875\n",
      "epoch:750,train loss:2.3077123165130615,train accuracy:0.046875\n",
      "--epoch:750,test loss:2.300687789916992,test accuracy:0.125\n",
      "epoch:760,train loss:2.3032479286193848,train accuracy:0.09375\n",
      "epoch:770,train loss:2.3083982467651367,train accuracy:0.015625\n",
      "epoch:780,train loss:2.3022165298461914,train accuracy:0.109375\n",
      "--epoch:780,test loss:2.3022360801696777,test accuracy:0.109375\n",
      "epoch:790,train loss:2.3030495643615723,train accuracy:0.09375\n",
      "epoch:800,train loss:2.3015894889831543,train accuracy:0.125\n",
      "@@epoch:800,val loss:2.2989535331726074,val accuracy:0.1875\n",
      "epoch:810,train loss:2.3034613132476807,train accuracy:0.078125\n",
      "--epoch:810,test loss:2.302907943725586,test accuracy:0.09375\n",
      "epoch:820,train loss:2.3034539222717285,train accuracy:0.078125\n",
      "epoch:830,train loss:2.3015494346618652,train accuracy:0.125\n",
      "epoch:840,train loss:2.30709171295166,train accuracy:0.03125\n",
      "--epoch:840,test loss:2.2982404232025146,test accuracy:0.171875\n",
      "epoch:850,train loss:2.303053140640259,train accuracy:0.09375\n",
      "epoch:860,train loss:2.3021936416625977,train accuracy:0.109375\n",
      "epoch:870,train loss:2.3053815364837646,train accuracy:0.0625\n",
      "--epoch:870,test loss:2.29887056350708,test accuracy:0.15625\n",
      "epoch:880,train loss:2.3022468090057373,train accuracy:0.109375\n",
      "epoch:890,train loss:2.2992005348205566,train accuracy:0.15625\n",
      "epoch:900,train loss:2.3021697998046875,train accuracy:0.109375\n",
      "--epoch:900,test loss:2.2988178730010986,test accuracy:0.15625\n",
      "@@epoch:900,val loss:2.293252468109131,val accuracy:0.234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:910,train loss:2.304311513900757,train accuracy:0.078125\n",
      "epoch:920,train loss:2.2993617057800293,train accuracy:0.15625\n",
      "epoch:930,train loss:2.302194356918335,train accuracy:0.109375\n",
      "--epoch:930,test loss:2.301413059234619,test accuracy:0.125\n",
      "epoch:940,train loss:2.3038551807403564,train accuracy:0.078125\n",
      "epoch:950,train loss:2.301501750946045,train accuracy:0.125\n",
      "epoch:960,train loss:2.3029732704162598,train accuracy:0.09375\n",
      "--epoch:960,test loss:2.302957534790039,test accuracy:0.09375\n",
      "epoch:970,train loss:2.3017489910125732,train accuracy:0.125\n",
      "epoch:980,train loss:2.3036298751831055,train accuracy:0.0625\n",
      "epoch:990,train loss:2.3024816513061523,train accuracy:0.109375\n",
      "--epoch:990,test loss:2.303072452545166,test accuracy:0.0625\n",
      "epoch:1000,train loss:2.3035404682159424,train accuracy:0.03125\n",
      "@@epoch:1000,val loss:2.3005611896514893,val accuracy:0.25\n",
      "epoch:1010,train loss:2.301934003829956,train accuracy:0.15625\n",
      "epoch:1020,train loss:2.303035259246826,train accuracy:0.078125\n",
      "--epoch:1020,test loss:2.303048849105835,test accuracy:0.078125\n",
      "epoch:1030,train loss:2.302797317504883,train accuracy:0.09375\n",
      "epoch:1040,train loss:2.3023152351379395,train accuracy:0.109375\n",
      "epoch:1050,train loss:2.302290916442871,train accuracy:0.109375\n",
      "--epoch:1050,test loss:2.3045589923858643,test accuracy:0.046875\n",
      "epoch:1060,train loss:2.301821231842041,train accuracy:0.125\n",
      "epoch:1070,train loss:2.3012447357177734,train accuracy:0.140625\n",
      "epoch:1080,train loss:2.3027937412261963,train accuracy:0.09375\n",
      "--epoch:1080,test loss:2.30143404006958,test accuracy:0.140625\n",
      "epoch:1090,train loss:2.30188250541687,train accuracy:0.125\n",
      "epoch:1100,train loss:2.303152561187744,train accuracy:0.078125\n",
      "@@epoch:1100,val loss:2.298811435699463,val accuracy:0.25\n",
      "epoch:1110,train loss:2.301739454269409,train accuracy:0.140625\n",
      "--epoch:1110,test loss:2.3027303218841553,test accuracy:0.09375\n",
      "epoch:1120,train loss:2.3024191856384277,train accuracy:0.109375\n",
      "epoch:1130,train loss:2.3027920722961426,train accuracy:0.09375\n",
      "epoch:1140,train loss:2.3023130893707275,train accuracy:0.109375\n",
      "--epoch:1140,test loss:2.2994513511657715,test accuracy:0.1875\n",
      "epoch:1150,train loss:2.3007757663726807,train accuracy:0.140625\n",
      "epoch:1160,train loss:2.302248954772949,train accuracy:0.109375\n",
      "epoch:1170,train loss:2.301361560821533,train accuracy:0.125\n",
      "--epoch:1170,test loss:2.303009510040283,test accuracy:0.09375\n",
      "epoch:1180,train loss:2.3031368255615234,train accuracy:0.09375\n",
      "epoch:1190,train loss:2.303180456161499,train accuracy:0.09375\n",
      "epoch:1200,train loss:2.3013288974761963,train accuracy:0.125\n",
      "--epoch:1200,test loss:2.3013365268707275,test accuracy:0.125\n",
      "@@epoch:1200,val loss:2.296923875808716,val accuracy:0.203125\n",
      "epoch:1210,train loss:2.302220344543457,train accuracy:0.109375\n",
      "epoch:1220,train loss:2.3005387783050537,train accuracy:0.140625\n",
      "epoch:1230,train loss:2.299875259399414,train accuracy:0.15625\n",
      "--epoch:1230,test loss:2.3045759201049805,test accuracy:0.0625\n",
      "epoch:1240,train loss:2.2991888523101807,train accuracy:0.15625\n",
      "epoch:1250,train loss:2.305555820465088,train accuracy:0.0625\n",
      "epoch:1260,train loss:2.303192615509033,train accuracy:0.09375\n",
      "--epoch:1260,test loss:2.300095796585083,test accuracy:0.140625\n",
      "epoch:1270,train loss:2.3043293952941895,train accuracy:0.078125\n",
      "epoch:1280,train loss:2.2997779846191406,train accuracy:0.140625\n",
      "epoch:1290,train loss:2.307471513748169,train accuracy:0.046875\n",
      "--epoch:1290,test loss:2.307427167892456,test accuracy:0.046875\n",
      "epoch:1300,train loss:2.304628610610962,train accuracy:0.078125\n",
      "@@epoch:1300,val loss:2.2996487617492676,val accuracy:0.140625\n",
      "epoch:1310,train loss:2.299752712249756,train accuracy:0.140625\n",
      "epoch:1320,train loss:2.299833297729492,train accuracy:0.140625\n",
      "--epoch:1320,test loss:2.303342819213867,test accuracy:0.09375\n",
      "epoch:1330,train loss:2.3068666458129883,train accuracy:0.046875\n",
      "epoch:1340,train loss:2.3054986000061035,train accuracy:0.0625\n",
      "epoch:1350,train loss:2.300014019012451,train accuracy:0.140625\n",
      "--epoch:1350,test loss:2.3032708168029785,test accuracy:0.09375\n",
      "epoch:1360,train loss:2.3032402992248535,train accuracy:0.09375\n",
      "epoch:1370,train loss:2.3012871742248535,train accuracy:0.125\n",
      "epoch:1380,train loss:2.3039798736572266,train accuracy:0.078125\n",
      "--epoch:1380,test loss:2.3030946254730225,test accuracy:0.09375\n",
      "epoch:1390,train loss:2.3046555519104004,train accuracy:0.0625\n",
      "epoch:1400,train loss:2.3037567138671875,train accuracy:0.078125\n",
      "@@epoch:1400,val loss:2.2984023094177246,val accuracy:0.1875\n",
      "epoch:1410,train loss:2.2998106479644775,train accuracy:0.15625\n",
      "--epoch:1410,test loss:2.3014113903045654,test accuracy:0.125\n",
      "epoch:1420,train loss:2.3022000789642334,train accuracy:0.109375\n",
      "epoch:1430,train loss:2.3057336807250977,train accuracy:0.046875\n",
      "epoch:1440,train loss:2.305302381515503,train accuracy:0.046875\n",
      "--epoch:1440,test loss:2.3045668601989746,test accuracy:0.0625\n",
      "epoch:1450,train loss:2.2992634773254395,train accuracy:0.171875\n",
      "epoch:1460,train loss:2.301419258117676,train accuracy:0.125\n",
      "epoch:1470,train loss:2.3031020164489746,train accuracy:0.09375\n",
      "--epoch:1470,test loss:2.299616575241089,test accuracy:0.15625\n",
      "epoch:1480,train loss:2.3021202087402344,train accuracy:0.109375\n",
      "epoch:1490,train loss:2.298923969268799,train accuracy:0.15625\n",
      "epoch:1500,train loss:2.3028407096862793,train accuracy:0.09375\n",
      "--epoch:1500,test loss:2.3080878257751465,test accuracy:0.015625\n",
      "@@epoch:1500,val loss:2.2896065711975098,val accuracy:0.296875\n",
      "epoch:1510,train loss:2.3034067153930664,train accuracy:0.109375\n",
      "epoch:1520,train loss:2.307631015777588,train accuracy:0.0625\n",
      "epoch:1530,train loss:2.302266836166382,train accuracy:0.078125\n",
      "--epoch:1530,test loss:2.305602788925171,test accuracy:0.0625\n",
      "epoch:1540,train loss:2.3009703159332275,train accuracy:0.171875\n",
      "epoch:1550,train loss:2.299870014190674,train accuracy:0.171875\n",
      "epoch:1560,train loss:2.301788330078125,train accuracy:0.125\n",
      "--epoch:1560,test loss:2.3035364151000977,test accuracy:0.078125\n",
      "epoch:1570,train loss:2.302290678024292,train accuracy:0.109375\n",
      "epoch:1580,train loss:2.304670810699463,train accuracy:0.046875\n",
      "epoch:1590,train loss:2.301149368286133,train accuracy:0.140625\n",
      "--epoch:1590,test loss:2.301741600036621,test accuracy:0.125\n",
      "epoch:1600,train loss:2.304861545562744,train accuracy:0.046875\n",
      "@@epoch:1600,val loss:2.2971181869506836,val accuracy:0.234375\n",
      "epoch:1610,train loss:2.2996749877929688,train accuracy:0.171875\n",
      "epoch:1620,train loss:2.304685115814209,train accuracy:0.046875\n",
      "--epoch:1620,test loss:2.3034982681274414,test accuracy:0.078125\n",
      "epoch:1630,train loss:2.3007864952087402,train accuracy:0.171875\n",
      "epoch:1640,train loss:2.3027424812316895,train accuracy:0.09375\n",
      "epoch:1650,train loss:2.301114797592163,train accuracy:0.15625\n",
      "--epoch:1650,test loss:2.3032193183898926,test accuracy:0.078125\n",
      "epoch:1660,train loss:2.3016343116760254,train accuracy:0.125\n",
      "epoch:1670,train loss:2.301588535308838,train accuracy:0.125\n",
      "epoch:1680,train loss:2.3007736206054688,train accuracy:0.140625\n",
      "--epoch:1680,test loss:2.3030202388763428,test accuracy:0.09375\n",
      "epoch:1690,train loss:2.3002398014068604,train accuracy:0.15625\n",
      "epoch:1700,train loss:2.3022618293762207,train accuracy:0.109375\n",
      "@@epoch:1700,val loss:2.302257776260376,val accuracy:0.109375\n",
      "epoch:1710,train loss:2.301429510116577,train accuracy:0.125\n",
      "--epoch:1710,test loss:2.2990026473999023,test accuracy:0.171875\n",
      "epoch:1720,train loss:2.3056371212005615,train accuracy:0.046875\n",
      "epoch:1730,train loss:2.3022403717041016,train accuracy:0.109375\n",
      "epoch:1740,train loss:2.3038740158081055,train accuracy:0.078125\n",
      "--epoch:1740,test loss:2.298832416534424,test accuracy:0.171875\n",
      "epoch:1750,train loss:2.3021931648254395,train accuracy:0.109375\n",
      "epoch:1760,train loss:2.3003759384155273,train accuracy:0.140625\n",
      "epoch:1770,train loss:2.2994227409362793,train accuracy:0.15625\n",
      "--epoch:1770,test loss:2.303103446960449,test accuracy:0.09375\n",
      "epoch:1780,train loss:2.306354284286499,train accuracy:0.046875\n",
      "epoch:1790,train loss:2.3011937141418457,train accuracy:0.125\n",
      "epoch:1800,train loss:2.298719644546509,train accuracy:0.15625\n",
      "--epoch:1800,test loss:2.303297519683838,test accuracy:0.09375\n",
      "@@epoch:1800,val loss:2.296205759048462,val accuracy:0.1875\n",
      "epoch:1810,train loss:2.303647994995117,train accuracy:0.09375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1820,train loss:2.298856258392334,train accuracy:0.140625\n",
      "epoch:1830,train loss:2.302130699157715,train accuracy:0.109375\n",
      "--epoch:1830,test loss:2.2968521118164062,test accuracy:0.15625\n",
      "epoch:1840,train loss:2.308539867401123,train accuracy:0.046875\n",
      "epoch:1850,train loss:2.3035075664520264,train accuracy:0.09375\n",
      "epoch:1860,train loss:2.3032703399658203,train accuracy:0.09375\n",
      "--epoch:1860,test loss:2.3010454177856445,test accuracy:0.125\n",
      "epoch:1870,train loss:2.3040924072265625,train accuracy:0.078125\n",
      "epoch:1880,train loss:2.297161102294922,train accuracy:0.203125\n",
      "epoch:1890,train loss:2.3012611865997314,train accuracy:0.125\n",
      "--epoch:1890,test loss:2.3020858764648438,test accuracy:0.109375\n",
      "epoch:1900,train loss:2.303194761276245,train accuracy:0.09375\n",
      "@@epoch:1900,val loss:2.2969040870666504,val accuracy:0.203125\n",
      "epoch:1910,train loss:2.3040688037872314,train accuracy:0.078125\n",
      "epoch:1920,train loss:2.303945779800415,train accuracy:0.078125\n",
      "--epoch:1920,test loss:2.3030967712402344,test accuracy:0.09375\n",
      "epoch:1930,train loss:2.301227569580078,train accuracy:0.125\n",
      "epoch:1940,train loss:2.304088592529297,train accuracy:0.078125\n",
      "epoch:1950,train loss:2.3041510581970215,train accuracy:0.078125\n",
      "--epoch:1950,test loss:2.2992215156555176,test accuracy:0.15625\n",
      "epoch:1960,train loss:2.3059463500976562,train accuracy:0.046875\n",
      "epoch:1970,train loss:2.3040308952331543,train accuracy:0.078125\n",
      "epoch:1980,train loss:2.3012523651123047,train accuracy:0.125\n",
      "--epoch:1980,test loss:2.303102493286133,test accuracy:0.09375\n",
      "epoch:1990,train loss:2.305851936340332,train accuracy:0.046875\n",
      "epoch:2000,train loss:2.304755210876465,train accuracy:0.0625\n",
      "@@epoch:2000,val loss:2.299649715423584,val accuracy:0.15625\n",
      "epoch:2010,train loss:2.303051471710205,train accuracy:0.09375\n",
      "--epoch:2010,test loss:2.3038668632507324,test accuracy:0.078125\n",
      "epoch:2020,train loss:2.3014471530914307,train accuracy:0.125\n",
      "epoch:2030,train loss:2.3049044609069824,train accuracy:0.0625\n",
      "epoch:2040,train loss:2.301271677017212,train accuracy:0.125\n",
      "--epoch:2040,test loss:2.303107261657715,test accuracy:0.09375\n",
      "epoch:2050,train loss:2.3040032386779785,train accuracy:0.078125\n",
      "epoch:2060,train loss:2.3002357482910156,train accuracy:0.140625\n",
      "epoch:2070,train loss:2.296696662902832,train accuracy:0.1875\n",
      "--epoch:2070,test loss:2.305453300476074,test accuracy:0.0625\n",
      "epoch:2080,train loss:2.3020734786987305,train accuracy:0.109375\n",
      "epoch:2090,train loss:2.3019652366638184,train accuracy:0.109375\n",
      "epoch:2100,train loss:2.3058698177337646,train accuracy:0.0625\n",
      "--epoch:2100,test loss:2.302189350128174,test accuracy:0.109375\n",
      "@@epoch:2100,val loss:2.293447256088257,val accuracy:0.21875\n",
      "epoch:2110,train loss:2.304461717605591,train accuracy:0.078125\n",
      "epoch:2120,train loss:2.3004698753356934,train accuracy:0.140625\n",
      "epoch:2130,train loss:2.3008670806884766,train accuracy:0.125\n",
      "--epoch:2130,test loss:2.298412799835205,test accuracy:0.15625\n",
      "epoch:2140,train loss:2.30641508102417,train accuracy:0.046875\n",
      "epoch:2150,train loss:2.3049509525299072,train accuracy:0.078125\n",
      "epoch:2160,train loss:2.2989754676818848,train accuracy:0.15625\n",
      "--epoch:2160,test loss:2.3022451400756836,test accuracy:0.109375\n",
      "epoch:2170,train loss:2.3028879165649414,train accuracy:0.09375\n",
      "epoch:2180,train loss:2.300327777862549,train accuracy:0.109375\n",
      "epoch:2190,train loss:2.299708127975464,train accuracy:0.109375\n",
      "--epoch:2190,test loss:2.3045663833618164,test accuracy:0.09375\n",
      "epoch:2200,train loss:2.2997145652770996,train accuracy:0.15625\n",
      "@@epoch:2200,val loss:2.3023829460144043,val accuracy:0.03125\n",
      "epoch:2210,train loss:2.30196213722229,train accuracy:0.140625\n",
      "epoch:2220,train loss:2.3020496368408203,train accuracy:0.140625\n",
      "--epoch:2220,test loss:2.301224708557129,test accuracy:0.09375\n",
      "epoch:2230,train loss:2.3029847145080566,train accuracy:0.109375\n",
      "epoch:2240,train loss:2.3009212017059326,train accuracy:0.125\n",
      "epoch:2250,train loss:2.303710460662842,train accuracy:0.078125\n",
      "--epoch:2250,test loss:2.3027572631835938,test accuracy:0.109375\n",
      "epoch:2260,train loss:2.300208806991577,train accuracy:0.15625\n",
      "epoch:2270,train loss:2.3015336990356445,train accuracy:0.140625\n",
      "epoch:2280,train loss:2.302920341491699,train accuracy:0.0625\n",
      "--epoch:2280,test loss:2.3031604290008545,test accuracy:0.09375\n",
      "epoch:2290,train loss:2.3034708499908447,train accuracy:0.078125\n",
      "epoch:2300,train loss:2.3023667335510254,train accuracy:0.109375\n",
      "@@epoch:2300,val loss:2.301053047180176,val accuracy:0.140625\n",
      "epoch:2310,train loss:2.3035027980804443,train accuracy:0.0625\n",
      "--epoch:2310,test loss:2.3045284748077393,test accuracy:0.046875\n",
      "epoch:2320,train loss:2.30454421043396,train accuracy:0.109375\n",
      "epoch:2330,train loss:2.3015756607055664,train accuracy:0.109375\n",
      "epoch:2340,train loss:2.3077306747436523,train accuracy:0.046875\n",
      "--epoch:2340,test loss:2.3037590980529785,test accuracy:0.09375\n",
      "epoch:2350,train loss:2.306624174118042,train accuracy:0.046875\n",
      "epoch:2360,train loss:2.302339553833008,train accuracy:0.078125\n",
      "epoch:2370,train loss:2.3062539100646973,train accuracy:0.046875\n",
      "--epoch:2370,test loss:2.300959348678589,test accuracy:0.140625\n",
      "epoch:2380,train loss:2.302503824234009,train accuracy:0.078125\n",
      "epoch:2390,train loss:2.3008458614349365,train accuracy:0.09375\n",
      "epoch:2400,train loss:2.304103374481201,train accuracy:0.078125\n",
      "--epoch:2400,test loss:2.3033745288848877,test accuracy:0.0625\n",
      "@@epoch:2400,val loss:2.300326108932495,val accuracy:0.046875\n",
      "epoch:2410,train loss:2.3011720180511475,train accuracy:0.125\n",
      "epoch:2420,train loss:2.3000149726867676,train accuracy:0.09375\n",
      "epoch:2430,train loss:2.3016281127929688,train accuracy:0.140625\n",
      "--epoch:2430,test loss:2.302353858947754,test accuracy:0.09375\n",
      "epoch:2440,train loss:2.302887439727783,train accuracy:0.078125\n",
      "epoch:2450,train loss:2.3028831481933594,train accuracy:0.0625\n",
      "epoch:2460,train loss:2.3072962760925293,train accuracy:0.078125\n",
      "--epoch:2460,test loss:2.3040685653686523,test accuracy:0.109375\n",
      "epoch:2470,train loss:2.2998247146606445,train accuracy:0.078125\n",
      "epoch:2480,train loss:2.3057217597961426,train accuracy:0.109375\n",
      "epoch:2490,train loss:2.3035595417022705,train accuracy:0.0625\n",
      "--epoch:2490,test loss:2.3009426593780518,test accuracy:0.140625\n",
      "epoch:2500,train loss:2.297896385192871,train accuracy:0.15625\n",
      "@@epoch:2500,val loss:2.2954111099243164,val accuracy:0.265625\n",
      "epoch:2510,train loss:2.3064727783203125,train accuracy:0.09375\n",
      "epoch:2520,train loss:2.3049769401550293,train accuracy:0.0625\n",
      "--epoch:2520,test loss:2.3029537200927734,test accuracy:0.15625\n",
      "epoch:2530,train loss:2.304198741912842,train accuracy:0.09375\n",
      "epoch:2540,train loss:2.3056609630584717,train accuracy:0.0625\n",
      "epoch:2550,train loss:2.307206153869629,train accuracy:0.09375\n",
      "--epoch:2550,test loss:2.29866886138916,test accuracy:0.15625\n",
      "epoch:2560,train loss:2.3000590801239014,train accuracy:0.109375\n",
      "epoch:2570,train loss:2.3025059700012207,train accuracy:0.078125\n",
      "epoch:2580,train loss:2.3029747009277344,train accuracy:0.09375\n",
      "--epoch:2580,test loss:2.303532123565674,test accuracy:0.078125\n",
      "epoch:2590,train loss:2.302830696105957,train accuracy:0.046875\n",
      "epoch:2600,train loss:2.298916816711426,train accuracy:0.078125\n",
      "@@epoch:2600,val loss:2.300976514816284,val accuracy:0.140625\n",
      "epoch:2610,train loss:2.3023054599761963,train accuracy:0.078125\n",
      "--epoch:2610,test loss:2.302083969116211,test accuracy:0.140625\n",
      "epoch:2620,train loss:2.300766944885254,train accuracy:0.109375\n",
      "epoch:2630,train loss:2.3033087253570557,train accuracy:0.109375\n",
      "epoch:2640,train loss:2.302098035812378,train accuracy:0.140625\n",
      "--epoch:2640,test loss:2.2970261573791504,test accuracy:0.15625\n",
      "epoch:2650,train loss:2.304131507873535,train accuracy:0.078125\n",
      "epoch:2660,train loss:2.30120849609375,train accuracy:0.09375\n",
      "epoch:2670,train loss:2.306924343109131,train accuracy:0.078125\n",
      "--epoch:2670,test loss:2.305565357208252,test accuracy:0.015625\n",
      "epoch:2680,train loss:2.3000385761260986,train accuracy:0.09375\n",
      "epoch:2690,train loss:2.301229476928711,train accuracy:0.15625\n",
      "epoch:2700,train loss:2.298452854156494,train accuracy:0.125\n",
      "--epoch:2700,test loss:2.2979869842529297,test accuracy:0.140625\n",
      "@@epoch:2700,val loss:2.298879623413086,val accuracy:0.21875\n",
      "epoch:2710,train loss:2.3071253299713135,train accuracy:0.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2720,train loss:2.304764747619629,train accuracy:0.15625\n",
      "epoch:2730,train loss:2.302657127380371,train accuracy:0.125\n",
      "--epoch:2730,test loss:2.301715135574341,test accuracy:0.109375\n",
      "epoch:2740,train loss:2.300588846206665,train accuracy:0.109375\n",
      "epoch:2750,train loss:2.2978975772857666,train accuracy:0.09375\n",
      "epoch:2760,train loss:2.303342342376709,train accuracy:0.171875\n",
      "--epoch:2760,test loss:2.303971290588379,test accuracy:0.078125\n",
      "epoch:2770,train loss:2.301316738128662,train accuracy:0.140625\n",
      "epoch:2780,train loss:2.301251173019409,train accuracy:0.09375\n",
      "epoch:2790,train loss:2.3021841049194336,train accuracy:0.078125\n",
      "--epoch:2790,test loss:2.304563045501709,test accuracy:0.140625\n",
      "epoch:2800,train loss:2.30098819732666,train accuracy:0.15625\n",
      "@@epoch:2800,val loss:2.2980849742889404,val accuracy:0.15625\n",
      "epoch:2810,train loss:2.2998135089874268,train accuracy:0.140625\n",
      "epoch:2820,train loss:2.302067756652832,train accuracy:0.09375\n",
      "--epoch:2820,test loss:2.305480718612671,test accuracy:0.0625\n",
      "epoch:2830,train loss:2.3007097244262695,train accuracy:0.09375\n",
      "epoch:2840,train loss:2.2958743572235107,train accuracy:0.203125\n",
      "epoch:2850,train loss:2.304871082305908,train accuracy:0.09375\n",
      "--epoch:2850,test loss:2.297551155090332,test accuracy:0.125\n",
      "epoch:2860,train loss:2.299053192138672,train accuracy:0.171875\n",
      "epoch:2870,train loss:2.3018202781677246,train accuracy:0.09375\n",
      "epoch:2880,train loss:2.302459239959717,train accuracy:0.125\n",
      "--epoch:2880,test loss:2.3067119121551514,test accuracy:0.0625\n",
      "epoch:2890,train loss:2.3022074699401855,train accuracy:0.15625\n",
      "epoch:2900,train loss:2.303635597229004,train accuracy:0.078125\n",
      "@@epoch:2900,val loss:2.302182912826538,val accuracy:0.109375\n",
      "epoch:2910,train loss:2.2981698513031006,train accuracy:0.109375\n",
      "--epoch:2910,test loss:2.3014540672302246,test accuracy:0.140625\n",
      "epoch:2920,train loss:2.307070255279541,train accuracy:0.046875\n",
      "epoch:2930,train loss:2.308833599090576,train accuracy:0.015625\n",
      "epoch:2940,train loss:2.306004047393799,train accuracy:0.03125\n",
      "--epoch:2940,test loss:2.302957057952881,test accuracy:0.078125\n",
      "epoch:2950,train loss:2.2995901107788086,train accuracy:0.125\n",
      "epoch:2960,train loss:2.2990260124206543,train accuracy:0.140625\n",
      "epoch:2970,train loss:2.302126169204712,train accuracy:0.109375\n",
      "--epoch:2970,test loss:2.297417163848877,test accuracy:0.21875\n",
      "epoch:2980,train loss:2.3010482788085938,train accuracy:0.125\n",
      "epoch:2990,train loss:2.3007915019989014,train accuracy:0.140625\n",
      "epoch:3000,train loss:2.301778554916382,train accuracy:0.078125\n",
      "--epoch:3000,test loss:2.303894281387329,test accuracy:0.0625\n",
      "@@epoch:3000,val loss:2.298701524734497,val accuracy:0.171875\n",
      "epoch:3010,train loss:2.303731918334961,train accuracy:0.09375\n",
      "epoch:3020,train loss:2.3010947704315186,train accuracy:0.109375\n",
      "epoch:3030,train loss:2.301143169403076,train accuracy:0.125\n",
      "--epoch:3030,test loss:2.2975692749023438,test accuracy:0.1875\n",
      "epoch:3040,train loss:2.296661138534546,train accuracy:0.21875\n",
      "epoch:3050,train loss:2.298923969268799,train accuracy:0.1875\n",
      "epoch:3060,train loss:2.297536849975586,train accuracy:0.078125\n",
      "--epoch:3060,test loss:2.3021793365478516,test accuracy:0.109375\n",
      "epoch:3070,train loss:2.3048319816589355,train accuracy:0.03125\n",
      "epoch:3080,train loss:2.3011887073516846,train accuracy:0.15625\n",
      "epoch:3090,train loss:2.300227642059326,train accuracy:0.109375\n",
      "--epoch:3090,test loss:2.303309440612793,test accuracy:0.09375\n",
      "epoch:3100,train loss:2.310260772705078,train accuracy:0.0625\n",
      "@@epoch:3100,val loss:2.2990200519561768,val accuracy:0.203125\n",
      "epoch:3110,train loss:2.3003745079040527,train accuracy:0.109375\n",
      "epoch:3120,train loss:2.3077034950256348,train accuracy:0.078125\n",
      "--epoch:3120,test loss:2.2956149578094482,test accuracy:0.171875\n",
      "epoch:3130,train loss:2.303219795227051,train accuracy:0.15625\n",
      "epoch:3140,train loss:2.3006577491760254,train accuracy:0.109375\n",
      "epoch:3150,train loss:2.2996785640716553,train accuracy:0.15625\n",
      "--epoch:3150,test loss:2.302471399307251,test accuracy:0.140625\n",
      "epoch:3160,train loss:2.302767276763916,train accuracy:0.09375\n",
      "epoch:3170,train loss:2.2973060607910156,train accuracy:0.109375\n",
      "epoch:3180,train loss:2.2975096702575684,train accuracy:0.15625\n",
      "--epoch:3180,test loss:2.304842472076416,test accuracy:0.09375\n",
      "epoch:3190,train loss:2.303412914276123,train accuracy:0.09375\n",
      "epoch:3200,train loss:2.3010458946228027,train accuracy:0.125\n",
      "@@epoch:3200,val loss:2.2985148429870605,val accuracy:0.140625\n",
      "epoch:3210,train loss:2.297947406768799,train accuracy:0.171875\n",
      "--epoch:3210,test loss:2.296383857727051,test accuracy:0.078125\n",
      "epoch:3220,train loss:2.293295383453369,train accuracy:0.171875\n",
      "epoch:3230,train loss:2.296750068664551,train accuracy:0.109375\n",
      "epoch:3240,train loss:2.2952916622161865,train accuracy:0.09375\n",
      "--epoch:3240,test loss:2.297860622406006,test accuracy:0.109375\n",
      "epoch:3250,train loss:2.291037082672119,train accuracy:0.171875\n",
      "epoch:3260,train loss:2.303133487701416,train accuracy:0.125\n",
      "epoch:3270,train loss:2.30039644241333,train accuracy:0.125\n",
      "--epoch:3270,test loss:2.305346965789795,test accuracy:0.125\n",
      "epoch:3280,train loss:2.3021492958068848,train accuracy:0.09375\n",
      "epoch:3290,train loss:2.300891399383545,train accuracy:0.125\n",
      "epoch:3300,train loss:2.3044776916503906,train accuracy:0.0625\n",
      "--epoch:3300,test loss:2.3086233139038086,test accuracy:0.0625\n",
      "@@epoch:3300,val loss:2.292457103729248,val accuracy:0.234375\n",
      "epoch:3310,train loss:2.3051836490631104,train accuracy:0.046875\n",
      "epoch:3320,train loss:2.311507225036621,train accuracy:0.078125\n",
      "epoch:3330,train loss:2.3009109497070312,train accuracy:0.078125\n",
      "--epoch:3330,test loss:2.3054025173187256,test accuracy:0.09375\n",
      "epoch:3340,train loss:2.30686092376709,train accuracy:0.078125\n",
      "epoch:3350,train loss:2.3088998794555664,train accuracy:0.0625\n",
      "epoch:3360,train loss:2.3052382469177246,train accuracy:0.125\n",
      "--epoch:3360,test loss:2.3009085655212402,test accuracy:0.15625\n",
      "epoch:3370,train loss:2.3043346405029297,train accuracy:0.078125\n",
      "epoch:3380,train loss:2.3004815578460693,train accuracy:0.109375\n",
      "epoch:3390,train loss:2.2999777793884277,train accuracy:0.109375\n",
      "--epoch:3390,test loss:2.304089307785034,test accuracy:0.078125\n",
      "epoch:3400,train loss:2.297238826751709,train accuracy:0.140625\n",
      "@@epoch:3400,val loss:2.294053792953491,val accuracy:0.203125\n",
      "epoch:3410,train loss:2.300933361053467,train accuracy:0.078125\n",
      "epoch:3420,train loss:2.2975335121154785,train accuracy:0.140625\n",
      "--epoch:3420,test loss:2.3077526092529297,test accuracy:0.046875\n",
      "epoch:3430,train loss:2.30344557762146,train accuracy:0.109375\n",
      "epoch:3440,train loss:2.3033695220947266,train accuracy:0.109375\n",
      "epoch:3450,train loss:2.2980833053588867,train accuracy:0.109375\n",
      "--epoch:3450,test loss:2.308401584625244,test accuracy:0.046875\n",
      "epoch:3460,train loss:2.3013243675231934,train accuracy:0.09375\n",
      "epoch:3470,train loss:2.307804584503174,train accuracy:0.0625\n",
      "epoch:3480,train loss:2.3083484172821045,train accuracy:0.0625\n",
      "--epoch:3480,test loss:2.3005051612854004,test accuracy:0.125\n",
      "epoch:3490,train loss:2.2994377613067627,train accuracy:0.078125\n",
      "epoch:3500,train loss:2.2947871685028076,train accuracy:0.171875\n",
      "@@epoch:3500,val loss:2.2948269844055176,val accuracy:0.203125\n",
      "epoch:3510,train loss:2.3079683780670166,train accuracy:0.078125\n",
      "--epoch:3510,test loss:2.3027193546295166,test accuracy:0.078125\n",
      "epoch:3520,train loss:2.306539535522461,train accuracy:0.0625\n",
      "epoch:3530,train loss:2.296813488006592,train accuracy:0.109375\n",
      "epoch:3540,train loss:2.3020501136779785,train accuracy:0.125\n",
      "--epoch:3540,test loss:2.2983765602111816,test accuracy:0.109375\n",
      "epoch:3550,train loss:2.3070108890533447,train accuracy:0.0625\n",
      "epoch:3560,train loss:2.3021018505096436,train accuracy:0.078125\n",
      "epoch:3570,train loss:2.3103559017181396,train accuracy:0.046875\n",
      "--epoch:3570,test loss:2.3063087463378906,test accuracy:0.078125\n",
      "epoch:3580,train loss:2.3081536293029785,train accuracy:0.0625\n",
      "epoch:3590,train loss:2.304666757583618,train accuracy:0.09375\n",
      "epoch:3600,train loss:2.2949366569519043,train accuracy:0.15625\n",
      "--epoch:3600,test loss:2.301933526992798,test accuracy:0.15625\n",
      "@@epoch:3600,val loss:2.2949533462524414,val accuracy:0.15625\n",
      "epoch:3610,train loss:2.297332763671875,train accuracy:0.140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3620,train loss:2.3068289756774902,train accuracy:0.109375\n",
      "epoch:3630,train loss:2.3102731704711914,train accuracy:0.0625\n",
      "--epoch:3630,test loss:2.3031930923461914,test accuracy:0.109375\n",
      "epoch:3640,train loss:2.3038289546966553,train accuracy:0.078125\n",
      "epoch:3650,train loss:2.308277130126953,train accuracy:0.0625\n",
      "epoch:3660,train loss:2.298304557800293,train accuracy:0.140625\n",
      "--epoch:3660,test loss:2.299645185470581,test accuracy:0.109375\n",
      "epoch:3670,train loss:2.3101534843444824,train accuracy:0.03125\n",
      "epoch:3680,train loss:2.294032096862793,train accuracy:0.140625\n",
      "epoch:3690,train loss:2.30373477935791,train accuracy:0.078125\n",
      "--epoch:3690,test loss:2.2997806072235107,test accuracy:0.078125\n",
      "epoch:3700,train loss:2.2974982261657715,train accuracy:0.09375\n",
      "@@epoch:3700,val loss:2.2919397354125977,val accuracy:0.25\n",
      "epoch:3710,train loss:2.3076257705688477,train accuracy:0.078125\n",
      "epoch:3720,train loss:2.299354314804077,train accuracy:0.09375\n",
      "--epoch:3720,test loss:2.304774761199951,test accuracy:0.109375\n",
      "epoch:3730,train loss:2.303165912628174,train accuracy:0.109375\n",
      "epoch:3740,train loss:2.3037424087524414,train accuracy:0.09375\n",
      "epoch:3750,train loss:2.3040764331817627,train accuracy:0.0625\n",
      "--epoch:3750,test loss:2.3085813522338867,test accuracy:0.046875\n",
      "epoch:3760,train loss:2.302060127258301,train accuracy:0.125\n",
      "epoch:3770,train loss:2.3045525550842285,train accuracy:0.109375\n",
      "epoch:3780,train loss:2.2999227046966553,train accuracy:0.140625\n",
      "--epoch:3780,test loss:2.3017630577087402,test accuracy:0.09375\n",
      "epoch:3790,train loss:2.2967958450317383,train accuracy:0.109375\n",
      "epoch:3800,train loss:2.3034939765930176,train accuracy:0.09375\n",
      "@@epoch:3800,val loss:2.29657244682312,val accuracy:0.171875\n",
      "epoch:3810,train loss:2.3000073432922363,train accuracy:0.140625\n",
      "--epoch:3810,test loss:2.2991065979003906,test accuracy:0.140625\n",
      "epoch:3820,train loss:2.3000168800354004,train accuracy:0.125\n",
      "epoch:3830,train loss:2.30013370513916,train accuracy:0.140625\n",
      "epoch:3840,train loss:2.3071799278259277,train accuracy:0.0625\n",
      "--epoch:3840,test loss:2.301154136657715,test accuracy:0.125\n",
      "epoch:3850,train loss:2.3014395236968994,train accuracy:0.109375\n",
      "epoch:3860,train loss:2.3034210205078125,train accuracy:0.09375\n",
      "epoch:3870,train loss:2.298809051513672,train accuracy:0.15625\n",
      "--epoch:3870,test loss:2.3015658855438232,test accuracy:0.125\n",
      "epoch:3880,train loss:2.2980058193206787,train accuracy:0.109375\n",
      "epoch:3890,train loss:2.3063926696777344,train accuracy:0.09375\n",
      "epoch:3900,train loss:2.2997841835021973,train accuracy:0.125\n",
      "--epoch:3900,test loss:2.3032307624816895,test accuracy:0.09375\n",
      "@@epoch:3900,val loss:2.295212745666504,val accuracy:0.171875\n",
      "epoch:3910,train loss:2.3006062507629395,train accuracy:0.109375\n",
      "epoch:3920,train loss:2.303955078125,train accuracy:0.0625\n",
      "epoch:3930,train loss:2.305288314819336,train accuracy:0.078125\n",
      "--epoch:3930,test loss:2.2957775592803955,test accuracy:0.1875\n",
      "epoch:3940,train loss:2.299689769744873,train accuracy:0.125\n",
      "epoch:3950,train loss:2.3042380809783936,train accuracy:0.09375\n",
      "epoch:3960,train loss:2.2954463958740234,train accuracy:0.140625\n",
      "--epoch:3960,test loss:2.303973436355591,test accuracy:0.078125\n",
      "epoch:3970,train loss:2.303112506866455,train accuracy:0.125\n",
      "epoch:3980,train loss:2.305365562438965,train accuracy:0.078125\n",
      "epoch:3990,train loss:2.301936149597168,train accuracy:0.09375\n",
      "--epoch:3990,test loss:2.3021159172058105,test accuracy:0.078125\n",
      "epoch:4000,train loss:2.3077211380004883,train accuracy:0.078125\n",
      "@@epoch:4000,val loss:2.301438808441162,val accuracy:0.109375\n",
      "epoch:4010,train loss:2.2984039783477783,train accuracy:0.078125\n",
      "epoch:4020,train loss:2.305762767791748,train accuracy:0.0625\n",
      "--epoch:4020,test loss:2.2979297637939453,test accuracy:0.171875\n",
      "epoch:4030,train loss:2.303349494934082,train accuracy:0.078125\n",
      "epoch:4040,train loss:2.296262741088867,train accuracy:0.140625\n",
      "epoch:4050,train loss:2.2986276149749756,train accuracy:0.171875\n",
      "--epoch:4050,test loss:2.295639991760254,test accuracy:0.140625\n",
      "epoch:4060,train loss:2.299128770828247,train accuracy:0.140625\n",
      "epoch:4070,train loss:2.3064777851104736,train accuracy:0.09375\n",
      "epoch:4080,train loss:2.3075761795043945,train accuracy:0.09375\n",
      "--epoch:4080,test loss:2.3055717945098877,test accuracy:0.109375\n",
      "epoch:4090,train loss:2.311025619506836,train accuracy:0.03125\n",
      "epoch:4100,train loss:2.300663471221924,train accuracy:0.09375\n",
      "@@epoch:4100,val loss:2.2981173992156982,val accuracy:0.171875\n",
      "epoch:4110,train loss:2.299126148223877,train accuracy:0.15625\n",
      "--epoch:4110,test loss:2.3013014793395996,test accuracy:0.109375\n",
      "epoch:4120,train loss:2.302450180053711,train accuracy:0.109375\n",
      "epoch:4130,train loss:2.3029778003692627,train accuracy:0.078125\n",
      "epoch:4140,train loss:2.3051865100860596,train accuracy:0.078125\n",
      "--epoch:4140,test loss:2.3054556846618652,test accuracy:0.140625\n",
      "epoch:4150,train loss:2.306135416030884,train accuracy:0.109375\n",
      "epoch:4160,train loss:2.304297924041748,train accuracy:0.09375\n",
      "epoch:4170,train loss:2.3081772327423096,train accuracy:0.078125\n",
      "--epoch:4170,test loss:2.2964026927948,test accuracy:0.15625\n",
      "epoch:4180,train loss:2.307343006134033,train accuracy:0.09375\n",
      "epoch:4190,train loss:2.3004398345947266,train accuracy:0.140625\n",
      "epoch:4200,train loss:2.305001735687256,train accuracy:0.109375\n",
      "--epoch:4200,test loss:2.3074021339416504,test accuracy:0.09375\n",
      "@@epoch:4200,val loss:2.2861838340759277,val accuracy:0.265625\n",
      "epoch:4210,train loss:2.3018956184387207,train accuracy:0.125\n",
      "epoch:4220,train loss:2.300724506378174,train accuracy:0.046875\n",
      "epoch:4230,train loss:2.3033289909362793,train accuracy:0.09375\n",
      "--epoch:4230,test loss:2.3019449710845947,test accuracy:0.15625\n",
      "epoch:4240,train loss:2.301830530166626,train accuracy:0.15625\n",
      "epoch:4250,train loss:2.297602415084839,train accuracy:0.125\n",
      "epoch:4260,train loss:2.301954746246338,train accuracy:0.171875\n",
      "--epoch:4260,test loss:2.306428909301758,test accuracy:0.109375\n",
      "epoch:4270,train loss:2.2981836795806885,train accuracy:0.15625\n",
      "epoch:4280,train loss:2.306208610534668,train accuracy:0.0625\n",
      "epoch:4290,train loss:2.293997049331665,train accuracy:0.125\n",
      "--epoch:4290,test loss:2.299581527709961,test accuracy:0.078125\n",
      "epoch:4300,train loss:2.3097877502441406,train accuracy:0.078125\n",
      "@@epoch:4300,val loss:2.3003599643707275,val accuracy:0.09375\n",
      "epoch:4310,train loss:2.303931713104248,train accuracy:0.078125\n",
      "epoch:4320,train loss:2.2977395057678223,train accuracy:0.09375\n",
      "--epoch:4320,test loss:2.300975799560547,test accuracy:0.171875\n",
      "epoch:4330,train loss:2.2983274459838867,train accuracy:0.15625\n",
      "epoch:4340,train loss:2.299670457839966,train accuracy:0.140625\n",
      "epoch:4350,train loss:2.3020551204681396,train accuracy:0.125\n",
      "--epoch:4350,test loss:2.3012852668762207,test accuracy:0.109375\n",
      "epoch:4360,train loss:2.2950024604797363,train accuracy:0.09375\n",
      "epoch:4370,train loss:2.3022217750549316,train accuracy:0.171875\n",
      "epoch:4380,train loss:2.3017170429229736,train accuracy:0.078125\n",
      "--epoch:4380,test loss:2.3003883361816406,test accuracy:0.046875\n",
      "epoch:4390,train loss:2.3037524223327637,train accuracy:0.078125\n",
      "epoch:4400,train loss:2.3080673217773438,train accuracy:0.078125\n",
      "@@epoch:4400,val loss:2.293241500854492,val accuracy:0.234375\n",
      "epoch:4410,train loss:2.3024721145629883,train accuracy:0.15625\n",
      "--epoch:4410,test loss:2.2989094257354736,test accuracy:0.171875\n",
      "epoch:4420,train loss:2.301758289337158,train accuracy:0.078125\n",
      "epoch:4430,train loss:2.3020362854003906,train accuracy:0.140625\n",
      "epoch:4440,train loss:2.3030495643615723,train accuracy:0.109375\n",
      "--epoch:4440,test loss:2.297342300415039,test accuracy:0.09375\n",
      "epoch:4450,train loss:2.303140163421631,train accuracy:0.109375\n",
      "epoch:4460,train loss:2.305006265640259,train accuracy:0.109375\n",
      "epoch:4470,train loss:2.308286666870117,train accuracy:0.046875\n",
      "--epoch:4470,test loss:2.3043413162231445,test accuracy:0.109375\n",
      "epoch:4480,train loss:2.3066658973693848,train accuracy:0.078125\n",
      "epoch:4490,train loss:2.3028368949890137,train accuracy:0.09375\n",
      "epoch:4500,train loss:2.3048927783966064,train accuracy:0.09375\n",
      "--epoch:4500,test loss:2.299478530883789,test accuracy:0.109375\n",
      "@@epoch:4500,val loss:2.2979702949523926,val accuracy:0.171875\n",
      "epoch:4510,train loss:2.305588483810425,train accuracy:0.046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4520,train loss:2.3059239387512207,train accuracy:0.09375\n",
      "epoch:4530,train loss:2.3051443099975586,train accuracy:0.09375\n",
      "--epoch:4530,test loss:2.29986572265625,test accuracy:0.109375\n",
      "epoch:4540,train loss:2.303229331970215,train accuracy:0.09375\n",
      "epoch:4550,train loss:2.30387544631958,train accuracy:0.0625\n",
      "epoch:4560,train loss:2.2967820167541504,train accuracy:0.125\n",
      "--epoch:4560,test loss:2.303297281265259,test accuracy:0.078125\n",
      "epoch:4570,train loss:2.301499366760254,train accuracy:0.140625\n",
      "epoch:4580,train loss:2.303576707839966,train accuracy:0.125\n",
      "epoch:4590,train loss:2.2964565753936768,train accuracy:0.125\n",
      "--epoch:4590,test loss:2.296483039855957,test accuracy:0.140625\n",
      "epoch:4600,train loss:2.302952527999878,train accuracy:0.078125\n",
      "@@epoch:4600,val loss:2.293022632598877,val accuracy:0.25\n",
      "epoch:4610,train loss:2.299351692199707,train accuracy:0.140625\n",
      "epoch:4620,train loss:2.2982306480407715,train accuracy:0.125\n",
      "--epoch:4620,test loss:2.302172899246216,test accuracy:0.140625\n",
      "epoch:4630,train loss:2.3083157539367676,train accuracy:0.0625\n",
      "epoch:4640,train loss:2.3028106689453125,train accuracy:0.09375\n",
      "epoch:4650,train loss:2.3003716468811035,train accuracy:0.15625\n",
      "--epoch:4650,test loss:2.3078207969665527,test accuracy:0.03125\n",
      "epoch:4660,train loss:2.304619312286377,train accuracy:0.078125\n",
      "epoch:4670,train loss:2.3015708923339844,train accuracy:0.15625\n",
      "epoch:4680,train loss:2.3047213554382324,train accuracy:0.09375\n",
      "--epoch:4680,test loss:2.3005576133728027,test accuracy:0.140625\n",
      "epoch:4690,train loss:2.3057308197021484,train accuracy:0.09375\n",
      "epoch:4700,train loss:2.302715539932251,train accuracy:0.109375\n",
      "@@epoch:4700,val loss:2.2924644947052,val accuracy:0.203125\n",
      "epoch:4710,train loss:2.300442934036255,train accuracy:0.125\n",
      "--epoch:4710,test loss:2.3005199432373047,test accuracy:0.109375\n",
      "epoch:4720,train loss:2.2924766540527344,train accuracy:0.203125\n",
      "epoch:4730,train loss:2.304473876953125,train accuracy:0.0625\n",
      "epoch:4740,train loss:2.310302257537842,train accuracy:0.0625\n",
      "--epoch:4740,test loss:2.3052315711975098,test accuracy:0.078125\n",
      "epoch:4750,train loss:2.29801344871521,train accuracy:0.140625\n",
      "epoch:4760,train loss:2.307542562484741,train accuracy:0.078125\n",
      "epoch:4770,train loss:2.308826446533203,train accuracy:0.0625\n",
      "--epoch:4770,test loss:2.300158977508545,test accuracy:0.140625\n",
      "epoch:4780,train loss:2.3027939796447754,train accuracy:0.125\n",
      "epoch:4790,train loss:2.308225154876709,train accuracy:0.09375\n",
      "epoch:4800,train loss:2.2998409271240234,train accuracy:0.140625\n",
      "--epoch:4800,test loss:2.296492576599121,test accuracy:0.171875\n",
      "@@epoch:4800,val loss:2.2800893783569336,val accuracy:0.28125\n",
      "epoch:4810,train loss:2.306457042694092,train accuracy:0.078125\n",
      "epoch:4820,train loss:2.3008718490600586,train accuracy:0.140625\n",
      "epoch:4830,train loss:2.3028335571289062,train accuracy:0.09375\n",
      "--epoch:4830,test loss:2.298767328262329,test accuracy:0.15625\n",
      "epoch:4840,train loss:2.312269926071167,train accuracy:0.0\n",
      "epoch:4850,train loss:2.301138401031494,train accuracy:0.140625\n",
      "epoch:4860,train loss:2.3036065101623535,train accuracy:0.09375\n",
      "--epoch:4860,test loss:2.3057284355163574,test accuracy:0.078125\n",
      "epoch:4870,train loss:2.3024468421936035,train accuracy:0.09375\n",
      "epoch:4880,train loss:2.3000600337982178,train accuracy:0.140625\n",
      "epoch:4890,train loss:2.2965149879455566,train accuracy:0.140625\n",
      "--epoch:4890,test loss:2.3000826835632324,test accuracy:0.140625\n",
      "epoch:4900,train loss:2.2942895889282227,train accuracy:0.15625\n",
      "@@epoch:4900,val loss:2.292868137359619,val accuracy:0.203125\n",
      "epoch:4910,train loss:2.299748420715332,train accuracy:0.109375\n",
      "epoch:4920,train loss:2.2992005348205566,train accuracy:0.125\n",
      "--epoch:4920,test loss:2.3067564964294434,test accuracy:0.078125\n",
      "epoch:4930,train loss:2.2993385791778564,train accuracy:0.125\n",
      "epoch:4940,train loss:2.3103113174438477,train accuracy:0.03125\n",
      "epoch:4950,train loss:2.293233871459961,train accuracy:0.171875\n",
      "--epoch:4950,test loss:2.304234504699707,test accuracy:0.078125\n",
      "epoch:4960,train loss:2.3031179904937744,train accuracy:0.109375\n",
      "epoch:4970,train loss:2.2977352142333984,train accuracy:0.140625\n",
      "epoch:4980,train loss:2.2912142276763916,train accuracy:0.21875\n",
      "--epoch:4980,test loss:2.305982828140259,test accuracy:0.09375\n",
      "epoch:4990,train loss:2.302866220474243,train accuracy:0.09375\n",
      "epoch:5000,train loss:2.304248094558716,train accuracy:0.078125\n",
      "@@epoch:5000,val loss:2.2866175174713135,val accuracy:0.265625\n",
      "epoch:5010,train loss:2.306419610977173,train accuracy:0.078125\n",
      "--epoch:5010,test loss:2.2986578941345215,test accuracy:0.109375\n",
      "epoch:5020,train loss:2.296314239501953,train accuracy:0.171875\n",
      "epoch:5030,train loss:2.2984635829925537,train accuracy:0.140625\n",
      "epoch:5040,train loss:2.310892105102539,train accuracy:0.015625\n",
      "--epoch:5040,test loss:2.2957587242126465,test accuracy:0.203125\n",
      "epoch:5050,train loss:2.2987380027770996,train accuracy:0.109375\n",
      "epoch:5060,train loss:2.295311689376831,train accuracy:0.171875\n",
      "epoch:5070,train loss:2.3048746585845947,train accuracy:0.109375\n",
      "--epoch:5070,test loss:2.3028337955474854,test accuracy:0.109375\n",
      "epoch:5080,train loss:2.3008697032928467,train accuracy:0.09375\n",
      "epoch:5090,train loss:2.308441162109375,train accuracy:0.0625\n",
      "epoch:5100,train loss:2.299347400665283,train accuracy:0.140625\n",
      "--epoch:5100,test loss:2.2954578399658203,test accuracy:0.171875\n",
      "@@epoch:5100,val loss:2.2963991165161133,val accuracy:0.203125\n",
      "epoch:5110,train loss:2.304379940032959,train accuracy:0.0625\n",
      "epoch:5120,train loss:2.3032307624816895,train accuracy:0.09375\n",
      "epoch:5130,train loss:2.300924777984619,train accuracy:0.0625\n",
      "--epoch:5130,test loss:2.297429084777832,test accuracy:0.171875\n",
      "epoch:5140,train loss:2.303798198699951,train accuracy:0.09375\n",
      "epoch:5150,train loss:2.301215887069702,train accuracy:0.109375\n",
      "epoch:5160,train loss:2.301056385040283,train accuracy:0.140625\n",
      "--epoch:5160,test loss:2.299943685531616,test accuracy:0.125\n"
     ]
    }
   ],
   "source": [
    "lr_=1e-3\n",
    "batchsize=64\n",
    "for i in range(1000*6*12):\n",
    "    mask=np.random.choice(tr_data.shape[0],batchsize,replace=False)\n",
    "    x_,y_=tr_data[mask]-cumt_picmean,tr_label[mask]\n",
    "    feed_dict={X:x_,Y:y_,LR:lr_}\n",
    "    sess.run(TRAIN,feed_dict=feed_dict)\n",
    "    if i%10==0:\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_tr.add_summary(m_,i)\n",
    "        print('epoch:{},train loss:{},train accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%30==0:\n",
    "        mask=np.random.choice(te_data.shape[0],batchsize,replace=False)\n",
    "        x_,y_=te_data[mask]-cumt_picmean,te_label[mask]\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_te.add_summary(m_,i)\n",
    "        print('--epoch:{},test loss:{},test accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%100==0:\n",
    "        mask=np.random.choice(val_data.shape[0],batchsize,replace=False)\n",
    "        x_,y_=val_data[mask]-cumt_picmean,val_label[mask]\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_val.add_summary(m_,i)\n",
    "        print('@@epoch:{},val loss:{},val accuracy:{}'.format(i,loss_,acc_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型\n",
    "saver=tf.train.Saver()\n",
    "saver.save(sess,'./model_save/SqueezeNet/model_984.ckpt',global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addr=r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\Proj_iTraker\\CUMT_iTraker\\test_video\\101603\\101603_z.pkl'\n",
    "val_d=np.load(addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_d['images'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_val=cv2.resize(val_d['images'][0],(128,128))\n",
    "plt.imshow(img_val.astype('uint8'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_lab={ \n",
    "        '7':4,'8':3,'9':2,\n",
    "        '4':7,'5':6,'6':5,\n",
    "        '1':10,'2':9,'3':8,\n",
    "'0':1}\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob=tf.nn.softmax(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data=[]\n",
    "for v in range(val_d['images'].shape[0]):\n",
    "    img_=cv2.resize(val_d['images'][v],(128,128))\n",
    "    val_data.append(img_.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_data=np.array(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_d['labels'][mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_=val_data-cumt_picmean\n",
    "mean_sum=0\n",
    "for k in range(50):\n",
    "    mask=np.random.choice(range(val_data.shape[0]),128,replace=False)\n",
    "    acc_=sess.run(ACCURACY,feed_dict={X:x_[mask],Y:val_d['labels'][mask]})\n",
    "    #print(acc_)\n",
    "    mean_sum+=acc_\n",
    "print('mean accuracy:')\n",
    "print(mean_sum/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getimg(addr):\n",
    "    VGG_MEAN = [103.939, 116.779, 123.68]\n",
    "    a=imread(addr)\n",
    "    plt.imshow(a)\n",
    "    plt.show()\n",
    "    b=imresize(a-VGG_MEAN,(32,128,3)).reshape((1,32,128,3))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_dir=r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\eye_val\\441_5.jpg'\n",
    "b=getimg(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_=sess.run(prob,feed_dict={X:b,DROPOUT:1.,BN_FLAG:False,LR:1e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(p_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argmax(p_)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算所有可训练参数的数量\n",
    "sum_=0\n",
    "for s in list(tf.trainable_variables()):\n",
    "    s=str(s)\n",
    "    shape_=s[s.index('(')+1:s.index(')')].split(',')\n",
    "    s_=1\n",
    "    #print(shape_)\n",
    "    for i in shape_:\n",
    "        if i =='':continue\n",
    "        #print(i)\n",
    "        s_*=int(i)\n",
    "    sum_+=s_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
