{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用SqueezeNet结构训练cumt数据\n",
    "## 2017年11月8日"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %reload_ext autoreload\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from cumt_eye import Cumt_itraker\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from Cumt_SqueezeNet import squeezenet\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "sess=tf.InteractiveSession()\n",
    "cumt_data=np.load('cumt_data.pkl')\n",
    "index=np.arange(cumt_data['data'].shape[0])\n",
    "np.random.shuffle(index)\n",
    "data=cumt_data['data'][index]\n",
    "label=cumt_data['labels'][index]\n",
    "del cumt_data\n",
    "\n",
    "#cumt rgb 相片均值\n",
    "cumt_picmean=[103.939, 116.779, 123.68]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将图片从 （32,128,3）转换成（128,128,3），有可能会导致精度下降，非必要\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resize_img=[]\n",
    "for i in range(data.shape[0]):\n",
    "    img=data[i]+cumt_picmean\n",
    "    img=cv2.resize(img.astype('uint8'),(128,128))\n",
    "    resize_img.append(img.astype('uint8'))\n",
    "    if i%10000==0:\n",
    "        print (i)\n",
    "data=None\n",
    "resize_img=np.array(resize_img).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 常规设置占位符，训练节点等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('PlaceHolder'):\n",
    "    X=tf.placeholder(shape=[None,128,128,3],dtype=tf.float32)\n",
    "    Y=tf.placeholder(shape=[None,10],dtype=tf.float32)\n",
    "    LR=tf.placeholder(dtype=tf.float32)\n",
    "with tf.name_scope('model'):\n",
    "    model=squeezenet(X,sess)\n",
    "    y_score=model.score\n",
    "with tf.name_scope('LOSS'):\n",
    "    LOSS=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_score,labels=Y))\n",
    "    tf.summary.scalar('loss',LOSS)\n",
    "with tf.name_scope('TRAIN'):\n",
    "    TRAIN=tf.train.AdamOptimizer(LR).minimize(LOSS)\n",
    "with tf.name_scope('ACCURACY'):\n",
    "    acc_count=tf.equal(tf.arg_max(y_score,1),tf.arg_max(Y,1))\n",
    "    ACCURACY=tf.reduce_mean(tf.cast(acc_count,tf.float32))\n",
    "    tf.summary.scalar('acc',ACCURACY)\n",
    "writer_tr=tf.summary.FileWriter('./mylog/squeezenet/train')\n",
    "writer_te=tf.summary.FileWriter('./mylog/squeezenet/test',sess.graph)\n",
    "writer_val=tf.summary.FileWriter('./mylog/squeezenet/val')\n",
    "merge=tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train,test,val数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=resize_img\n",
    "index=np.arange(data.shape[0])\n",
    "np.random.shuffle(index)\n",
    "# tr_index=index[:100]\n",
    "# te_index=index[100:200]\n",
    "tr_index=index[:int(data.shape[0]*0.9)]\n",
    "te_index=index[int(data.shape[0]*0.9):]\n",
    "tr_data,tr_label=data[tr_index],label[tr_index]\n",
    "te_data,te_label=data[te_index],label[te_index]\n",
    "del data\n",
    "del label\n",
    "del resize_img\n",
    "print(tr_data.shape,te_data.shape)\n",
    "\n",
    "\n",
    "val_d=np.load('valimg1k_1109.pkl')\n",
    "val_data=[]\n",
    "for v in range(val_d['data'].shape[0]):\n",
    "    img_=cv2.resize(val_d['data'][v],(128,128))\n",
    "    val_data.append(img_)\n",
    "val_data=np.array(val_data)\n",
    "val_label=val_d['label']\n",
    "del val_d\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.extract_network_weight('squeezenet_669.pkl')\n",
    "model.init_network('squeezenet_795.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#5k each hour\n",
    "batchsize=83\n",
    "#warm up,先过拟合一个小数据集，使得网络有一个比较好的初始权值(解决网络难收敛问题)\n",
    "s_time=time.time()\n",
    "for j in range(5000):\n",
    "    mask=np.random.choice(100,batchsize,replace=False)\n",
    "    x_,y_=tr_data[mask]-cumt_picmean,tr_label[mask]\n",
    "    feed_dict={X:x_,Y:y_,LR:1e-3}\n",
    "    sess.run(TRAIN,feed_dict=feed_dict)\n",
    "    if j%10==0:\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        #writer_tr.add_summary(m_,i)\n",
    "        print('warm up,epoch:{},train loss:{},train accuracy:{}'.format(j,loss_,acc_))\n",
    "        if acc_>0.9:\n",
    "            print('warm up ready!time eslape:{}'.format(time.time()-s_time))\n",
    "            break\n",
    "\n",
    "#开始正式训练\n",
    "lr_=1e-3\n",
    "bestval_acc=0.7\n",
    "for i in range(1,1000*6*12):\n",
    "    mask=np.random.choice(tr_data.shape[0],batchsize,replace=False)\n",
    "    x_,y_=tr_data[mask]-cumt_picmean,tr_label[mask]\n",
    "    feed_dict={X:x_,Y:y_,LR:lr_}\n",
    "    sess.run(TRAIN,feed_dict=feed_dict)\n",
    "    if i%10==0:\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_tr.add_summary(m_,i)\n",
    "        print('epoch:{},train loss:{},train accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%20==0:\n",
    "        mask=np.random.choice(te_data.shape[0],batchsize,replace=False)\n",
    "        x_,y_=te_data[mask]-cumt_picmean,te_label[mask]\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_te.add_summary(m_,i)\n",
    "        print('--epoch:{},test loss:{},test accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%30==0:\n",
    "        mask=np.random.choice(val_data.shape[0],128,replace=False)\n",
    "        x_,y_=val_data[mask]-cumt_picmean,val_label[mask]\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_val.add_summary(m_,i)\n",
    "        print('@@epoch:{},val loss:{},val accuracy:{}'.format(i,loss_,acc_))\n",
    "        if acc_>bestval_acc+0.1:\n",
    "            bestval_acc=acc_\n",
    "            model_name=r'./model_save/SqueezeNet/model_'+str(int(acc_*10000))+'.ckpt'\n",
    "            saver.save(sess,model_name,global_step=i)\n",
    "            print('!!!!!model save!!!!!')\n",
    "    if i%1000==0:\n",
    "        lr_*=0.9\n",
    "        lr_=max(lr_,1e-6)\n",
    "        print('epoch:{},learning rate change:{}'.format(i,lr_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#保存模型\n",
    "saver=tf.train.Saver()\n",
    "saver.save(sess,'./model_save/SqueezeNet/model_984.ckpt',global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()\n",
    "#model_984.ckpt-34925\n",
    "#model_8437.ckpt-1020\n",
    "saver.restore(sess,r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\Proj_iTraker\\CUMT_iTraker\\model_save\\SqueezeNet\\model_984.ckpt-34925')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试在验证集上的平均正确率，并提取权值保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "acc_lis=[]\n",
    "for k in range(100):\n",
    "    mask=np.random.choice(val_data.shape[0],128,replace=False)\n",
    "    x_,y_=val_data[mask]-cumt_picmean,val_label[mask]\n",
    "    feed_dict={X:x_,Y:y_}\n",
    "    acc_=sess.run(ACCURACY,feed_dict=feed_dict)\n",
    "    acc_lis.append(acc_)\n",
    "    #print(acc_)\n",
    "print('acc mean:')\n",
    "np.mean(acc_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=list(tf.trainable_variables())\n",
    "model_d={}\n",
    "for k in n:\n",
    "    #变量名称\n",
    "    a=str(k).split(\"'\")[1][:-2]\n",
    "    print(a)\n",
    "    with tf.variable_scope('',reuse=True):\n",
    "        var=tf.get_variable(a)\n",
    "        model_d[a]=var.eval()\n",
    "        print(tf.shape(var).eval())\n",
    "\n",
    "# fp=open('squeezenet_795.pkl','wb')\n",
    "# pickle.dump(obj=model_d,file=fp)\n",
    "# fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将4X4眼部预测图像截取眼部，与标签一起保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') \n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_lab={ \n",
    "        '7':4,'8':3,'9':2,\n",
    "        '4':7,'5':6,'6':5,\n",
    "        '1':10,'2':9,'3':8,\n",
    "'0':1}\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def geteyeimg(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3,5) \n",
    "    if len(faces) !=1:\n",
    "        print(len(faces))\n",
    "        print('bad faces')\n",
    "        return None\n",
    "    for (x,y,w,h) in faces: \n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) \n",
    "            roi_gray = gray[y:y+h, x:x+w] \n",
    "            roi_color = img[y:y+h, x:x+w] \n",
    "            #检测视频中脸部的眼睛，并用vector保存眼睛的坐标、大小（用矩形表示） \n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray,scaleFactor=1.2, minNeighbors=7, minSize=(29, 29),\n",
    "                                     flags=cv2.CASCADE_SCALE_IMAGE) \n",
    "            #眼睛检测 ,对于识别比较差的情况舍弃\n",
    "            if len(eyes)!=2:\n",
    "                print(len(eyes))\n",
    "                print('bad eyes')\n",
    "                return None\n",
    "            if eyes[0][0]>eyes[1][0]:\n",
    "                ex=eyes[1][0]\n",
    "                W=eyes[0][0]-eyes[1][0]+eyes[0][2]\n",
    "            else:\n",
    "                ex=eyes[0][0]\n",
    "                W=eyes[1][0]-eyes[0][0]+eyes[1][2]\n",
    "            \n",
    "            if eyes[0][1]>eyes[1][1]:\n",
    "                ey=eyes[1][1]\n",
    "                H=eyes[0][1]-eyes[1][1]+eyes[0][3]\n",
    "            else:\n",
    "                ey=eyes[0][1]\n",
    "                H=eyes[1][1]-eyes[0][1]+eyes[1][3]\n",
    "    \n",
    "    return roi_color[ey+10:ey+H-2,ex-10:ex+W+10] if roi_color is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_dir=r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\Proj_iTraker\\Transfer_iTraker\\img4X4_val'\n",
    "img_dir=r'D:/Proj_DL/Code/Proj_EyeTraker/Proj_iTraker/CUMT_iTraker/img4x4'\n",
    "eye_lis,label_lis=[],[]\n",
    "for addr_ in os.listdir(img_dir):\n",
    "    label_id=int(addr_[:-4].split('_')[-1])\n",
    "    label_=[0]*16\n",
    "    label_[label_id]=1\n",
    "    img_=cv2.imread(os.path.join(img_dir,addr_))\n",
    "    eyes_=geteyeimg(img_)\n",
    "    if eyes_ is None:\n",
    "        continue\n",
    "    eyes_=cv2.resize(eyes_,(128,128))\n",
    "    eye_lis.append(eyes_[:,:,::-1])\n",
    "    label_lis.append(label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_lis=np.array(eye_lis)\n",
    "label_lis=np.array(label_lis)\n",
    "print(eye_lis.shape,label_lis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(eye_lis[0]);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_=np.arange(eye_lis.shape[0])\n",
    "np.random.shuffle(index_)\n",
    "eye_lis=eye_lis[index_]\n",
    "label_lis=label_lis[index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld={}\n",
    "for i,l in enumerate(label_lis):\n",
    "    index_=np.argmax(l)\n",
    "    if not index_ in ld:\n",
    "        ld[index_]=[]\n",
    "    ld[index_].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,10))\n",
    "for i in range(1,17):\n",
    "    index_=ld[i-1][0]\n",
    "    plt.subplot(4,4,i)\n",
    "    plt.imshow(eye_lis[index_])\n",
    "    plt.title(np.argmax(label_lis[index_]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp=open('img4X4_1006.pkl','wb')\n",
    "pickle.dump(obj={'data':eye_lis,'label':label_lis},file=fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#计算所有可训练参数的数量\n",
    "def get_trainable_variables_nums()\n",
    "    sum_=0\n",
    "    for s in list(tf.trainable_variables()):\n",
    "        s=str(s)\n",
    "        shape_=s[s.index('(')+1:s.index(')')].split(',')\n",
    "        s_=1\n",
    "        #print(shape_)\n",
    "        for i in shape_:\n",
    "            if i =='':continue\n",
    "            #print(i)\n",
    "            s_*=int(i)\n",
    "        sum_+=s_\n",
    "    print('trainable variables nums:{}'.format(sum_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017年11月12日10:45:39\n",
    "# 利用CUMT数据迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from cumt_eye import Cumt_itraker\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from Cumt_SqueezeNet import squeezenet\n",
    "sess=tf.InteractiveSession()\n",
    "#cumt rgb 相片均值\n",
    "cumt_picmean=[103.939, 116.779, 123.68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('PlaceHolder'):\n",
    "    X=tf.placeholder(shape=[None,128,128,3],dtype=tf.float32)\n",
    "    Y=tf.placeholder(shape=[None,16],dtype=tf.float32)\n",
    "    LR=tf.placeholder(dtype=tf.float32)\n",
    "with tf.name_scope('model'):\n",
    "    model=squeezenet(X,sess,outputclass=16)\n",
    "    y_score=model.score\n",
    "with tf.name_scope('LOSS'):\n",
    "    LOSS=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_score,labels=Y))\n",
    "    tf.summary.scalar('loss',LOSS)\n",
    "with tf.name_scope('TRAIN'):\n",
    "    TRAIN=tf.train.AdamOptimizer(LR).minimize(LOSS)\n",
    "with tf.name_scope('ACCURACY'):\n",
    "    acc_count=tf.equal(tf.arg_max(y_score,1),tf.arg_max(Y,1))\n",
    "    ACCURACY=tf.reduce_mean(tf.cast(acc_count,tf.float32))\n",
    "    tf.summary.scalar('acc',ACCURACY)\n",
    "writer_tr=tf.summary.FileWriter('./mylog/squeezenet_1k_zero/train')\n",
    "writer_te=tf.summary.FileWriter('./mylog/squeezenet_1k_zero/test')\n",
    "writer_val=tf.summary.FileWriter('./mylog/squeezenet_1k_zero/val')\n",
    "merge=tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#加载cumt训练出来的权值作为初始值\n",
    "model.init_network('squeezenet_795.pkl',skip_layer=['tail/conv/biases','tail/conv/weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载训练好的权值\n",
    "model.init_network('squeeze1k4x4_9688.pkl',skip_layer=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#从 0 开始训练网络\n",
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.load('img4X4_1006.pkl')\n",
    "index_=np.arange(d['data'].shape[0])\n",
    "np.random.shuffle(index_)\n",
    "tr_index=index_[:int(d['data'].shape[0]*0.8)]\n",
    "te_index=index_[int(d['data'].shape[0]*0.8):]\n",
    "tr_data,tr_label=d['data'][tr_index],d['label'][tr_index]\n",
    "te_data,te_label=d['data'][te_index],d['label'][te_index]\n",
    "print(tr_data.shape,te_data.shape)\n",
    "del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#开始正式训练\n",
    "batchsize=64\n",
    "lr_=1e-3\n",
    "bestval_acc=0.7\n",
    "for i in range(1,1000*6*12):\n",
    "    mask=np.random.choice(tr_data.shape[0],batchsize,replace=False)\n",
    "    x_,y_=tr_data[mask]-cumt_picmean,tr_label[mask]\n",
    "    feed_dict={X:x_,Y:y_,LR:lr_}\n",
    "    sess.run(TRAIN,feed_dict=feed_dict)\n",
    "    if i%10==0:\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_tr.add_summary(m_,i)\n",
    "        print('epoch:{},train loss:{},train accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%20==0:\n",
    "        mask=np.random.choice(te_data.shape[0],batchsize,replace=False)\n",
    "        x_,y_=te_data[mask]-cumt_picmean,te_label[mask]\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_te.add_summary(m_,i)\n",
    "        print('--epoch:{},test loss:{},test accuracy:{}'.format(i,loss_,acc_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试平均测试集ACC\n",
    "acc_lis=[]\n",
    "for j in range(10):\n",
    "    mask=np.random.choice(te_data.shape[0],100,replace=False)\n",
    "    x_,y_=te_data[mask]-cumt_picmean,te_label[mask]\n",
    "    feed_dict={X:x_,Y:y_}\n",
    "    acc_=sess.run(ACCURACY,feed_dict=feed_dict)\n",
    "    acc_lis.append(acc_)\n",
    "print(np.mean(acc_lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save_network_weight('squeeze1k4x4_9688.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017年11月12日17:41:38\n",
    "# 在现实环境中实测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building graph\n",
      "loading weight file:squeeze1k4x4_9688.pkl\n",
      "network init done!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from cumt_eye import Cumt_itraker\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from Cumt_SqueezeNet import squeezenet\n",
    "import time\n",
    "sess=tf.InteractiveSession()\n",
    "#cumt rgb 相片均值\n",
    "cumt_picmean=[103.939, 116.779, 123.68]\n",
    "X=tf.placeholder(shape=[None,128,128,3],dtype=tf.float32)\n",
    "model=squeezenet(X,sess,outputclass=16)\n",
    "model.init_network('squeeze1k4x4_9688.pkl',skip_layer=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') \n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')  \n",
    "def drawline(img_,line_w=1,line_color=(0,0,0),wandh_num=4):\n",
    "        '''\n",
    "        在图片上格子\n",
    "        :param line_w: 线宽\n",
    "        :param line_color: 线颜色\n",
    "        :param wandh_num:  长宽线的数量\n",
    "        :return:  无\n",
    "        '''\n",
    "        h,w=img_.shape[0],img_.shape[1]\n",
    "        w_num,h_num=wandh_num,wandh_num\n",
    "        h_,w_=h//h_num,w//w_num\n",
    "\n",
    "        # 竖线 (w,h)\n",
    "        for i in range(1,w_num):\n",
    "            #print(i)\n",
    "            cv2.line(img_,(w_*i,0),(w_*i,h),line_color,line_w)\n",
    "        # 横线\n",
    "        for i in range(1,h_num):\n",
    "            cv2.line(img_,(0,h_*i),(w,h_*i),line_color,line_w)\n",
    "        return img_\n",
    "\n",
    "def drawblock(img,line_num,block_id=0,blockcolor=(46,218,255),blockwideth=5,show_rec=True):\n",
    "        '''\n",
    "        选定九宫格，在这个格子上填充矩形表示选定这个格子\n",
    "        :param img_: 图片\n",
    "        :param block: 九宫格序号 0-15\n",
    "        :param blockcolor: 矩形框颜色\n",
    "        :param blockwideth: 框的宽度\n",
    "        :return:\n",
    "        '''\n",
    "        h,w=img.shape[0],img.shape[1]\n",
    "        w_line,h_line=line_num,line_num\n",
    "        h_,w_=h//h_line,w//w_line\n",
    "        cor_h=block_id//line_num\n",
    "        cor_w=block_id%line_num\n",
    "        sx,sy=cor_w*w_,cor_h*h_\n",
    "        \n",
    "        if show_rec:\n",
    "        #将整个矩形填充为其他颜色\n",
    "            img[sy:sy+h_,sx:sx+w_,:]=blockcolor\n",
    "        else:\n",
    "            roi_=img[sy:sy+h_,sx:sx+w_]\n",
    "            cv2.circle(roi_,(roi_.shape[1]//2,roi_.shape[0]//2), 10, (255,128,120), -1)\n",
    "       \n",
    "        return img\n",
    "def geteyeimg(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3,5) \n",
    "    if len(faces) !=1:\n",
    "        print(len(faces))\n",
    "        print('bad faces')\n",
    "        return None\n",
    "    for (x,y,w,h) in faces: \n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) \n",
    "            roi_gray = gray[y:y+h, x:x+w] \n",
    "            roi_color = img[y:y+h, x:x+w] \n",
    "            #检测视频中脸部的眼睛，并用vector保存眼睛的坐标、大小（用矩形表示） \n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray,scaleFactor=1.2, minNeighbors=7, minSize=(29, 29),\n",
    "                                     flags=cv2.CASCADE_SCALE_IMAGE) \n",
    "            #眼睛检测 ,对于识别比较差的情况舍弃\n",
    "            if len(eyes)!=2:\n",
    "                print(len(eyes))\n",
    "                print('bad eyes')\n",
    "                return None\n",
    "            if eyes[0][0]>eyes[1][0]:\n",
    "                ex=eyes[1][0]\n",
    "                W=eyes[0][0]-eyes[1][0]+eyes[0][2]\n",
    "            else:\n",
    "                ex=eyes[0][0]\n",
    "                W=eyes[1][0]-eyes[0][0]+eyes[1][2]\n",
    "            \n",
    "            if eyes[0][1]>eyes[1][1]:\n",
    "                ey=eyes[1][1]\n",
    "                H=eyes[0][1]-eyes[1][1]+eyes[0][3]\n",
    "            else:\n",
    "                ey=eyes[0][1]\n",
    "                H=eyes[1][1]-eyes[0][1]+eyes[1][3]\n",
    "    \n",
    "    return roi_color[ey+10:ey+H-2,ex-10:ex+W+10] if roi_color is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试网络是否能正常运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "_,frame=cap.read()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "0\n",
      "bad faces\n",
      "23.5 ms ± 621 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "e=model.get_eyeimg(frame,pre_process=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "e=model.get_eyeimg(frame)\n",
    "asw_prob=model.predict(X_tensor=X,eyes_images=e)\n",
    "\n",
    "#print(np.argmax(asw_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "_,frame=cap.read()\n",
    "cap.release()\n",
    "e=geteyeimg(frame)\n",
    "if e is None:\n",
    "    print('bad pic')\n",
    "else:\n",
    "    e=cv2.resize(e,(128,128))[:,:,::-1]\n",
    "asw_prob=model.predict(X_tensor=X,eyes_images=e.reshape(1,128,128,3))\n",
    "# test_score=sess.run(y_score,feed_dict={X:e.reshape(1,128,128,3)})\n",
    "print(np.argmax(asw_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 显示实时图像，帮助调整姿态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,fram=cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow('cam',fram)\n",
    "        if cv2.waitKey(30)&0xff==27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始正式的预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1253516674041748 sec per frame\n",
      "0.22356963157653809 sec per frame\n",
      "0.15644121170043945 sec per frame\n",
      "0.13533282279968262 sec per frame\n",
      "0.1484224796295166 sec per frame\n",
      "0.13533234596252441 sec per frame\n",
      "0.14037489891052246 sec per frame\n",
      "0.14341068267822266 sec per frame\n",
      "0.13234543800354004 sec per frame\n",
      "0.13834023475646973 sec per frame\n",
      "0.14338135719299316 sec per frame\n",
      "0.14037442207336426 sec per frame\n",
      "0.14039969444274902 sec per frame\n",
      "0.22757887840270996 sec per frame\n",
      "0.14240598678588867 sec per frame\n",
      "0.14937067031860352 sec per frame\n",
      "0.13638877868652344 sec per frame\n",
      "0.14134931564331055 sec per frame\n",
      "0.14040017127990723 sec per frame\n",
      "0.13936829566955566 sec per frame\n",
      "0.14135122299194336 sec per frame\n",
      "0.14942598342895508 sec per frame\n",
      "0.1463627815246582 sec per frame\n",
      "0.14335036277770996 sec per frame\n",
      "0.1414046287536621 sec per frame\n",
      "0.1524055004119873 sec per frame\n",
      "0.14037203788757324 sec per frame\n",
      "0.14836764335632324 sec per frame\n",
      "0.1313490867614746 sec per frame\n",
      "0.13939881324768066 sec per frame\n",
      "0.14137482643127441 sec per frame\n",
      "0.1504054069519043 sec per frame\n",
      "0.12934017181396484 sec per frame\n",
      "0.1433544158935547 sec per frame\n",
      "0.13636302947998047 sec per frame\n",
      "0.20956039428710938 sec per frame\n",
      "0.13635969161987305 sec per frame\n",
      "0.15641498565673828 sec per frame\n",
      "0.14438486099243164 sec per frame\n",
      "0.13636183738708496 sec per frame\n",
      "0.13638997077941895 sec per frame\n",
      "0.12731289863586426 sec per frame\n",
      "0.13839960098266602 sec per frame\n",
      "0.20952439308166504 sec per frame\n",
      "0.13435983657836914 sec per frame\n",
      "0.13636040687561035 sec per frame\n",
      "0.12837457656860352 sec per frame\n",
      "0.12933754920959473 sec per frame\n",
      "0.13937091827392578 sec per frame\n",
      "0.15438461303710938 sec per frame\n",
      "0.13836669921875 sec per frame\n",
      "0.13037371635437012 sec per frame\n",
      "0.14034700393676758 sec per frame\n",
      "0.14240527153015137 sec per frame\n",
      "0.1383218765258789 sec per frame\n",
      "0.13736414909362793 sec per frame\n",
      "0.1454148292541504 sec per frame\n",
      "0.1383671760559082 sec per frame\n",
      "0.13834428787231445 sec per frame\n",
      "0.1413736343383789 sec per frame\n",
      "0.13736486434936523 sec per frame\n",
      "0.2316434383392334 sec per frame\n",
      "0.13533258438110352 sec per frame\n",
      "0.14037394523620605 sec per frame\n",
      "0.1323533058166504 sec per frame\n",
      "0.1273632049560547 sec per frame\n",
      "0.14338350296020508 sec per frame\n",
      "0.13833999633789062 sec per frame\n",
      "0.14040565490722656 sec per frame\n",
      "0.14237427711486816 sec per frame\n",
      "0.13633465766906738 sec per frame\n",
      "0.13034820556640625 sec per frame\n",
      "0.1353590488433838 sec per frame\n",
      "0.16142964363098145 sec per frame\n",
      "0.14438509941101074 sec per frame\n",
      "0.13237810134887695 sec per frame\n",
      "0.14338040351867676 sec per frame\n",
      "0.14839649200439453 sec per frame\n",
      "0.1293485164642334 sec per frame\n",
      "0.1413438320159912 sec per frame\n",
      "0.14040565490722656 sec per frame\n",
      "0.1453564167022705 sec per frame\n",
      "0.13335227966308594 sec per frame\n",
      "0.128373384475708 sec per frame\n",
      "0.14337682723999023 sec per frame\n",
      "0.23763322830200195 sec per frame\n",
      "0.13332724571228027 sec per frame\n",
      "0.1423790454864502 sec per frame\n",
      "0.1373453140258789 sec per frame\n",
      "0.1444110870361328 sec per frame\n",
      "0.14535951614379883 sec per frame\n",
      "0.13638973236083984 sec per frame\n",
      "0.1393446922302246 sec per frame\n",
      "0.14642047882080078 sec per frame\n",
      "0.13332414627075195 sec per frame\n",
      "0.14438343048095703 sec per frame\n",
      "0.14137482643127441 sec per frame\n",
      "0.16143441200256348 sec per frame\n",
      "0.13237333297729492 sec per frame\n",
      "0.21554851531982422 sec per frame\n",
      "0.14541244506835938 sec per frame\n",
      "0.1363363265991211 sec per frame\n",
      "0.14641618728637695 sec per frame\n",
      "0.1363368034362793 sec per frame\n",
      "0.14137601852416992 sec per frame\n",
      "0.1453852653503418 sec per frame\n",
      "0.1393733024597168 sec per frame\n",
      "0.14438223838806152 sec per frame\n",
      "0.13135099411010742 sec per frame\n",
      "0.16443729400634766 sec per frame\n",
      "0.13639283180236816 sec per frame\n",
      "0.1453561782836914 sec per frame\n",
      "0.13034534454345703 sec per frame\n",
      "0.14641666412353516 sec per frame\n",
      "0.13435649871826172 sec per frame\n",
      "0.13132333755493164 sec per frame\n",
      "0.14039945602416992 sec per frame\n",
      "0.13636326789855957 sec per frame\n",
      "0.14235210418701172 sec per frame\n",
      "0.14240622520446777 sec per frame\n",
      "0.13432908058166504 sec per frame\n",
      "0.156416654586792 sec per frame\n",
      "0.12536287307739258 sec per frame\n",
      "0.21353626251220703 sec per frame\n",
      "0.128373384475708 sec per frame\n",
      "0.12633085250854492 sec per frame\n",
      "0.1393451690673828 sec per frame\n",
      "0.1303730010986328 sec per frame\n",
      "0.13132166862487793 sec per frame\n",
      "0.13538765907287598 sec per frame\n",
      "0.1353607177734375 sec per frame\n",
      "0.142378568649292 sec per frame\n",
      "0.1463620662689209 sec per frame\n",
      "0.16543984413146973 sec per frame\n",
      "0.14140748977661133 sec per frame\n",
      "0.14134573936462402 sec per frame\n",
      "0.13937044143676758 sec per frame\n",
      "0.1424093246459961 sec per frame\n",
      "0.13736295700073242 sec per frame\n",
      "0.14438390731811523 sec per frame\n",
      "0.1383659839630127 sec per frame\n",
      "0.14736557006835938 sec per frame\n",
      "0.14037346839904785 sec per frame\n",
      "0.13636302947998047 sec per frame\n",
      "0.14340829849243164 sec per frame\n",
      "0.1563889980316162 sec per frame\n",
      "0.1383953094482422 sec per frame\n",
      "0.1383686065673828 sec per frame\n",
      "0.1433548927307129 sec per frame\n",
      "0.1424095630645752 sec per frame\n",
      "0.13232183456420898 sec per frame\n",
      "0.1423788070678711 sec per frame\n",
      "0.20858407020568848 sec per frame\n",
      "0.13633084297180176 sec per frame\n",
      "0.13939809799194336 sec per frame\n",
      "0.1393444538116455 sec per frame\n",
      "0.14137482643127441 sec per frame\n",
      "0.16042733192443848 sec per frame\n",
      "0.1343843936920166 sec per frame\n",
      "0.14134883880615234 sec per frame\n",
      "0.14340972900390625 sec per frame\n",
      "0.13834071159362793 sec per frame\n",
      "0.1414024829864502 sec per frame\n",
      "0.13736653327941895 sec per frame\n",
      "0.14535880088806152 sec per frame\n",
      "0.13639020919799805 sec per frame\n",
      "0.14536142349243164 sec per frame\n",
      "0.13739228248596191 sec per frame\n",
      "0.1423501968383789 sec per frame\n",
      "0.24067211151123047 sec per frame\n",
      "0.12730813026428223 sec per frame\n",
      "0.1313767433166504 sec per frame\n",
      "0.13636207580566406 sec per frame\n",
      "0.14037346839904785 sec per frame\n",
      "0.14338183403015137 sec per frame\n",
      "0.13733983039855957 sec per frame\n",
      "0.14140033721923828 sec per frame\n",
      "0.14137673377990723 sec per frame\n",
      "0.14034652709960938 sec per frame\n",
      "0.13939857482910156 sec per frame\n",
      "0.14134788513183594 sec per frame\n",
      "0.15944957733154297 sec per frame\n",
      "0.13734197616577148 sec per frame\n",
      "0.14037275314331055 sec per frame\n",
      "0.14441609382629395 sec per frame\n",
      "0.13733291625976562 sec per frame\n",
      "3\n",
      "bad eyes\n",
      "0.21657514572143555 sec per frame\n",
      "0.14639043807983398 sec per frame\n",
      "0.1393883228302002 sec per frame\n",
      "0.1393733024597168 sec per frame\n",
      "0.13936567306518555 sec per frame\n",
      "0.13335514068603516 sec per frame\n",
      "0.2145700454711914 sec per frame\n",
      "0.1533827781677246 sec per frame\n",
      "0.13839459419250488 sec per frame\n",
      "0.1423783302307129 sec per frame\n",
      "accuracy:0.5482233502538071\n",
      "out\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fps=10\n",
    "fsize_desk=(1920,1080)\n",
    "# save video\n",
    "video_d=cv2.VideoWriter('demo_desk.flv',cv2.VideoWriter_fourcc('F','L','V','1'),fps,fsize_desk)\n",
    "cap=cv2.VideoCapture(0)\n",
    "s_time=time.time()\n",
    "tar_img=cv2.imread('test.jpg')\n",
    "#设置window 为全屏\n",
    "cv2.namedWindow('Capture001',cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Capture001', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "s_time=time.time()\n",
    "random_show=np.random.randint(0,16,1)[0]\n",
    "\n",
    "#每N帧输出平均预测\n",
    "sum_score=[]\n",
    "sum_counter=0\n",
    "block_id=0\n",
    "ret_counter=0\n",
    "right_frame_counter=0\n",
    "while True:\n",
    "    ret,fram=cap.read()\n",
    "    if ret:\n",
    "        ret_counter+=1\n",
    "        #显示 内窥镜图像\n",
    "        tar_img=cv2.imread('test.jpg')\n",
    "        tar_img=drawline(tar_img,wandh_num=4)\n",
    "        #每30帧换点\n",
    "        if ret_counter%22==0:\n",
    "            random_show=np.random.randint(0,16,1)[0]\n",
    "\n",
    "        tar_img=drawblock(tar_img,line_num=4,block_id=random_show)\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "\n",
    "        #预测注视方向\n",
    "#             face_op=geteyeimg(fram)\n",
    "#             if face_op is None:\n",
    "#                 continue\n",
    "#         e=cv2.resize(face_op,(128,128))[:,:,::-1]\n",
    "#         y_guess=model.predict(X_tensor=X,eyes_images=e.reshape(1,128,128,3))[0]\n",
    "        e=model.get_eyeimg(fram)\n",
    "        if e is None:\n",
    "            continue\n",
    "        y_guess=model.predict(X_tensor=X,eyes_images=e)[0]\n",
    "\n",
    "        #平均每 N 帧的预测分数\n",
    "        block_id=np.argmax(y_guess)-1\n",
    "#         sum_counter+=1\n",
    "#         sum_score.append(y_guess)\n",
    "#         if sum_counter==5:\n",
    "#             sum_score=np.asarray(sum_score).reshape((-1,16))\n",
    "#             mean_score=np.mean(sum_score,0)\n",
    "#             block_id=np.argmax(mean_score)-1\n",
    "#             sum_score=[]\n",
    "#             sum_counter=0\n",
    "#             print(block_id)\n",
    "#             if block_id<0:block_id=0\n",
    "#             elif block_id>15:block_id=15\n",
    "\n",
    "        if block_id==random_show:\n",
    "             right_frame_counter+=1\n",
    "        tar_img=drawblock(tar_img,line_num=4,block_id=block_id,show_rec=False)\n",
    "        v_img=tar_img.copy()\n",
    "        fram=cv2.resize(fram,(300,300))\n",
    "        v_img[:300,-300:]=fram\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "\n",
    "\n",
    "        print('{} sec per frame'.format(time.time()-s_time))\n",
    "        s_time=time.time()\n",
    "        video_d.write(v_img)\n",
    "        if cv2.waitKey(1)&0xff==27:\n",
    "            print('accuracy:{}'.format(right_frame_counter/ret_counter))\n",
    "            print('out')\n",
    "            break\n",
    "    if (time.time()-s_time)>60*5:\n",
    "        print('time out')\n",
    "        break\n",
    "video_d.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_d.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
