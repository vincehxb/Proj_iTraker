{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用SqueezeNet结构训练cumt数据\n",
    "## 2017年11月8日"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %reload_ext autoreload\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from cumt_eye import Cumt_itraker\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from Cumt_SqueezeNet import squeezenet\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "sess=tf.InteractiveSession()\n",
    "cumt_data=np.load('cumt_data.pkl')\n",
    "index=np.arange(cumt_data['data'].shape[0])\n",
    "np.random.shuffle(index)\n",
    "data=cumt_data['data'][index]\n",
    "label=cumt_data['labels'][index]\n",
    "del cumt_data\n",
    "\n",
    "#cumt rgb 相片均值\n",
    "cumt_picmean=[103.939, 116.779, 123.68]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将图片从 （32,128,3）转换成（128,128,3），有可能会导致精度下降，非必要\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resize_img=[]\n",
    "for i in range(data.shape[0]):\n",
    "    img=data[i]+cumt_picmean\n",
    "    img=cv2.resize(img.astype('uint8'),(128,128))\n",
    "    resize_img.append(img.astype('uint8'))\n",
    "    if i%10000==0:\n",
    "        print (i)\n",
    "data=None\n",
    "resize_img=np.array(resize_img).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 常规设置占位符，训练节点等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('PlaceHolder'):\n",
    "    X=tf.placeholder(shape=[None,128,128,3],dtype=tf.float32)\n",
    "    Y=tf.placeholder(shape=[None,10],dtype=tf.float32)\n",
    "    LR=tf.placeholder(dtype=tf.float32)\n",
    "with tf.name_scope('model'):\n",
    "    model=squeezenet(X,sess)\n",
    "    y_score=model.score\n",
    "with tf.name_scope('LOSS'):\n",
    "    LOSS=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_score,labels=Y))\n",
    "    tf.summary.scalar('loss',LOSS)\n",
    "with tf.name_scope('TRAIN'):\n",
    "    TRAIN=tf.train.AdamOptimizer(LR).minimize(LOSS)\n",
    "with tf.name_scope('ACCURACY'):\n",
    "    acc_count=tf.equal(tf.arg_max(y_score,1),tf.arg_max(Y,1))\n",
    "    ACCURACY=tf.reduce_mean(tf.cast(acc_count,tf.float32))\n",
    "    tf.summary.scalar('acc',ACCURACY)\n",
    "writer_tr=tf.summary.FileWriter('./mylog/squeezenet/train')\n",
    "writer_te=tf.summary.FileWriter('./mylog/squeezenet/test',sess.graph)\n",
    "writer_val=tf.summary.FileWriter('./mylog/squeezenet/val')\n",
    "merge=tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train,test,val数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=resize_img\n",
    "index=np.arange(data.shape[0])\n",
    "np.random.shuffle(index)\n",
    "# tr_index=index[:100]\n",
    "# te_index=index[100:200]\n",
    "tr_index=index[:int(data.shape[0]*0.9)]\n",
    "te_index=index[int(data.shape[0]*0.9):]\n",
    "tr_data,tr_label=data[tr_index],label[tr_index]\n",
    "te_data,te_label=data[te_index],label[te_index]\n",
    "del data\n",
    "del label\n",
    "del resize_img\n",
    "print(tr_data.shape,te_data.shape)\n",
    "\n",
    "\n",
    "val_d=np.load('valimg1k_1109.pkl')\n",
    "val_data=[]\n",
    "for v in range(val_d['data'].shape[0]):\n",
    "    img_=cv2.resize(val_d['data'][v],(128,128))\n",
    "    val_data.append(img_)\n",
    "val_data=np.array(val_data)\n",
    "val_label=val_d['label']\n",
    "del val_d\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.extract_network_weight('squeezenet_669.pkl')\n",
    "model.init_network('squeezenet_795.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#5k each hour\n",
    "batchsize=83\n",
    "#warm up,先过拟合一个小数据集，使得网络有一个比较好的初始权值(解决网络难收敛问题)\n",
    "s_time=time.time()\n",
    "for j in range(5000):\n",
    "    mask=np.random.choice(100,batchsize,replace=False)\n",
    "    x_,y_=tr_data[mask]-cumt_picmean,tr_label[mask]\n",
    "    feed_dict={X:x_,Y:y_,LR:1e-3}\n",
    "    sess.run(TRAIN,feed_dict=feed_dict)\n",
    "    if j%10==0:\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        #writer_tr.add_summary(m_,i)\n",
    "        print('warm up,epoch:{},train loss:{},train accuracy:{}'.format(j,loss_,acc_))\n",
    "        if acc_>0.9:\n",
    "            print('warm up ready!time eslape:{}'.format(time.time()-s_time))\n",
    "            break\n",
    "\n",
    "#开始正式训练\n",
    "lr_=1e-3\n",
    "bestval_acc=0.7\n",
    "for i in range(1,1000*6*12):\n",
    "    mask=np.random.choice(tr_data.shape[0],batchsize,replace=False)\n",
    "    x_,y_=tr_data[mask]-cumt_picmean,tr_label[mask]\n",
    "    feed_dict={X:x_,Y:y_,LR:lr_}\n",
    "    sess.run(TRAIN,feed_dict=feed_dict)\n",
    "    if i%10==0:\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_tr.add_summary(m_,i)\n",
    "        print('epoch:{},train loss:{},train accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%20==0:\n",
    "        mask=np.random.choice(te_data.shape[0],batchsize,replace=False)\n",
    "        x_,y_=te_data[mask]-cumt_picmean,te_label[mask]\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_te.add_summary(m_,i)\n",
    "        print('--epoch:{},test loss:{},test accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%30==0:\n",
    "        mask=np.random.choice(val_data.shape[0],128,replace=False)\n",
    "        x_,y_=val_data[mask]-cumt_picmean,val_label[mask]\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_val.add_summary(m_,i)\n",
    "        print('@@epoch:{},val loss:{},val accuracy:{}'.format(i,loss_,acc_))\n",
    "        if acc_>bestval_acc+0.1:\n",
    "            bestval_acc=acc_\n",
    "            model_name=r'./model_save/SqueezeNet/model_'+str(int(acc_*10000))+'.ckpt'\n",
    "            saver.save(sess,model_name,global_step=i)\n",
    "            print('!!!!!model save!!!!!')\n",
    "    if i%1000==0:\n",
    "        lr_*=0.9\n",
    "        lr_=max(lr_,1e-6)\n",
    "        print('epoch:{},learning rate change:{}'.format(i,lr_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#保存模型\n",
    "saver=tf.train.Saver()\n",
    "saver.save(sess,'./model_save/SqueezeNet/model_984.ckpt',global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()\n",
    "#model_984.ckpt-34925\n",
    "#model_8437.ckpt-1020\n",
    "saver.restore(sess,r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\Proj_iTraker\\CUMT_iTraker\\model_save\\SqueezeNet\\model_984.ckpt-34925')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试在验证集上的平均正确率，并提取权值保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "acc_lis=[]\n",
    "for k in range(100):\n",
    "    mask=np.random.choice(val_data.shape[0],128,replace=False)\n",
    "    x_,y_=val_data[mask]-cumt_picmean,val_label[mask]\n",
    "    feed_dict={X:x_,Y:y_}\n",
    "    acc_=sess.run(ACCURACY,feed_dict=feed_dict)\n",
    "    acc_lis.append(acc_)\n",
    "    #print(acc_)\n",
    "print('acc mean:')\n",
    "np.mean(acc_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=list(tf.trainable_variables())\n",
    "model_d={}\n",
    "for k in n:\n",
    "    #变量名称\n",
    "    a=str(k).split(\"'\")[1][:-2]\n",
    "    print(a)\n",
    "    with tf.variable_scope('',reuse=True):\n",
    "        var=tf.get_variable(a)\n",
    "        model_d[a]=var.eval()\n",
    "        print(tf.shape(var).eval())\n",
    "\n",
    "# fp=open('squeezenet_795.pkl','wb')\n",
    "# pickle.dump(obj=model_d,file=fp)\n",
    "# fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将4X4眼部预测图像截取眼部，与标签一起保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') \n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_lab={ \n",
    "        '7':4,'8':3,'9':2,\n",
    "        '4':7,'5':6,'6':5,\n",
    "        '1':10,'2':9,'3':8,\n",
    "'0':1}\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def geteyeimg(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3,5) \n",
    "    if len(faces) !=1:\n",
    "        print(len(faces))\n",
    "        print('bad faces')\n",
    "        return None\n",
    "    for (x,y,w,h) in faces: \n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) \n",
    "            roi_gray = gray[y:y+h, x:x+w] \n",
    "            roi_color = img[y:y+h, x:x+w] \n",
    "            #检测视频中脸部的眼睛，并用vector保存眼睛的坐标、大小（用矩形表示） \n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray,scaleFactor=1.2, minNeighbors=7, minSize=(29, 29),\n",
    "                                     flags=cv2.CASCADE_SCALE_IMAGE) \n",
    "            #眼睛检测 ,对于识别比较差的情况舍弃\n",
    "            if len(eyes)!=2:\n",
    "                print(len(eyes))\n",
    "                print('bad eyes')\n",
    "                return None\n",
    "            if eyes[0][0]>eyes[1][0]:\n",
    "                ex=eyes[1][0]\n",
    "                W=eyes[0][0]-eyes[1][0]+eyes[0][2]\n",
    "            else:\n",
    "                ex=eyes[0][0]\n",
    "                W=eyes[1][0]-eyes[0][0]+eyes[1][2]\n",
    "            \n",
    "            if eyes[0][1]>eyes[1][1]:\n",
    "                ey=eyes[1][1]\n",
    "                H=eyes[0][1]-eyes[1][1]+eyes[0][3]\n",
    "            else:\n",
    "                ey=eyes[0][1]\n",
    "                H=eyes[1][1]-eyes[0][1]+eyes[1][3]\n",
    "    \n",
    "    return roi_color[ey+10:ey+H-2,ex-10:ex+W+10] if roi_color is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_dir=r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\Proj_iTraker\\Transfer_iTraker\\img4X4_val'\n",
    "img_dir=r'D:/Proj_DL/Code/Proj_EyeTraker/Proj_iTraker/CUMT_iTraker/img4x4'\n",
    "eye_lis,label_lis=[],[]\n",
    "for addr_ in os.listdir(img_dir):\n",
    "    label_id=int(addr_[:-4].split('_')[-1])\n",
    "    label_=[0]*16\n",
    "    label_[label_id]=1\n",
    "    img_=cv2.imread(os.path.join(img_dir,addr_))\n",
    "    eyes_=geteyeimg(img_)\n",
    "    if eyes_ is None:\n",
    "        continue\n",
    "    eyes_=cv2.resize(eyes_,(128,128))\n",
    "    eye_lis.append(eyes_[:,:,::-1])\n",
    "    label_lis.append(label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_lis=np.array(eye_lis)\n",
    "label_lis=np.array(label_lis)\n",
    "print(eye_lis.shape,label_lis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(eye_lis[0]);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_=np.arange(eye_lis.shape[0])\n",
    "np.random.shuffle(index_)\n",
    "eye_lis=eye_lis[index_]\n",
    "label_lis=label_lis[index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld={}\n",
    "for i,l in enumerate(label_lis):\n",
    "    index_=np.argmax(l)\n",
    "    if not index_ in ld:\n",
    "        ld[index_]=[]\n",
    "    ld[index_].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,10))\n",
    "for i in range(1,17):\n",
    "    index_=ld[i-1][0]\n",
    "    plt.subplot(4,4,i)\n",
    "    plt.imshow(eye_lis[index_])\n",
    "    plt.title(np.argmax(label_lis[index_]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp=open('img4X4_1006.pkl','wb')\n",
    "pickle.dump(obj={'data':eye_lis,'label':label_lis},file=fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#计算所有可训练参数的数量\n",
    "def get_trainable_variables_nums()\n",
    "    sum_=0\n",
    "    for s in list(tf.trainable_variables()):\n",
    "        s=str(s)\n",
    "        shape_=s[s.index('(')+1:s.index(')')].split(',')\n",
    "        s_=1\n",
    "        #print(shape_)\n",
    "        for i in shape_:\n",
    "            if i =='':continue\n",
    "            #print(i)\n",
    "            s_*=int(i)\n",
    "        sum_+=s_\n",
    "    print('trainable variables nums:{}'.format(sum_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017年11月12日10:45:39\n",
    "# 利用CUMT数据迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from cumt_eye import Cumt_itraker\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from Cumt_SqueezeNet import squeezenet\n",
    "sess=tf.InteractiveSession()\n",
    "#cumt rgb 相片均值\n",
    "cumt_picmean=[103.939, 116.779, 123.68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('PlaceHolder'):\n",
    "    X=tf.placeholder(shape=[None,128,128,3],dtype=tf.float32)\n",
    "    Y=tf.placeholder(shape=[None,16],dtype=tf.float32)\n",
    "    LR=tf.placeholder(dtype=tf.float32)\n",
    "with tf.name_scope('model'):\n",
    "    model=squeezenet(X,sess,outputclass=16)\n",
    "    y_score=model.score\n",
    "with tf.name_scope('LOSS'):\n",
    "    LOSS=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_score,labels=Y))\n",
    "    tf.summary.scalar('loss',LOSS)\n",
    "with tf.name_scope('TRAIN'):\n",
    "    TRAIN=tf.train.AdamOptimizer(LR).minimize(LOSS)\n",
    "with tf.name_scope('ACCURACY'):\n",
    "    acc_count=tf.equal(tf.arg_max(y_score,1),tf.arg_max(Y,1))\n",
    "    ACCURACY=tf.reduce_mean(tf.cast(acc_count,tf.float32))\n",
    "    tf.summary.scalar('acc',ACCURACY)\n",
    "writer_tr=tf.summary.FileWriter('./mylog/squeezenet_1k_zero/train')\n",
    "writer_te=tf.summary.FileWriter('./mylog/squeezenet_1k_zero/test')\n",
    "writer_val=tf.summary.FileWriter('./mylog/squeezenet_1k_zero/val')\n",
    "merge=tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#加载cumt训练出来的权值作为初始值\n",
    "model.init_network('squeezenet_795.pkl',skip_layer=['tail/conv/biases','tail/conv/weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载训练好的权值\n",
    "model.init_network('squeeze1k4x4_9688.pkl',skip_layer=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#从 0 开始训练网络\n",
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.load('img4X4_1006.pkl')\n",
    "index_=np.arange(d['data'].shape[0])\n",
    "np.random.shuffle(index_)\n",
    "tr_index=index_[:int(d['data'].shape[0]*0.8)]\n",
    "te_index=index_[int(d['data'].shape[0]*0.8):]\n",
    "tr_data,tr_label=d['data'][tr_index],d['label'][tr_index]\n",
    "te_data,te_label=d['data'][te_index],d['label'][te_index]\n",
    "print(tr_data.shape,te_data.shape)\n",
    "del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#开始正式训练\n",
    "batchsize=64\n",
    "lr_=1e-3\n",
    "bestval_acc=0.7\n",
    "for i in range(1,1000*6*12):\n",
    "    mask=np.random.choice(tr_data.shape[0],batchsize,replace=False)\n",
    "    x_,y_=tr_data[mask]-cumt_picmean,tr_label[mask]\n",
    "    feed_dict={X:x_,Y:y_,LR:lr_}\n",
    "    sess.run(TRAIN,feed_dict=feed_dict)\n",
    "    if i%10==0:\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_tr.add_summary(m_,i)\n",
    "        print('epoch:{},train loss:{},train accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%20==0:\n",
    "        mask=np.random.choice(te_data.shape[0],batchsize,replace=False)\n",
    "        x_,y_=te_data[mask]-cumt_picmean,te_label[mask]\n",
    "        feed_dict={X:x_,Y:y_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_te.add_summary(m_,i)\n",
    "        print('--epoch:{},test loss:{},test accuracy:{}'.format(i,loss_,acc_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试平均测试集ACC\n",
    "acc_lis=[]\n",
    "for j in range(10):\n",
    "    mask=np.random.choice(te_data.shape[0],100,replace=False)\n",
    "    x_,y_=te_data[mask]-cumt_picmean,te_label[mask]\n",
    "    feed_dict={X:x_,Y:y_}\n",
    "    acc_=sess.run(ACCURACY,feed_dict=feed_dict)\n",
    "    acc_lis.append(acc_)\n",
    "print(np.mean(acc_lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save_network_weight('squeeze1k4x4_9688.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017年11月12日17:41:38\n",
    "# 在现实环境中实测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from cumt_eye import Cumt_itraker\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from Cumt_SqueezeNet import squeezenet\n",
    "import time\n",
    "sess=tf.InteractiveSession()\n",
    "#cumt rgb 相片均值\n",
    "cumt_picmean=[103.939, 116.779, 123.68]\n",
    "X=tf.placeholder(shape=[None,128,128,3],dtype=tf.float32)\n",
    "model=squeezenet(X,sess,outputclass=16)\n",
    "model.init_network('squeeze1k4x4_9688.pkl',skip_layer=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') \n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')  \n",
    "def drawline(img_,line_w=1,line_color=(0,0,0),wandh_num=4):\n",
    "        '''\n",
    "        在图片上格子\n",
    "        :param line_w: 线宽\n",
    "        :param line_color: 线颜色\n",
    "        :param wandh_num:  长宽线的数量\n",
    "        :return:  无\n",
    "        '''\n",
    "        h,w=img_.shape[0],img_.shape[1]\n",
    "        w_num,h_num=wandh_num,wandh_num\n",
    "        h_,w_=h//h_num,w//w_num\n",
    "\n",
    "        # 竖线 (w,h)\n",
    "        for i in range(1,w_num):\n",
    "            #print(i)\n",
    "            cv2.line(img_,(w_*i,0),(w_*i,h),line_color,line_w)\n",
    "        # 横线\n",
    "        for i in range(1,h_num):\n",
    "            cv2.line(img_,(0,h_*i),(w,h_*i),line_color,line_w)\n",
    "        return img_\n",
    "\n",
    "def drawblock(img,line_num,block_id=0,blockcolor=(46,218,255),blockwideth=5,show_rec=True):\n",
    "        '''\n",
    "        选定九宫格，在这个格子上填充矩形表示选定这个格子\n",
    "        :param img_: 图片\n",
    "        :param block: 九宫格序号 0-15\n",
    "        :param blockcolor: 矩形框颜色\n",
    "        :param blockwideth: 框的宽度\n",
    "        :return:\n",
    "        '''\n",
    "        h,w=img.shape[0],img.shape[1]\n",
    "        w_line,h_line=line_num,line_num\n",
    "        h_,w_=h//h_line,w//w_line\n",
    "        cor_h=block_id//line_num\n",
    "        cor_w=block_id%line_num\n",
    "        sx,sy=cor_w*w_,cor_h*h_\n",
    "        \n",
    "        if show_rec:\n",
    "        #将整个矩形填充为其他颜色\n",
    "            img[sy:sy+h_,sx:sx+w_,:]=blockcolor\n",
    "        else:\n",
    "            roi_=img[sy:sy+h_,sx:sx+w_]\n",
    "            cv2.circle(roi_,(roi_.shape[1]//2,roi_.shape[0]//2), 10, (255,128,120), -1)\n",
    "       \n",
    "        return img\n",
    "def geteyeimg(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3,5) \n",
    "    if len(faces) !=1:\n",
    "        print(len(faces))\n",
    "        print('bad faces')\n",
    "        return None\n",
    "    for (x,y,w,h) in faces: \n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) \n",
    "            roi_gray = gray[y:y+h, x:x+w] \n",
    "            roi_color = img[y:y+h, x:x+w] \n",
    "            #检测视频中脸部的眼睛，并用vector保存眼睛的坐标、大小（用矩形表示） \n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray,scaleFactor=1.2, minNeighbors=7, minSize=(29, 29),\n",
    "                                     flags=cv2.CASCADE_SCALE_IMAGE) \n",
    "            #眼睛检测 ,对于识别比较差的情况舍弃\n",
    "            if len(eyes)!=2:\n",
    "                print(len(eyes))\n",
    "                print('bad eyes')\n",
    "                return None\n",
    "            if eyes[0][0]>eyes[1][0]:\n",
    "                ex=eyes[1][0]\n",
    "                W=eyes[0][0]-eyes[1][0]+eyes[0][2]\n",
    "            else:\n",
    "                ex=eyes[0][0]\n",
    "                W=eyes[1][0]-eyes[0][0]+eyes[1][2]\n",
    "            \n",
    "            if eyes[0][1]>eyes[1][1]:\n",
    "                ey=eyes[1][1]\n",
    "                H=eyes[0][1]-eyes[1][1]+eyes[0][3]\n",
    "            else:\n",
    "                ey=eyes[0][1]\n",
    "                H=eyes[1][1]-eyes[0][1]+eyes[1][3]\n",
    "    \n",
    "    return roi_color[ey+10:ey+H-2,ex-10:ex+W+10] if roi_color is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试网络是否能正常运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "_,frame=cap.read()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "e=model.get_eyeimg(frame,pre_process=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "e=model.get_eyeimg(frame)\n",
    "asw_prob=model.predict(X_tensor=X,eyes_images=e)\n",
    "\n",
    "#print(np.argmax(asw_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "_,frame=cap.read()\n",
    "cap.release()\n",
    "e=geteyeimg(frame)\n",
    "if e is None:\n",
    "    print('bad pic')\n",
    "else:\n",
    "    e=cv2.resize(e,(128,128))[:,:,::-1]\n",
    "asw_prob=model.predict(X_tensor=X,eyes_images=e.reshape(1,128,128,3))\n",
    "# test_score=sess.run(y_score,feed_dict={X:e.reshape(1,128,128,3)})\n",
    "print(np.argmax(asw_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 显示实时图像，帮助调整姿态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,fram=cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow('cam',fram)\n",
    "        if cv2.waitKey(30)&0xff==27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始正式的预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fps=10\n",
    "fsize_desk=(1920,1080)\n",
    "# save video\n",
    "video_d=cv2.VideoWriter('demo_desk.flv',cv2.VideoWriter_fourcc('F','L','V','1'),fps,fsize_desk)\n",
    "cap=cv2.VideoCapture(0)\n",
    "s_time=time.time()\n",
    "tar_img=cv2.imread('test.jpg')\n",
    "#设置window 为全屏\n",
    "cv2.namedWindow('Capture001',cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Capture001', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "s_time=time.time()\n",
    "random_show=np.random.randint(0,16,1)[0]\n",
    "\n",
    "#每N帧输出平均预测\n",
    "sum_score=[]\n",
    "sum_counter=0\n",
    "block_id=0\n",
    "ret_counter=0\n",
    "right_frame_counter=0\n",
    "while True:\n",
    "    ret,fram=cap.read()\n",
    "    if ret:\n",
    "        ret_counter+=1\n",
    "        #显示 内窥镜图像\n",
    "        tar_img=cv2.imread('test.jpg')\n",
    "        tar_img=drawline(tar_img,wandh_num=4)\n",
    "        #每30帧换点\n",
    "        if ret_counter%22==0:\n",
    "            random_show=np.random.randint(0,16,1)[0]\n",
    "\n",
    "        tar_img=drawblock(tar_img,line_num=4,block_id=random_show)\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "\n",
    "        #预测注视方向\n",
    "#             face_op=geteyeimg(fram)\n",
    "#             if face_op is None:\n",
    "#                 continue\n",
    "#         e=cv2.resize(face_op,(128,128))[:,:,::-1]\n",
    "#         y_guess=model.predict(X_tensor=X,eyes_images=e.reshape(1,128,128,3))[0]\n",
    "        e=model.get_eyeimg(fram)\n",
    "        if e is None:\n",
    "            continue\n",
    "        y_guess=model.predict(X_tensor=X,eyes_images=e)[0]\n",
    "\n",
    "        #平均每 N 帧的预测分数\n",
    "        block_id=np.argmax(y_guess)-1\n",
    "#         sum_counter+=1\n",
    "#         sum_score.append(y_guess)\n",
    "#         if sum_counter==5:\n",
    "#             sum_score=np.asarray(sum_score).reshape((-1,16))\n",
    "#             mean_score=np.mean(sum_score,0)\n",
    "#             block_id=np.argmax(mean_score)-1\n",
    "#             sum_score=[]\n",
    "#             sum_counter=0\n",
    "#             print(block_id)\n",
    "#             if block_id<0:block_id=0\n",
    "#             elif block_id>15:block_id=15\n",
    "\n",
    "        if block_id==random_show:\n",
    "             right_frame_counter+=1\n",
    "        tar_img=drawblock(tar_img,line_num=4,block_id=block_id,show_rec=False)\n",
    "        v_img=tar_img.copy()\n",
    "        fram=cv2.resize(fram,(300,300))\n",
    "        v_img[:300,-300:]=fram\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "\n",
    "\n",
    "        print('{} sec per frame'.format(time.time()-s_time))\n",
    "        s_time=time.time()\n",
    "        video_d.write(v_img)\n",
    "        if cv2.waitKey(1)&0xff==27:\n",
    "            print('accuracy:{}'.format(right_frame_counter/ret_counter))\n",
    "            print('out')\n",
    "            break\n",
    "    if (time.time()-s_time)>60*5:\n",
    "        print('time out')\n",
    "        break\n",
    "video_d.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_d.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
