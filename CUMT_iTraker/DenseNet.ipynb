{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017年11月15日20:46:13\n",
    "# 利用DenseNet结构改进原CNN网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from cumt_variant import densenet\n",
    "sess=tf.InteractiveSession()\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cumt rgb 相片均值\n",
    "cumt_picmean=[103.939, 116.779, 123.68]\n",
    "cumt_data=np.load('cumt_data.pkl')\n",
    "index=np.arange(cumt_data['data'].shape[0])\n",
    "np.random.shuffle(index)\n",
    "data=cumt_data['data'][index]\n",
    "label=cumt_data['labels'][index]\n",
    "del cumt_data\n",
    "resize_img=[]\n",
    "for i in range(data.shape[0]):\n",
    "    img=data[i]+cumt_picmean\n",
    "    img=cv2.resize(img.astype('uint8'),(128,128))\n",
    "    resize_img.append(img.astype('uint8'))\n",
    "    if i%10000==0:\n",
    "        print (i)\n",
    "data=None\n",
    "resize_img=np.array(resize_img).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**修改DenseNet参数，希望能够减小参数，希望能用1k的数据集训练出一个ACC接近1的网络**\n",
    "* ori:  k=12,  L=5,  dense block=4,  theta=0.5   ->  0.197 million,  acc=0.95\n",
    "* 1: k=12 ,L=4 ,dense block=4,theta=0.5  ->0.146 million,acc=0.93\n",
    "* 2: k=8 ,L=5 ,dense block=4,theta=0.5   ->0.089 million,acc=0.85\n",
    "* 3: k=12 ,L=5 ,dense block=3,theta=0.5   ->0.065 million,acc=0.89\n",
    "* 4: k=12 ,L=5 ,dense block=4,theta=0.3   ->0.166 million,acc=0.925\n",
    "* 5: k=8 ,L=4 ,dense block=3,theta=0.3,reg=le-3   ->0.042 million,?acc=0.9\n",
    "* 6: k=8 ,L=4 ,dense block=3,theta=0.3,reg=le-3,drop out=0.5   ->0.042 million,acc=0.9\n",
    "* 7: k=8 ,L=4 ,dense block=3,theta=0.3,reg=4e-4,drop out=0.5,data size =2048   ->0.042 million,?acc=0.95\n",
    "\n",
    "*总结：*\n",
    "* *减少L,theta对准确率的影响最小，但是减少的参数也少*\n",
    "* *减小K,dense block数量能大量的减小参数，但是同时也会比较大程度的影响ACC*\n",
    "* *增加正则和drop out能稍微增加一点准确率，但不是关键的因素*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name='cumtdata/densenet_samllv7_conv'\n",
    "with tf.variable_scope('Placehloder'):\n",
    "    X=tf.placeholder(dtype=tf.float32,shape=[None,128,128,3],name='X')\n",
    "    Y=tf.placeholder(dtype=tf.float32,shape=[None,10],name='Y')\n",
    "    bn_train=tf.placeholder(dtype=tf.bool,name='BN_FLAG')\n",
    "    LR=tf.placeholder(dtype=tf.float32,name='lr')\n",
    "    DROPOUT=tf.placeholder(dtype=tf.float32,name='DROPOUT')\n",
    "with tf.name_scope('DenseNet'):\n",
    "    model=densenet(Images=X,dropout=DROPOUT,bn_istraining=bn_train,K=8,L=4,theta=0.3,output_class=10,sess=sess,denseblock_num=3)\n",
    "    y_score=model.y_score\n",
    "with tf.name_scope('LOSS'):\n",
    "    LOSS=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_score,labels=Y))+4e-4*(model.get_l2loss())\n",
    "    tf.summary.scalar('loss',LOSS)\n",
    "with tf.name_scope('TRAIN'):\n",
    "    TRAIN=tf.train.AdamOptimizer(LR).minimize(LOSS)\n",
    "with tf.name_scope('ACCURACY'):\n",
    "    acc_count=tf.equal(tf.arg_max(y_score,1),tf.arg_max(Y,1))\n",
    "    ACCURACY=tf.reduce_mean(tf.cast(acc_count,tf.float32))\n",
    "    tf.summary.scalar('acc',ACCURACY)\n",
    "bn_ops=tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "writer_te=tf.summary.FileWriter(r'./mylog/'+log_name+r'/test')\n",
    "writer_tr=tf.summary.FileWriter(r'./mylog/'+log_name+r'/train')\n",
    "writer_val=tf.summary.FileWriter(r'./mylog/'+log_name+r'/val')\n",
    "merge=tf.summary.merge_all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_params():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        shape = variable.get_shape()\n",
    "        variable_parametes = 1\n",
    "        for dim in shape:\n",
    "            variable_parametes *= dim.value\n",
    "        total_parameters += variable_parametes\n",
    "    print(\"Total training params: %.5f Million,%.5f Mb\" % (total_parameters / 1e6,total_parameters* 4/ (1024*1024)))\n",
    "count_trainable_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size=1024*2\n",
    "\n",
    "data=resize_img\n",
    "\n",
    "index=np.arange(data.shape[0])\n",
    "np.random.shuffle(index)\n",
    "tr_index=index[:data_size]\n",
    "te_index=index[data_size:]\n",
    "# tr_index=index[:int(data.shape[0]*0.9)]\n",
    "# te_index=index[int(data.shape[0]*0.9):]\n",
    "tr_data,tr_label=data[tr_index],label[tr_index]\n",
    "te_data,te_label=data[te_index],label[te_index]\n",
    "del data\n",
    "del label\n",
    "del resize_img\n",
    "print(tr_data.shape,te_data.shape)\n",
    "\n",
    "\n",
    "val_d=np.load('valimg1k_1109.pkl')\n",
    "val_data=[]\n",
    "for v in range(val_d['data'].shape[0]):\n",
    "    img_=cv2.resize(val_d['data'][v],(128,128))\n",
    "    \n",
    "    val_data.append(img_)\n",
    "val_data=np.array(val_data)\n",
    "val_label=val_d['label']\n",
    "del val_d\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#开始正式训练\n",
    "batchsize=128\n",
    "best_acc=0\n",
    "lr_=1e-3\n",
    "dp_=0.5\n",
    "test_acc_his=[]\n",
    "for i in range(1,1000*6*12):\n",
    "    mask=np.random.choice(tr_data.shape[0],batchsize,replace=False)\n",
    "    x_,y_=tr_data[mask]-cumt_picmean,tr_label[mask]\n",
    "    feed_dict={X:x_,Y:y_,bn_train:True,LR:lr_,DROPOUT:dp_}\n",
    "    sess.run([TRAIN,bn_ops],feed_dict=feed_dict)\n",
    "    if i%10==0:\n",
    "        feed_dict={X:x_,Y:y_,bn_train:False,DROPOUT:1.}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_tr.add_summary(m_,i)\n",
    "        print('epoch:{},train loss:{},train accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%20==0:\n",
    "        mask=np.random.choice(te_data.shape[0],batchsize,replace=False)\n",
    "        x_,y_=te_data[mask]-cumt_picmean,te_label[mask]\n",
    "        feed_dict={X:x_,Y:y_,bn_train:False,DROPOUT:1.}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_te.add_summary(m_,i)\n",
    "        test_acc_his.append(acc_)\n",
    "        print('--epoch:{},test loss:{},test accuracy:{},mean acc:{}'.format(i,loss_,acc_,np.mean(test_acc_his[-20:])))\n",
    "    if i%30==0:\n",
    "        mask=np.random.choice(val_data.shape[0],batchsize,replace=False)\n",
    "        x_,y_=val_data[mask]-cumt_picmean,val_label[mask]\n",
    "        feed_dict={X:x_,Y:y_,bn_train:False,DROPOUT:1.}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        best_acc=max(best_acc,acc_)\n",
    "        writer_val.add_summary(m_,i)\n",
    "        print('@@epoch:{},val loss:{},val accuracy:{},best val acc:{}'.format(i,loss_,acc_,best_acc))\n",
    "    if i%400==0:\n",
    "        lr_=max(lr_*0.8,5e-5)\n",
    "        print('$$$ lr change:{}'.format(lr_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save_network_weight('densenet_dump/smallmodel_acc964.pkl',sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver.save(sess,'DenseNet/model_578',global_step=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用CUMT训练好的模型进行迁移 学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from cumt_variant import densenet\n",
    "cumt_picmean=[103.939, 116.779, 123.68]\n",
    "sess=tf.InteractiveSession()\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_class=25\n",
    "log_name='densenet5X5_zeros_256'\n",
    "with tf.variable_scope('Placehloder'):\n",
    "    X=tf.placeholder(dtype=tf.float32,shape=[None,128,128,3],name='X')\n",
    "    Y=tf.placeholder(dtype=tf.float32,shape=[None,output_class],name='Y')\n",
    "    bn_train=tf.placeholder(dtype=tf.bool,name='BN_FLAG')\n",
    "    LR=tf.placeholder(dtype=tf.float32,name='lr')\n",
    "with tf.name_scope('DenseNet'):\n",
    "    model=densenet(Images=X,bn_istraining=bn_train,K=12,L=5,theta=0.5,output_class=output_class,sess=sess)\n",
    "    y_score=model.y_score\n",
    "with tf.name_scope('LOSS'):\n",
    "    LOSS=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_score,labels=Y))\n",
    "    tf.summary.scalar('loss',LOSS)\n",
    "with tf.name_scope('TRAIN'):\n",
    "    TRAIN=tf.train.AdamOptimizer(LR).minimize(LOSS)\n",
    "with tf.name_scope('ACCURACY'):\n",
    "    acc_count=tf.equal(tf.arg_max(y_score,1),tf.arg_max(Y,1))\n",
    "    ACCURACY=tf.reduce_mean(tf.cast(acc_count,tf.float32))\n",
    "    tf.summary.scalar('acc',ACCURACY)\n",
    "bn_ops=tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "writer_te=tf.summary.FileWriter(r'./mylog/'+log_name+r'/test')\n",
    "writer_tr=tf.summary.FileWriter(r'./mylog/'+log_name+r'/train')\n",
    "writer_val=tf.summary.FileWriter(r'./mylog/'+log_name+r'/val')\n",
    "merge=tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <tf.Variable 'Tail/conv_class/weight:0' shape=(1, 1, 57, 10) dtype=float32_ref>\n",
    "# <tf.Variable 'Tail/conv_class/biases:0' shape=(10,) dtype=float32_ref>\n",
    "# <tf.Variable 'Tail/conv_class/BN/beta:0' shape=(10,) dtype=float32_ref>\n",
    "# <tf.Variable 'Tail/conv_class/BN/gamma:0' shape=(10,) dtype=float32_ref>\n",
    "model.init_network(sess=sess,weight_addr='densenet_1115.pkl',\n",
    "                   skip_layer=['Tail/conv_class/weight','Tail/conv_class/biases','Tail/conv_class/BN/beta','Tail/conv_class/BN/gamma'],\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  'img4X4_1006.pkl'   'img5X5_240.pkl'\n",
    "# d=np.load('img4X4_1006.pkl')\n",
    "d=np.load('img5X5_950.pkl')\n",
    "index_=np.arange(d['data'].shape[0])\n",
    "np.random.shuffle(index_)\n",
    "# tr_index=index_[:int(d['data'].shape[0]*0.8)]\n",
    "# te_index=index_[int(d['data'].shape[0]*0.8):]\n",
    "tr_index=index_[:256]\n",
    "te_index=index_[256:]\n",
    "tr_data,tr_label=d['data'][tr_index],d['label'][tr_index]\n",
    "te_data,te_label=d['data'][te_index],d['label'][te_index]\n",
    "print(tr_data.shape,te_data.shape)\n",
    "del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#开始正式训练\n",
    "batchsize=104\n",
    "lr_=1e-3\n",
    "for i in range(1,1000*6*12):\n",
    "    mask=np.random.choice(tr_data.shape[0],batchsize,replace=False)\n",
    "    x_,y_=tr_data[mask]-cumt_picmean,tr_label[mask]\n",
    "    feed_dict={X:x_,Y:y_,bn_train:True,LR:lr_}\n",
    "    sess.run([TRAIN,bn_ops],feed_dict=feed_dict)\n",
    "    if i%10==0:\n",
    "        feed_dict={X:x_,Y:y_,bn_train:False}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_tr.add_summary(m_,i)\n",
    "        print('epoch:{},train loss:{},train accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%20==0:\n",
    "        mask=np.random.choice(te_data.shape[0],batchsize,replace=False)\n",
    "        x_,y_=te_data[mask]-cumt_picmean,te_label[mask]\n",
    "        feed_dict={X:x_,Y:y_,bn_train:False}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_te.add_summary(m_,i)\n",
    "        print('--epoch:{},test loss:{},test accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%400==0:\n",
    "        lr_=max(lr_*0.5,1e-5)\n",
    "        print('$$$ lr change:{}'.format(lr_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()\n",
    "saver.save(sess,'./model_save/Densenet_trans/model_991.ckpt',global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save_network_weight('dense4x4_trans991.pkl',sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "mask=np.random.choice(10,1,replace=False)\n",
    "x_,y_=te_data[mask]-cumt_picmean,te_label[mask]\n",
    "feed_dict={X:x_,Y:y_,bn_train:False}\n",
    "sess.run(y_score,feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实测 5X5分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') \n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')  \n",
    "def drawline(img_,line_w=1,line_color=(0,0,0),wandh_num=4):\n",
    "        '''\n",
    "        在图片上格子\n",
    "        :param line_w: 线宽\n",
    "        :param line_color: 线颜色\n",
    "        :param wandh_num:  长宽线的数量\n",
    "        :return:  无\n",
    "        '''\n",
    "        h,w=img_.shape[0],img_.shape[1]\n",
    "        w_num,h_num=wandh_num,wandh_num\n",
    "        h_,w_=h//h_num,w//w_num\n",
    "\n",
    "        # 竖线 (w,h)\n",
    "        for i in range(1,w_num):\n",
    "            #print(i)\n",
    "            cv2.line(img_,(w_*i,0),(w_*i,h),line_color,line_w)\n",
    "        # 横线\n",
    "        for i in range(1,h_num):\n",
    "            cv2.line(img_,(0,h_*i),(w,h_*i),line_color,line_w)\n",
    "        return img_\n",
    "\n",
    "def drawblock(img,line_num,block_id=0,blockcolor=(46,218,255),blockwideth=5,show_rec='fill',rec_shape=None):\n",
    "        '''\n",
    "        选定九宫格，在这个格子上填充矩形表示选定这个格子\n",
    "        :param img_: 图片\n",
    "        :param block: 九宫格序号 0-15\n",
    "        :param blockcolor: 矩形框颜色\n",
    "        :param blockwideth: 框的宽度\n",
    "        :return:\n",
    "        '''\n",
    "        h,w=img.shape[0],img.shape[1]\n",
    "        w_line,h_line=line_num,line_num\n",
    "        h_,w_=h//h_line,w//w_line\n",
    "        cor_h=block_id//line_num\n",
    "        cor_w=block_id%line_num\n",
    "        sx,sy=cor_w*w_,cor_h*h_\n",
    "        \n",
    "        if show_rec=='fill':\n",
    "        #将整个矩形填充为其他颜色\n",
    "            img[sy:sy+h_,sx:sx+w_,:]=blockcolor\n",
    "        elif show_rec=='rec':\n",
    "            #显示矩形轮廓\n",
    "            xe,ye,we,he=rec_shape\n",
    "            cv2.rectangle(img,(xe,ye),(xe+we,ye+he),(255,0,0),10)\n",
    "        elif show_rec=='dot':\n",
    "            #标记一个小点\n",
    "            roi_=img[sy:sy+h_,sx:sx+w_]\n",
    "            cv2.circle(roi_,(roi_.shape[1]//2,roi_.shape[0]//2), 10, (255,128,120), -1)\n",
    "        elif show_rec=='select':\n",
    "            #hight light 矩形区域\n",
    "            #img[sy:sy+h_,sx:sx+w_,0]=255#r\n",
    "            img[sy:sy+h_,sx:sx+w_,1]=255#g\n",
    "            #img[sy:sy+h_,sx:sx+w_,2]=255#b\n",
    "        elif show_rec=='pick':\n",
    "            #返回矩形框内容\n",
    "            return img[sy:sy+h_,sx:sx+w_],(sx,sy,w_,h_)\n",
    "        return img\n",
    "def geteyeimg(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3,5) \n",
    "    if len(faces) !=1:\n",
    "        print(len(faces))\n",
    "        print('bad faces')\n",
    "        return None\n",
    "    for (x,y,w,h) in faces: \n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) \n",
    "            roi_gray = gray[y:y+h, x:x+w] \n",
    "            roi_color = img[y:y+h, x:x+w] \n",
    "            #检测视频中脸部的眼睛，并用vector保存眼睛的坐标、大小（用矩形表示） \n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray,scaleFactor=1.2, minNeighbors=7, minSize=(29, 29),\n",
    "                                     flags=cv2.CASCADE_SCALE_IMAGE) \n",
    "            #眼睛检测 ,对于识别比较差的情况舍弃\n",
    "            if len(eyes)!=2:\n",
    "                print(len(eyes))\n",
    "                print('bad eyes')\n",
    "                return None\n",
    "            if eyes[0][0]>eyes[1][0]:\n",
    "                ex=eyes[1][0]\n",
    "                W=eyes[0][0]-eyes[1][0]+eyes[0][2]\n",
    "            else:\n",
    "                ex=eyes[0][0]\n",
    "                W=eyes[1][0]-eyes[0][0]+eyes[1][2]\n",
    "            \n",
    "            if eyes[0][1]>eyes[1][1]:\n",
    "                ey=eyes[1][1]\n",
    "                H=eyes[0][1]-eyes[1][1]+eyes[0][3]\n",
    "            else:\n",
    "                ey=eyes[0][1]\n",
    "                H=eyes[1][1]-eyes[0][1]+eyes[1][3]\n",
    "    \n",
    "    return roi_color[ey+10:ey+H-2,ex-10:ex+W+10] if roi_color is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "_,frame=cap.read()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob=tf.nn.softmax(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e=geteyeimg(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e=cv2.resize(e,(128,128))[:,:,::-1].reshape((1,128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#e=get_eyeimg(frame)\n",
    "prob_=sess.run(prob,feed_dict={X:e-cumt_picmean,bn_train:False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fps=10\n",
    "fsize_desk=(1920,1080)\n",
    "# save video\n",
    "video_d=cv2.VideoWriter('demo_desk.flv',cv2.VideoWriter_fourcc('F','L','V','1'),fps,fsize_desk)\n",
    "cap=cv2.VideoCapture(0)\n",
    "s_time=time.time()\n",
    "tar_img=cv2.imread('test.jpg')\n",
    "#设置window 为全屏\n",
    "cv2.namedWindow('Capture001',cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Capture001', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "s_time=time.time()\n",
    "random_show=np.random.randint(0,16,1)[0]\n",
    "\n",
    "#每N帧输出平均预测\n",
    "sum_score=[]\n",
    "sum_counter=0\n",
    "block_id=0\n",
    "ret_counter=0\n",
    "right_frame_counter=0\n",
    "while True:\n",
    "    ret,fram=cap.read()\n",
    "    if ret:\n",
    "        ret_counter+=1\n",
    "        #显示 内窥镜图像\n",
    "        tar_img=cv2.imread('test.jpg')\n",
    "        tar_img=drawline(tar_img,wandh_num=5)\n",
    "        #每30帧换点\n",
    "        if ret_counter%22==0:\n",
    "            random_show=np.random.randint(0,16,1)[0]\n",
    "\n",
    "        tar_img=drawblock(tar_img,line_num=5,block_id=random_show)\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "        e=geteyeimg(fram)\n",
    "        if e is None:\n",
    "            continue\n",
    "        e=cv2.resize(e,(128,128))[:,:,::-1].reshape((1,128,128,3))\n",
    "        y_guess=sess.run(prob,feed_dict={X:e-cumt_picmean,bn_train:False})\n",
    "        sum_score.append(y_guess)\n",
    "        #平均每 N 帧的预测分数\n",
    "        if ret_counter%5==0:\n",
    "            sum_score=np.array(sum_score)\n",
    "            mean_=np.mean(sum_score,0)\n",
    "            block_id=np.argmax(mean_)-1\n",
    "            sum_score=[]\n",
    "        if block_id<0:block_id=0\n",
    "        elif block_id>25:block_id=25\n",
    "\n",
    "        print(block_id)\n",
    "        if block_id==random_show:\n",
    "             right_frame_counter+=1\n",
    "        tar_img=drawblock(tar_img,line_num=5,block_id=block_id,show_rec='dot')\n",
    "        v_img=tar_img.copy()\n",
    "        fram=cv2.resize(fram,(150,150))\n",
    "        v_img[:150,-150:]=fram\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "\n",
    "\n",
    "#         print('{} sec per frame'.format(time.time()-s_time))\n",
    "        s_time=time.time()\n",
    "        video_d.write(v_img)\n",
    "        if cv2.waitKey(1)&0xff==27:\n",
    "            print('accuracy:{}'.format(right_frame_counter/ret_counter))\n",
    "            print('out')\n",
    "            break\n",
    "    if (time.time()-s_time)>60*5:\n",
    "        print('time out')\n",
    "        break\n",
    "video_d.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_d.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
