{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017年11月13日17:20:39\n",
    "# 训练CUMT论文提出的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from cumt_eye import Cumt_itraker\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "import UI\n",
    "import cv2\n",
    "import pickle\n",
    "sess=tf.InteractiveSession()\n",
    "cumt_data=np.load(r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\cumt_data.pkl')\n",
    "\n",
    "\n",
    "X=tf.placeholder(shape=[None,32,128,3],dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,10],dtype=tf.float32)\n",
    "DROPOUT=tf.placeholder(dtype=tf.float32)\n",
    "LR=tf.placeholder(dtype=tf.float32)\n",
    "BN_FLAG=tf.placeholder(dtype=tf.bool)\n",
    "\n",
    "with tf.name_scope('model'):\n",
    "    model=Cumt_itraker(image=X,bn_flag=BN_FLAG,dropout_rate=DROPOUT)\n",
    "    y_score=model.score\n",
    "\n",
    "with tf.name_scope('LOSS'):\n",
    "    LOSS=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_score,labels=Y))\n",
    "    tf.summary.scalar('loss',LOSS)\n",
    "with tf.name_scope('TRAIN'):\n",
    "    TRAIN=tf.train.AdamOptimizer(LR).minimize(LOSS)\n",
    "with tf.name_scope('ACCURACY'):\n",
    "    acc_count=tf.equal(tf.arg_max(y_score,1),tf.arg_max(Y,1))\n",
    "    ACCURACY=tf.reduce_mean(tf.cast(acc_count,tf.float32))\n",
    "    tf.summary.scalar('acc',ACCURACY)\n",
    "\n",
    "writer_tr=tf.summary.FileWriter('./mylog/cumt/train')\n",
    "writer_te=tf.summary.FileWriter('./mylog/cumt/test')\n",
    "writer_val=tf.summary.FileWriter('./mylog/cumt/val')\n",
    "merge=tf.summary.merge_all()\n",
    "ex_ops=tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#初始化变量，需要重新训练才运行\n",
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从保存的检查点钟复原变量，加载原数据训练好的模型\n",
    "saver=tf.train.Saver()\n",
    "saver.restore(sess,r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\model_save\\model_71.ckpt-64600')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumt_picmean=[103.939, 116.779, 123.68]\n",
    "d=np.load('valimg1k_1109.pkl')\n",
    "val={}\n",
    "val_data=d['data'].astype('float32')-cumt_picmean\n",
    "val_label=d['label']\n",
    "del d\n",
    "print(val_data.shape,val_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=cumt_data['data']\n",
    "label=cumt_data['labels']\n",
    "index=np.arange(data.shape[0])\n",
    "np.random.shuffle(index)\n",
    "tr_index=index[:int(data.shape[0]*0.9)]\n",
    "te_index=index[int(data.shape[0]*0.9):]\n",
    "tr_data,tr_label=data[tr_index],label[tr_index]\n",
    "te_data,te_label=data[te_index],label[te_index]\n",
    "del data\n",
    "del label\n",
    "del cumt_data\n",
    "print(tr_data.shape,te_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "#mask=np.random.choice(te_data.shape[0],10,replace=False)\n",
    "x_,y_=te_data[:1],te_label[:1]\n",
    "feed_dict={X:x_,Y:y_,DROPOUT:1.,BN_FLAG:False,LR:lr_}\n",
    "sess.run(y_score,feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 150 loop/min\n",
    "lr_=1e-3\n",
    "batch_size=82\n",
    "for i in range(1000*5000):\n",
    "    mask=np.random.choice(tr_data.shape[0],batch_size,replace=False)\n",
    "    x_,y_=tr_data[mask],tr_label[mask]\n",
    "    feed_dict={X:x_,Y:y_,DROPOUT:0.5,BN_FLAG:True,LR:lr_}\n",
    "    sess.run([TRAIN,ex_ops],feed_dict=feed_dict)\n",
    "    if i%10==0:\n",
    "        feed_dict={X:x_,Y:y_,DROPOUT:1.,BN_FLAG:False,LR:lr_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_tr.add_summary(m_,i)\n",
    "        print('train epoch:{},loss:{},accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%20==0:\n",
    "        mask=np.random.choice(te_data.shape[0],batch_size,replace=False)\n",
    "        x_,y_=te_data[mask],te_label[mask]\n",
    "        feed_dict={X:x_,Y:y_,DROPOUT:1.,BN_FLAG:False,LR:lr_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_te.add_summary(m_,i)\n",
    "        print('--test epoch:{},loss:{},accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%30==0:\n",
    "        mask=np.random.choice(val_data.shape[0],batch_size,replace=False)\n",
    "        x_,y_=val_data[mask],val_label[mask]\n",
    "        feed_dict={X:x_,Y:y_,DROPOUT:1.,BN_FLAG:False,LR:lr_}\n",
    "        loss_,acc_,m_=sess.run([LOSS,ACCURACY,merge],feed_dict=feed_dict)\n",
    "        writer_val.add_summary(m_,i)\n",
    "        print('@@val epoch:{},loss:{},accuracy:{}'.format(i,loss_,acc_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 提取所有可训练参数，并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename='test_cumt.pkl'\n",
    "all_var_name=list(tf.trainable_variables())\n",
    "weight_dict={}\n",
    "#提取变量值\n",
    "for name_ in all_var_name:\n",
    "    #变量名称\n",
    "    layer_name=str(name_).split(\"'\")[1][:-2]\n",
    "    #print(layer_name)\n",
    "    with tf.variable_scope('',reuse=True):\n",
    "        var=tf.get_variable(layer_name)\n",
    "        #注意var是tensor，需要转换一下\n",
    "        weight_dict[layer_name]=sess.run(var)\n",
    "#保存到pkl文件中\n",
    "fp=open(filename,'wb')\n",
    "pickle.dump(obj=weight_dict,file=fp)\n",
    "fp.close()\n",
    "print('save weight file done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载保存的网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_addr='test_cumt.pkl'\n",
    "skip_layer=[]\n",
    "network_dict=np.load(weight_addr)\n",
    "layer_name=list(network_dict.keys())\n",
    "for name_ in layer_name:\n",
    "    if name_ in skip_layer:\n",
    "        print('skip layer:{}'.format(name_))\n",
    "        continue\n",
    "    with tf.variable_scope('',reuse=True):\n",
    "        var=tf.get_variable(name_)\n",
    "        sess.run(var.assign(network_dict[name_]))\n",
    "print('network init done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算所有可训练变量数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sum_=0\n",
    "for s in list(tf.trainable_variables()):\n",
    "    s=str(s)\n",
    "    shape_=s[s.index('(')+1:s.index(')')].split(',')\n",
    "    s_=1\n",
    "    #print(shape_)\n",
    "    for i in shape_:\n",
    "        if i =='':continue\n",
    "        #print(i)\n",
    "        s_*=int(i)\n",
    "    sum_+=s_\n",
    "print('trainable variables nums:{},{}Mb'.format(sum_,sum_*4/(1024*1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#保存模型\n",
    "saver=tf.train.Saver()\n",
    "saver.save(sess,'./model_save/model.ckpt',global_step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "在视频中插入判别网络\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob=tf.nn.softmax(y_score,name='prob')\n",
    "y_guess=tf.arg_max(prob,1)+1\n",
    "\n",
    "#预测方向到九宫格方向,\n",
    "pre2block={2:3,3:2,4:1,\n",
    "           5:6,6:5,7:4,\n",
    "           8:9,9:8,10:7}\n",
    "#校正时需要保存图像均值\n",
    "VGG_MEAN =mean_pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BGR\n",
    "#VGG_MEAN = [103.939, 116.779, 123.68]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(r'test_video/101603.mp4')\n",
    "fps=cap.get(cv2.CAP_PROP_FPS)\n",
    "fsize=(\n",
    "    int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "    int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "      )\n",
    "# save video\n",
    "video_saver=cv2.VideoWriter('demo_1041.flv',cv2.VideoWriter_fourcc('F','L','V','1'),50,fsize)\n",
    "while (True):\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        #截取眼部图片\n",
    "#         frame=np.transpose(frame,[1,0,2])\n",
    "#         frame=frame[::-1,:,:]\n",
    "#         eye_img=None\n",
    "        #frame=frame[:,::-1,:]\n",
    "        eye_img=UI.drew_face_eye(frame)\n",
    "        if eye_img is None:\n",
    "            #没有检测到眼睛，跳到下一帧\n",
    "            cv2.imshow('frame',frame)\n",
    "            video_saver.write(frame)\n",
    "            if cv2.waitKey(10)& 0xff ==ord('q'):\n",
    "                print('quite')\n",
    "                break\n",
    "            continue\n",
    "        # BGR -> RGB\n",
    "        eye_img=eye_img[:,:,::-1]\n",
    "        e1=imresize(eye_img,(32,128,3)).astype('float32')-VGG_MEAN\n",
    "        \n",
    "        x_=e1.reshape((1,32,128,3))\n",
    "        pre_asw=sess.run(y_guess,feed_dict={X:x_,DROPOUT:1.,BN_FLAG:False})[0]\n",
    "        #给图片划线，划框\n",
    "        print(pre_asw)\n",
    "        frame=UI.drawline(frame,line_w=1)\n",
    "        if pre_asw != 1:\n",
    "            #有检测结果\n",
    "            \n",
    "            frame=UI.drawblock(frame,pre2block[pre_asw])\n",
    "            #cv2.waitKey()\n",
    "        #cv2.imshow('frame',x_.reshape((32,128,3)))\n",
    "        cv2.imshow('frame',frame)\n",
    "        video_saver.write(frame)\n",
    "        if cv2.waitKey(10)& 0xff ==ord('q'):\n",
    "            print('quite')\n",
    "            break\n",
    "    else:\n",
    "        print('video end')\n",
    "        break\n",
    "cap.release()\n",
    "video_saver.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/**************************************************************************/\n",
    "'''\n",
    "用固定的眼部识别参数截取眼部图片\n",
    "标注，保存\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import UI\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "\n",
    "#自然方向 -> 论文方向\n",
    "key_map={\n",
    "         1:'10',2:'9',3:'8',\n",
    "         4:'7',5:'6',6:'5',\n",
    "         7:'4',8:'3',9:'2',\n",
    "         0:'1'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#改\n",
    "cap = cv2.VideoCapture(r'test_video/101603.mp4')\n",
    "i_counter=0\n",
    "while (True):\n",
    "    i_counter+=1\n",
    "    ret,frame = cap.read()\n",
    "    if ret==True:\n",
    "        #截取眼部图片\n",
    "        eye_img=UI.drew_face_eye(frame)\n",
    "        if eye_img is not None:\n",
    "            cv2.imshow('frame',eye_img)\n",
    "            a=(cv2.waitKey())-48\n",
    "            cv2.destroyWindow('frame')\n",
    "            \n",
    "            # Esc 退出，'.'表示放弃这张图\n",
    "            if a==(-21):\n",
    "                break\n",
    "            elif a!=-2:\n",
    "                resize_img=imresize(eye_img,(32,128,3)).astype('uint8')\n",
    "                cv2.imwrite('./test_video/101603'+str(i_counter)+'_'+key_map[a]+'.jpg',resize_img)\n",
    "    else:\n",
    "        print('video end')\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_root='./test_video/101603'\n",
    "lis=os.listdir(img_root)\n",
    "img_arr,lab_arr=[],[]\n",
    "for addr in lis:\n",
    "    #标签\n",
    "    lable_=[0]*10\n",
    "    if addr[-5]==0:\n",
    "        n=10\n",
    "    else:\n",
    "        n=int(addr[-5])\n",
    "    lable_[n-1]=1\n",
    "    lab_arr.append(lable_)\n",
    "    #图像\n",
    "    img_=imread(os.path.join(img_root,addr))\n",
    "    #img_=imresize(img_,(32,128,3)).astype('uint8')\n",
    "    img_arr.append(img_)\n",
    "img_mat=np.array(img_arr)\n",
    "lab_mat=np.array(lab_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fp=open('./test_video/101603/101603_z.pkl','wb')\n",
    "pickle.dump(file=fp,obj={'images':img_mat,'labels':lab_mat})\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
