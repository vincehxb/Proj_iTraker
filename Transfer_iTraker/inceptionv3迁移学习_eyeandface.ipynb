{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2017年10月27日：\n",
    "## 尝试利用脸部和眼部的bottleneck的特征来实现回归问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.platform import gfile\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import pickle\n",
    "import interface\n",
    "import matplotlib.pyplot as plt\n",
    "from Vgg_class import Vgg_19\n",
    "sess=tf.InteractiveSession()\n",
    "#face_img=np.load('face_10k.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Input_dim=7*7*512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184\n"
     ]
    }
   ],
   "source": [
    "def drew_face_eye(img,show_reg=True):\n",
    "        '''\n",
    "        检测用户当前环境是否能够比较好的识别面部特征\n",
    "        辨识出脸部以及眼部，标记出来\n",
    "        :param img:\n",
    "        :return:\n",
    "        '''\n",
    "        face_cascade = cv2.CascadeClassifier(r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\haarcascade_frontalface_default.xml')\n",
    "        eye_cascade = cv2.CascadeClassifier(r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\haarcascade_eye.xml')\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "        #确保画面中只有一个人脸识别出来\n",
    "        if(len(faces)!=1):\n",
    "            return None\n",
    "        for (x,y,w,h) in faces:\n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "#             #保存脸部图像\n",
    "            face_mat=roi_color\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray,scaleFactor=1.2, minNeighbors=7, minSize=(29,29),\n",
    "                                            flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "            #眼睛检测 ,对于识别比较差的情况舍弃\n",
    "            if len(eyes)!=2:\n",
    "                return None\n",
    "            if eyes[0][0]>eyes[1][0]:\n",
    "                ex=eyes[1][0]\n",
    "                W=eyes[0][0]-eyes[1][0]+eyes[0][2]\n",
    "            else:\n",
    "                ex=eyes[0][0]\n",
    "                W=eyes[1][0]-eyes[0][0]+eyes[1][2]\n",
    "\n",
    "            if eyes[0][1]>eyes[1][1]:\n",
    "                ey=eyes[1][1]\n",
    "                H=eyes[0][1]-eyes[1][1]+eyes[0][3]\n",
    "            else:\n",
    "                ey=eyes[0][1]\n",
    "                H=eyes[1][1]-eyes[0][1]+eyes[1][3]\n",
    "            eye_mat=roi_color[ey:ey+H,ex:ex+W]\n",
    "        return  (img,face_mat,eye_mat)\n",
    "file_root=r'D:/Proj_DL/Code/Proj_EyeTraker/Proj_iTraker/Transfer_iTraker/img4X4_val/'\n",
    "img_names=os.listdir(file_root)\n",
    "#打乱顺序\n",
    "index=np.arange(len(img_names))\n",
    "np.random.shuffle(index)\n",
    "img_names=list(np.array(img_names)[index])\n",
    "print(len(img_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载 inception 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#jpg 二进制输入\n",
    "JEPG_INPUT='DecodeJpeg/contents:0'\n",
    "#矩阵输入\n",
    "MAT_INPUT='ExpandDims:0'\n",
    "\n",
    "#bottleneck 输出(1,2048)\n",
    "BOTTLE_NECK='pool_3/_reshape:0'\n",
    "#最后一个池化层的输出(1,8,8,2048)\n",
    "MIX10='mixed_10/join:0'\n",
    "#mix9输出（1,8,8,2048)\n",
    "MIX9='mixed_9/join:0'\n",
    "#mix8输出(1,8,8,1280)\n",
    "MIX8='mixed_8/join:0'\n",
    "#mix8输出(1,17,17,768)\n",
    "MIX7='mixed_7/join:0'\n",
    "#mixed输出(1,35,35,256)\n",
    "MIX0='mixed/join:0'\n",
    "\n",
    "MODEL_DIR='inceptionv3_model/tensorflow_inception_graph.pb'\n",
    "with gfile.FastGFile(MODEL_DIR,'rb') as f:\n",
    "    graph_def=tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "feature_bottleneck,jpeg_tensor=tf.import_graph_def(graph_def,return_elements=[MIX10,MAT_INPUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_cordinate=[]\n",
    "face_matrix=[]\n",
    "eye_matrix=[]\n",
    "fail_counter=0\n",
    "s_time=time.time()\n",
    "file_index=0\n",
    "if not os.path.exists('Feature_File_bottleneck2'):\n",
    "    print('make file fold:Feature_File_bottleneck!')\n",
    "    os.mkdir('Feature_File_bottleneck2')\n",
    "for i,f in enumerate(img_names):\n",
    "    lable_id=int(f[:-4].split('_')[-1])\n",
    "    img=cv2.imread(os.path.join(file_root,f))\n",
    "    face_op=drew_face_eye(img)\n",
    "    if face_op == None:\n",
    "        fail_counter+=1\n",
    "        continue\n",
    "    _,f,e=face_op\n",
    "    f=f.reshape((1,f.shape[0],f.shape[1],f.shape[2]))\n",
    "    e=e.reshape((1,e.shape[0],e.shape[1],e.shape[2]))\n",
    "    fea_f=sess.run(feature_bottleneck,{jpeg_tensor:f}).reshape((1,8,8,2048))\n",
    "    fea_e=sess.run(feature_bottleneck,{jpeg_tensor:e}).reshape((1,8,8,2048))\n",
    "    lable_=[0]*16\n",
    "    lable_[lable_id]=1\n",
    "    y_cordinate.append(lable_)\n",
    "    face_matrix.append(fea_f.astype('float32'))\n",
    "    eye_matrix.append(fea_e.astype('float32'))\n",
    "    if i%100==0:\n",
    "        print('pic:{},fail count:{},run time:{}'.format(i,fail_counter,time.time()-s_time))\n",
    "       # s_time=time.time()\n",
    "    if (i%50000==0)and (i !=0):\n",
    "        file_index+=1\n",
    "        file_name='feature50k_bottle_'+str(file_index)+r'_.pkl'\n",
    "        fp=open(os.path.join(r'Feature_File_bottleneck2/',file_name),'wb')\n",
    "        face_matrix=np.array(face_matrix).astype('float32')\n",
    "        eye_matrix=np.array(eye_matrix).astype('float32')\n",
    "        y_cordinate=np.array(y_cordinate).astype('uint8')\n",
    "        pickle.dump(obj={'feature_face':face_matrix,'feature_eye':eye_matrix,'label':y_cordinate},file=fp)\n",
    "        fp.close()\n",
    "        y_cordinate=[]\n",
    "        face_matrix=[]\n",
    "        eye_matrix=[]\n",
    "        print('file save')\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_matrix=np.array(face_matrix).astype('float32').reshape((-1,8,8,2048))\n",
    "eye_matrix=np.array(eye_matrix).astype('float32').reshape((-1,8,8,2048))\n",
    "y_cordinate=np.array(y_cordinate).astype('uint8')\n",
    "fp=open('fea1k_mix10.pkl','wb')\n",
    "pickle.dump(file=fp,obj={'feature_face':face_matrix,'feature_eye':eye_matrix,'label':y_cordinate})\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d=np.load('fea908_bottleneck.pkl')\n",
    "fea_mat=[]\n",
    "y_xy=[]\n",
    "for i in range(0,d['label'].shape[0]):\n",
    "   \n",
    "    f_=np.concatenate((d['feature_eye'][i],d['feature_face'][i]),axis=0)\n",
    "    #just eyes\n",
    "#     f_=d['feature_eye'][i]\n",
    "    #just face\n",
    "#     f_=d['feature_face'][i]\n",
    "#     id_=np.argmax(d['label'][i])\n",
    "#     x_,y_=id_%4,id_//4\n",
    "#     y_xy.append((x_,y_))\n",
    "    fea_mat.append(f_)\n",
    "fea_mat=np.asarray(fea_mat)\n",
    "y_xy=np.asarray(d['label']).reshape((-1,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fea_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# *训练CNN进行分类*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#输入 X: (N,4096)\n",
    "def model_mlp(x_input,traing):\n",
    "    trainable_=True\n",
    "    drop_rate=0.1\n",
    "    with tf.variable_scope('fc_4'):\n",
    "        w=tf.get_variable('weight',shape=[Input_dim,2048],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[2048,]),trainable=trainable_)\n",
    "        y_l1=tf.matmul(x_input,w)+b\n",
    "        y_l1=tf.layers.batch_normalization(y_l1,training=traing)\n",
    "        y_l1=tf.nn.relu(y_l1)\n",
    "    #fc5 (N,2048)->(N,1024)\n",
    "    with tf.variable_scope('fc_5'):\n",
    "        y_l1=tf.nn.dropout(y_l1,drop_rate)\n",
    "        w=tf.get_variable('weight',shape=[2048,1024],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[1024,]),trainable=trainable_)\n",
    "        y_l2=tf.matmul(y_l1,w)+b\n",
    "        y_l2=tf.layers.batch_normalization(y_l2,training=traing)\n",
    "        y_l2=tf.nn.relu(y_l2)\n",
    "    #fc6 (N,1024)->(N,16)\n",
    "    with tf.variable_scope('fc_6'):\n",
    "        y_l2=tf.nn.dropout(y_l2,drop_rate)\n",
    "        w=tf.get_variable('weight',shape=[1024,16],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[16,]))\n",
    "        y_l3=tf.matmul(y_l2,w)+b\n",
    "    return y_l3\n",
    "\n",
    "def ReloadData():\n",
    "    index=np.random.choice(range(1,10),2,replace=False)\n",
    "    \n",
    "    file_name=r'Feature_File/feature50k_pool3_'+str(index[0])+'_.pkl'\n",
    "    d=np.load(file_name)\n",
    "    fea_data=d['feature'].reshape((d['feature'].shape[0],d['feature'].shape[2],d['feature'].shape[3],d['feature'].shape[4],))\n",
    "    fea_label=d['label']\n",
    "    file_name=r'Feature_File/feature50k_pool3_'+str(index[1])+'_.pkl'\n",
    "    d=np.load(file_name)\n",
    "    f_=d['feature'].reshape((d['feature'].shape[0],d['feature'].shape[2],d['feature'].shape[3],d['feature'].shape[4],))\n",
    "    fea_data=np.concatenate((fea_data,f_),axis=0)\n",
    "    fea_label=np.concatenate((fea_label,d['label']),axis=0)\n",
    "    #将id 装换成 坐标\n",
    "    fea_label=conver_id2xy(fea_label)\n",
    "    return fea_data,fea_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#输入 X: (N,8,8,2048)\n",
    "def model_cnn(x_input,traing):\n",
    "    trainable_=True\n",
    "    drop_rate=0.1\n",
    "    regularizer=tf.contrib.layers.l2_regularizer(1e-2)\n",
    "    #conv1 1*1/1 (8,8,2048)->(8,8,1024)\n",
    "    with tf.variable_scope('conv_1'):\n",
    "        w=tf.get_variable('weight',shape=[1,1,2048,256],initializer=tf.contrib.layers.xavier_initializer(),trainable=trainable_)\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[256,]),trainable=trainable_)\n",
    "        tf.add_to_collection('loss_w',regularizer(w))\n",
    "        conv_=tf.nn.conv2d(x_input,w,[1,1,1,1],'VALID')+b\n",
    "        conv_=tf.layers.batch_normalization(conv_,training=traing)\n",
    "        conv_=tf.nn.relu(conv_)\n",
    "        \n",
    "    #conv2 3*3/2 (8,8,1024)->(6,6,1024)\n",
    "    with tf.variable_scope('conv_2'):\n",
    "        w=tf.get_variable('weight',shape=[3,3,256,128],initializer=tf.contrib.layers.xavier_initializer(),trainable=trainable_)\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[128,]),trainable=trainable_)\n",
    "        tf.add_to_collection('loss_w',regularizer(w))\n",
    "        conv_=tf.nn.conv2d(conv_,w,[1,1,1,1],'VALID')+b\n",
    "        conv_=tf.layers.batch_normalization(conv_,training=traing)\n",
    "        conv_=tf.nn.relu(conv_)\n",
    "    #conv3 3*3/1 (6,6,1024)->(4,4,512)\n",
    "    with tf.variable_scope('conv_3'):\n",
    "        w=tf.get_variable('weight',shape=[3,3,128,64],initializer=tf.contrib.layers.xavier_initializer(),trainable=trainable_)\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[64,]),trainable=trainable_)\n",
    "        tf.add_to_collection('loss_w',regularizer(w))\n",
    "        conv_=tf.nn.conv2d(conv_,w,[1,1,1,1],'VALID')+b\n",
    "        conv_=tf.layers.batch_normalization(conv_,training=traing)\n",
    "        conv_=tf.nn.relu(conv_)\n",
    "     #conv4 3*3/1 (4,4,512)->(2,2,512)\n",
    "    with tf.variable_scope('conv_4'):\n",
    "        w=tf.get_variable('weight',shape=[3,3,64,32],initializer=tf.contrib.layers.xavier_initializer(),trainable=trainable_)\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[32,]),trainable=trainable_)\n",
    "        tf.add_to_collection('loss_w',regularizer(w))\n",
    "        conv_=tf.nn.conv2d(conv_,w,[1,1,1,1],'VALID')+b\n",
    "        conv_=tf.layers.batch_normalization(conv_,training=traing)\n",
    "        conv_=tf.nn.relu(conv_)\n",
    "      \n",
    "    #fc4 (N,2*2*768)->(N,2048)\n",
    "    with tf.variable_scope('fc_4'):\n",
    "        x_flatten=tf.reshape(conv_,shape=[-1,2*2*32]) # N*256\n",
    "        w=tf.get_variable('weight',shape=[2*2*32,100],initializer=tf.contrib.layers.xavier_initializer(),trainable=trainable_)\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[100,]),trainable=trainable_)\n",
    "        tf.add_to_collection('loss_w',regularizer(w))\n",
    "        y_l1=tf.matmul(x_flatten,w)+b\n",
    "        y_l1=tf.layers.batch_normalization(y_l1,training=traing)\n",
    "        y_l1=tf.nn.relu(y_l1)\n",
    "    #fc5 (N,2048)->(N,1024)\n",
    "    with tf.variable_scope('fc_5'):\n",
    "        y_l1=tf.nn.dropout(y_l1,drop_rate)\n",
    "        w=tf.get_variable('weight',shape=[100,100],initializer=tf.contrib.layers.xavier_initializer(),trainable=trainable_)\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[100,]),trainable=trainable_)\n",
    "        tf.add_to_collection('loss_w',regularizer(w))\n",
    "        y_l2=tf.matmul(y_l1,w)+b\n",
    "        y_l2=tf.layers.batch_normalization(y_l2,training=traing)\n",
    "        y_l2=tf.nn.relu(y_l2)\n",
    "    #fc6 (N,1024)->(N,16)\n",
    "    with tf.variable_scope('fc_6'):\n",
    "        y_l2=tf.nn.dropout(y_l2,drop_rate)\n",
    "        w=tf.get_variable('weight',shape=[100,16],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[16,]))\n",
    "        tf.add_to_collection('loss_w',regularizer(w))\n",
    "        y_l3=tf.matmul(y_l2,w)+b\n",
    "    return y_l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=np.load('vgg19_feature.pkl')\n",
    "fea_mat=d['feature_eye']\n",
    "y_xy=np.asarray(d['label'])\n",
    "del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32,[None,7*7*512])\n",
    "Y=tf.placeholder(tf.float32,[None,16])\n",
    "TRAINGING=tf.placeholder(tf.bool)\n",
    "#\n",
    "y_socre=model_mlp(X,TRAINGING)\n",
    "\n",
    "# Loss=(tf.losses.mean_squared_error(Y,y_socre))\n",
    "# tf.summary.scalar('loss',Loss)\n",
    "# ERR=tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.squared_difference(y_socre, Y), axis=1)))\n",
    "# tf.summary.scalar('err',ERR)\n",
    "\n",
    "Loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_socre,labels=Y))\n",
    "ACC_C=tf.equal(tf.arg_max(y_socre,1),tf.arg_max(Y,1))\n",
    "ACC=tf.reduce_mean(tf.cast(ACC_C,tf.float32))\n",
    "tf.summary.scalar('loss',Loss)\n",
    "tf.summary.scalar('Accuracy',ACC)\n",
    "\n",
    "TRAIN=tf.train.AdamOptimizer(1e-3).minimize(Loss)\n",
    "#ACC\n",
    "BN_OPS=tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "writer_tr=tf.summary.FileWriter('./mylog/cnn_mix8/train')\n",
    "writer_te=tf.summary.FileWriter('./mylog/cnn_mix8/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fea_mat=np.asarray(fea_mat).reshape((-1,4096))\n",
    "# y_xy=np.asarray(y_xy).reshape((-1,2))\n",
    "index=np.arange(fea_mat.shape[0])\n",
    "np.random.shuffle(index)\n",
    "tr_index=index[:int(fea_mat.shape[0]*0.8)]\n",
    "te_index=index[int(fea_mat.shape[0]*0.8):]\n",
    "tr_data,tr_label=fea_mat[tr_index],y_xy[tr_index]\n",
    "te_data,te_label=fea_mat[te_index],y_xy[te_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te_data.shape,tr_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge=tf.summary.merge_all()\n",
    "init=sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ERR=ACC\n",
    "#100 大概1min\n",
    "acc_his=[]\n",
    "loss_his=[]\n",
    "vacc_his=[]\n",
    "vloss_his=[]\n",
    "best_te=0\n",
    "for i in range(1,1000*1000):\n",
    "    mask=np.random.choice(range(tr_data.shape[0]),128,replace=False)\n",
    "    x_,y_=tr_data[mask],tr_label[mask]\n",
    "    sess.run([TRAIN,BN_OPS],{X:x_,Y:y_,TRAINGING:True })\n",
    "                  \n",
    "    if i%5==0:\n",
    "#         mask=np.random.choice(range(val_fea.shape[0]),128,replace=False)\n",
    "#         x_,y_=val_fea[mask],val_y[mask]\n",
    "        loss_,acc_,m_,_=sess.run([Loss,ERR,merge,BN_OPS],{X:x_,Y:y_,TRAINGING:False})\n",
    "#         acc_his.append(acc_)\n",
    "#             loss_his.append(loss_)\n",
    "        writer_tr.add_summary(m_,i)\n",
    "        print('epoch:{},loss:{},err:{}'.format(i,loss_,acc_))\n",
    "    if i%10==0:\n",
    "        mask=np.random.choice(range(te_data.shape[0]),128,replace=False)\n",
    "        x_,y_=te_data[mask],te_label[mask]\n",
    "        loss_,acc_,m_,_=sess.run([Loss,ERR,merge,BN_OPS],{X:x_,Y:y_,TRAINGING:True})\n",
    "#         vacc_his.append(acc_)\n",
    "        best_te=max(acc_,best_te)\n",
    "#         vloss_his.append(loss_)\n",
    "        writer_te.add_summary(m_,i)\n",
    "        print('--epoch:{},loss:{},err:{},best acc:{}'.format(i,loss_,acc_,best_te))\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(vacc_his,label='val')\n",
    "plt.plot(acc_his,label='train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(vacc_his[-100:]),np.mean(acc_his[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=np.load('Feature_File_bottleneck2/feature15k_bottle_1_.pkl')\n",
    "val_fea=[]\n",
    "val_y=[]\n",
    "for i in range(0,d['label'].shape[0]):\n",
    "    f_=d['feature_face'][i]\n",
    "    val_fea.append(f_)\n",
    "val_fea=np.asarray(val_fea).reshape((-1,Input_dim))\n",
    "val_y=np.asarray(d['label']).reshape((-1,16))\n",
    "val_fea-=np.mean(fea_mat,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname='justface.pkl'\n",
    "fp=open(fname,'wb')\n",
    "pickle.dump(file=fp,obj={'acc':acc_his,'loss':loss_his})\n",
    "fp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#保存\n",
    "saver=tf.train.Saver()\n",
    "saver.save(sess,'./model_save/inception_err/mlpmodelerr045'+'.ckpt',global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#复原\n",
    "\n",
    "saver=tf.train.Saver()\n",
    "saver.restore(sess,'./model_save/inception_err/mlpmodelerr045.ckpt-363615')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawline(img_,line_w=1,line_color=(0,0,0),wandh_num=4):\n",
    "        '''\n",
    "        在图片上格子\n",
    "        :param line_w: 线宽\n",
    "        :param line_color: 线颜色\n",
    "        :param wandh_num:  长宽线的数量\n",
    "        :return:  无\n",
    "        '''\n",
    "        h,w=img_.shape[0],img_.shape[1]\n",
    "        w_num,h_num=wandh_num,wandh_num\n",
    "        h_,w_=h//h_num,w//w_num\n",
    "\n",
    "        # 竖线 (w,h)\n",
    "        for i in range(1,w_num):\n",
    "            #print(i)\n",
    "            cv2.line(img_,(w_*i,0),(w_*i,h),line_color,line_w)\n",
    "        # 横线\n",
    "        for i in range(1,h_num):\n",
    "            cv2.line(img_,(0,h_*i),(w,h_*i),line_color,line_w)\n",
    "        return img_\n",
    "\n",
    "def drew_face_eye2(img):\n",
    "        '''\n",
    "        检测用户当前环境是否能够比较好的识别面部特征\n",
    "        辨识出脸部以及眼部，标记出来\n",
    "        :param img:\n",
    "        :return:\n",
    "        '''\n",
    "        face_cascade = cv2.CascadeClassifier(r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\haarcascade_frontalface_default.xml')\n",
    "        eye_cascade = cv2.CascadeClassifier(r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\haarcascade_eye.xml')\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "        #确保画面中只有一个人脸识别出来\n",
    "        if(len(faces)!=1):\n",
    "            return None\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x-10,y-10),(x+w+10,y+h+10),(255,0,0),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "            #保存脸部图像\n",
    "            face_mat=roi_color.copy()\n",
    "            #检测视频中脸部的眼睛，并用vector保存眼睛的坐标、大小（用矩形表示）\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray,scaleFactor=1.1, minNeighbors=5, minSize=(27, 27),\n",
    "                                                flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "            if len(eyes)!= 2:\n",
    "                return None\n",
    "            eye_mat=[]\n",
    "            for e in eyes:\n",
    "                xe,ye,we,he=e\n",
    "                eye_mat.append(face_mat[ye:ye+he,xe:xe+we])\n",
    "                cv2.rectangle(roi_color,(xe-3,ye-3),(xe+we+3,ye+he+3),(0,0,255),2)\n",
    "        return  (img,face_mat,eye_mat)\n",
    "def drawblock(img,line_num,block_id=0,blockcolor=(46,218,255),blockwideth=5,show_rec=True):\n",
    "        '''\n",
    "        选定九宫格，在这个格子上填充矩形表示选定这个格子\n",
    "        :param img_: 图片\n",
    "        :param block: 九宫格序号 0-15\n",
    "        :param blockcolor: 矩形框颜色\n",
    "        :param blockwideth: 框的宽度\n",
    "        :return:\n",
    "        '''\n",
    "        h,w=img.shape[0],img.shape[1]\n",
    "        w_line,h_line=line_num,line_num\n",
    "        h_,w_=h//h_line,w//w_line\n",
    "        cor_h=block_id//line_num\n",
    "        cor_w=block_id%line_num\n",
    "        sx,sy=cor_w*w_,cor_h*h_\n",
    "        \n",
    "        if show_rec:\n",
    "        #将整个矩形填充为其他颜色\n",
    "            img[sy:sy+h_,sx:sx+w_,:]=blockcolor\n",
    "        else:\n",
    "            roi_=img[sy:sy+h_,sx:sx+w_]\n",
    "            cv2.circle(roi_,(roi_.shape[1]//2,roi_.shape[0]//2), 10, (255,128,120), -1)\n",
    "       \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tar_img=cv2.imread('test.jpg')\n",
    "tar_img=drawline(tar_img,wandh_num=4)\n",
    "tar_img=drawblock(tar_img,line_num=4,block_id=6)\n",
    "cap=cv2.VideoCapture(0)\n",
    "_,frame=cap.read()\n",
    "cap.release()\n",
    "v_test=tar_img.copy()\n",
    "tar_img[:480,1280:]=frame\n",
    "cv2.namedWindow('Capture001',cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Capture001', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "cv2.imshow('Capture001',tar_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyWindow('Capture001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#分类\n",
    "#prob=tf.nn.softmax(y_socre)\n",
    "#guess=tf.arg_max(prob,1)\n",
    "#回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,fram=cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow('cam',fram)\n",
    "        if cv2.waitKey(30)&0xff==27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fps=10\n",
    "fsize_desk=(1920,1080)\n",
    "# save video\n",
    "video_d=cv2.VideoWriter('demo_desk.flv',cv2.VideoWriter_fourcc('F','L','V','1'),fps,fsize_desk)\n",
    "cap=cv2.VideoCapture(0)\n",
    "s_time=time.time()\n",
    "tar_img=cv2.imread('test.jpg')\n",
    "#设置window 为全屏\n",
    "cv2.namedWindow('Capture001',cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Capture001', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "s_time=time.time()\n",
    "random_show=np.random.randint(0,16,1)[0]\n",
    "\n",
    "#每N帧输出平均预测\n",
    "sum_score=[]\n",
    "sum_counter=0\n",
    "block_id=0\n",
    "ret_counter=0\n",
    "right_frame_counter=0\n",
    "while True:\n",
    "    ret,fram=cap.read()\n",
    "    if ret:\n",
    "        ret_counter+=1\n",
    "        #显示 内窥镜图像\n",
    "        tar_img=cv2.imread('test.jpg')\n",
    "        tar_img=drawline(tar_img,wandh_num=4)\n",
    "        #每30帧换点\n",
    "        if ret_counter%30==0:\n",
    "            random_show=np.random.randint(0,16,1)[0]\n",
    "        tar_img=drawblock(tar_img,line_num=4,block_id=random_show)\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "       \n",
    "        #预测注视方向\n",
    "        face_op=drew_face_eye(fram)\n",
    "        if face_op == None:\n",
    "            continue\n",
    "        _,f,e=face_op\n",
    "        #\n",
    "        f=f.reshape((1,f.shape[0],f.shape[1],f.shape[2]))\n",
    "        \n",
    "        fea_f=sess.run(feature_bottleneck,{jpeg_tensor:f})\n",
    "\n",
    "        y_guess=sess.run(y_socre,feed_dict={X:fea_f,TRAINGING:False})[0]\n",
    "        #平均每 N 帧的预测分数\n",
    "        sum_counter+=1\n",
    "        sum_score.append(y_guess)\n",
    "        if sum_counter==10:\n",
    "            sum_score=np.asarray(sum_score).reshape((-1,16))\n",
    "            mean_score=np.mean(sum_score,0)\n",
    "            block_id=np.argmax(mean_score)\n",
    "            sum_score=[]\n",
    "            sum_counter=0\n",
    "           \n",
    "        #block_id=4*int(y_guess[1])+int(y_guess[0])\n",
    "       # block_id=np.argmax(y_guess)\n",
    "        if block_id==random_show:\n",
    "             right_frame_counter+=1\n",
    "        tar_img=drawblock(tar_img,line_num=4,block_id=block_id,show_rec=False)\n",
    "        v_img=tar_img.copy()\n",
    "        v_img[:480,1280:]=fram\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "        #print(time.time()-s_time)\n",
    "        s_time=time.time()\n",
    "        video_d.write(v_img)\n",
    "        if cv2.waitKey(1)&0xff==27:\n",
    "            print('accuracy:{}'.format(right_frame_counter/ret_counter))\n",
    "            print('out')\n",
    "            break\n",
    "    if (time.time()-s_time)>60*5:\n",
    "        print('time out')\n",
    "        break\n",
    "video_d.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 制作图片，bottleneck的各种组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=np.load('justface.pkl')\n",
    "e=np.load('justeye.pkl')\n",
    "fe=np.load('faceeye_concate.pkl')\n",
    "for i in range(len(fe['acc'])):\n",
    "    fe['acc'][i]*=100\n",
    "def fn(a,aname,pic_name,b=None,bname=None,acc=True):\n",
    "    fig=plt.figure(figsize=(10,5))\n",
    "    if bname:\n",
    "        plt.plot(a,label=aname)\n",
    "        plt.xlabel('iteration')\n",
    "        if acc:plt.ylabel('accuracy(%)')\n",
    "        else:plt.ylabel('loss')\n",
    "        plt.plot(b,label=bname)\n",
    "        plt.xlabel('iteration')\n",
    "        if acc:plt.ylabel('accuracy')\n",
    "        else:plt.ylabel('loss')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.plot(a,label=aname)\n",
    "        plt.xlabel('iteration')\n",
    "        if acc:plt.ylabel('accuracy(%)')\n",
    "        else:plt.ylabel('loss')\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "    fig.savefig(pic_name)\n",
    "fn(fe['loss'],'concatenate','concate_loss.png',acc=False)\n",
    "fig=plt.figure(figsize=(10,5))\n",
    "plt.plot(fe['acc'],label='concatenate')\n",
    "plt.plot(f['acc'],label='face')\n",
    "plt.plot(e['acc'],label='eye')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('accuracy(%)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig('acc_all.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Images=tf.placeholder(tf.float32,[None,224,224,3])\n",
    "vgg_model=Vgg_19(model_path=r'D:\\Data warehouse\\Model\\VGG_16&19\\vgg19.npy',images=Images,\\\n",
    "                 train_list=[],session=sess,image_batch_size=128)\n",
    "conv5_feature=vgg_model.pool5\n",
    "#feature=sess.run(conv5_feature,feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cordinate=[]\n",
    "face_matrix=[]\n",
    "eye_matrix=[]\n",
    "fail_counter=0\n",
    "s_time=time.time()\n",
    "file_index=0\n",
    "if not os.path.exists('Feature_File_bottleneck2'):\n",
    "    print('make file fold:Feature_File_bottleneck!')\n",
    "    os.mkdir('Feature_File_bottleneck2')\n",
    "for i,f in enumerate(img_names):\n",
    "    lable_id=int(f[:-4].split('_')[-1])\n",
    "    # BGR\n",
    "    img=cv2.imread(os.path.join(file_root,f))\n",
    "    face_op=drew_face_eye(img)\n",
    "    if face_op == None:\n",
    "        fail_counter+=1\n",
    "        continue\n",
    "    _,f,e=face_op\n",
    "    f=cv2.resize(f,(224,224))[:,:,::-1]\n",
    "    e=cv2.resize(e,(224,224))[:,:,::-1]\n",
    "    fea_f=sess.run(conv5_feature,feed_dict={Images:f.reshape((1,224,224,3))})\n",
    "    fea_e=sess.run(conv5_feature,feed_dict={Images:e.reshape((1,224,224,3))})\n",
    "    lable_=[0]*16\n",
    "    lable_[lable_id]=1\n",
    "    y_cordinate.append(lable_)\n",
    "    face_matrix.append(fea_f.astype('float32'))\n",
    "    eye_matrix.append(fea_e.astype('float32'))\n",
    "    if i%100==0:\n",
    "        print('pic:{},fail count:{},run time:{}'.format(i,fail_counter,time.time()-s_time))\n",
    "       # s_time=time.time()\n",
    "    if (i%50000==0)and (i !=0):\n",
    "        file_index+=1\n",
    "        file_name='feature50k_bottle_'+str(file_index)+r'_.pkl'\n",
    "        fp=open(os.path.join(r'Feature_File_bottleneck2/',file_name),'wb')\n",
    "        face_matrix=np.array(face_matrix).astype('float32')\n",
    "        eye_matrix=np.array(eye_matrix).astype('float32')\n",
    "        y_cordinate=np.array(y_cordinate).astype('uint8')\n",
    "        pickle.dump(obj={'feature_face':face_matrix,'feature_eye':eye_matrix,'label':y_cordinate},file=fp)\n",
    "        fp.close()\n",
    "        y_cordinate=[]\n",
    "        face_matrix=[]\n",
    "        eye_matrix=[]\n",
    "        print('file save')\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eye_matrix=np.array(eye_matrix).reshape((-1,25088))\n",
    "face_matrix=np.array(face_matrix).reshape((-1,25088))\n",
    "y_cordinate=np.array(y_cordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp=open('vgg19_feature.pkl','wb')\n",
    "pickle.dump(file=fp,obj={'feature_eye':eye_matrix,'feature_face':face_matrix,'label':y_cordinate})\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=0\n",
    "face_lis=[]\n",
    "eye_lis=[]\n",
    "for i in range(100):\n",
    "    f_img,e_img=face_matrix[s:s+10],face_matrix[s:s+10]\n",
    "    fea_f=sess.run(conv5_feature,feed_dict={Images:f_img})\n",
    "    fea_e=sess.run(conv5_feature,feed_dict={Images:e_img})\n",
    "    face_lis.append(fea_f)\n",
    "    eye_lis.append(fea_e)\n",
    "    print(s)\n",
    "    s=i+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_=np.array([8]*8*8*10).reshape((1,8,8,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  8  8 10]\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant(a_)\n",
    "print(tf.shape(a).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=tf.nn.max_pool(a,ksize=[1,8,8,1],strides=[1,1,1,1],padding='SAME')\n",
    "#ps=tf.squeeze(p,[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_=sess.run(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8, 8, 10)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
