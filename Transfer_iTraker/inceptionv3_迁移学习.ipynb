{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.platform import gfile\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import pickle\n",
    "sess=tf.InteractiveSession()\n",
    "#face_img=np.load('face_10k.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/******************************************************************************\n",
    "1.读取图片\n",
    "2.提取脸部图片\n",
    "3.将脸部图片输入到Inception--V3模型中提取特征\n",
    "4.保存特征\n",
    "/******************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drew_face_eye(img):\n",
    "        '''\n",
    "        检测用户当前环境是否能够比较好的识别面部特征\n",
    "        辨识出脸部以及眼部，标记出来\n",
    "        :param img:\n",
    "        :return:\n",
    "        '''\n",
    "        face_cascade = cv2.CascadeClassifier(r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\haarcascade_frontalface_default.xml')\n",
    "        eye_cascade = cv2.CascadeClassifier(r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\haarcascade_eye.xml')\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "        #确保画面中只有一个人脸识别出来\n",
    "        if(len(faces)!=1):\n",
    "            return None\n",
    "     \n",
    "        for (x,y,w,h) in faces:\n",
    "            \n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "#             #保存脸部图像\n",
    "            face_mat=roi_color\n",
    "\n",
    "            eye_mat=[]\n",
    "\n",
    "        return  (img,face_mat,eye_mat)\n",
    "file_root=r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\Proj_iTraker\\MIT_iTraker\\calimg_file_num'\n",
    "img_names=os.listdir(file_root)\n",
    "#打乱顺序\n",
    "index=np.arange(len(img_names))\n",
    "np.random.shuffle(index)\n",
    "img_names=list(np.array(img_names)[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#输出\n",
    "BOTTLE_NECK='pool_3/_reshape:0'\n",
    "#jpg 二进制输入\n",
    "JEPG_INPUT='DecodeJpeg/contents:0'\n",
    "#矩阵输入\n",
    "MAT_INPUT='ExpandDims:0'\n",
    "#最后一个池化层的输入\n",
    "POOL_3='mixed_10/join:0'\n",
    "MODEL_DIR='inceptionv3_model/tensorflow_inception_graph.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with gfile.FastGFile(MODEL_DIR,'rb') as f:\n",
    "    graph_def=tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "feature_bottleneck,jpeg_tensor=tf.import_graph_def(graph_def,return_elements=[POOL_3,MAT_INPUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#提取图片特征\n",
    "y_cordinate=[]\n",
    "face_matrix=[]\n",
    "fail_counter=0\n",
    "s_time=time.time()\n",
    "file_index=0\n",
    "for i,f in enumerate(img_names):\n",
    "    lable_id=int(f[:-4].split('_')[-1])\n",
    "    img=cv2.imread(os.path.join(file_root,f))\n",
    "    face_op=drew_face_eye(img)\n",
    "    if face_op == None:\n",
    "        fail_counter+=1\n",
    "        continue\n",
    "    _,f,_=face_op\n",
    "    f=f.reshape((1,f.shape[0],f.shape[1],f.shape[2]))\n",
    "    fea_=sess.run(feature_bottleneck,{jpeg_tensor:f})\n",
    "    lable_=[0]*16\n",
    "    lable_[lable_id]=1\n",
    "    y_cordinate.append(lable_)\n",
    "    face_matrix.append(fea_.astype('float32'))\n",
    "    if i%100==0:\n",
    "        print('pic:{},fail count:{},run time:{}'.format(i,fail_counter,time.time()-s_time))\n",
    "       # s_time=time.time()\n",
    "    if (i%5000==0)and (i !=0):\n",
    "        file_index+=1\n",
    "        file_name='feature50k_pool3_'+str(file_index)+r'_.pkl'\n",
    "        fp=open(os.path.join(r'Feature_File/',file_name),'wb')\n",
    "        face_matrix=np.array(face_matrix).astype('float32')\n",
    "        y_cordinate=np.array(y_cordinate).astype('uint8')\n",
    "        pickle.dump(obj={'feature':face_matrix,'label':y_cordinate},file=fp)\n",
    "        fp.close()\n",
    "        y_cordinate=[]\n",
    "        face_matrix=[]\n",
    "        print('file save')\n",
    "        #break\n",
    "\n",
    "#y_cordinate=np.array(y_cordinate).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_matrix=np.array(face_matrix).astype('float32').reshape((-1,2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cordinate=np.array(y_cordinate).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp=open('inception_10k.pkl','wb')\n",
    "d={'feature':face_matrix,'label':y_cordinate}\n",
    "pickle.dump(file=fp,obj=d)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/*******************************************************************************************\n",
    "训练MLP进行分类\n",
    "/*******************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#输入 X: (N,2048)\n",
    "def model_MLP(x_input,traing):\n",
    "    drop_rate=0.1\n",
    "    with tf.variable_scope('layer_1'):\n",
    "        w=tf.get_variable('weight',shape=[2048,1024],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[1024,]))\n",
    "        y_l1=tf.matmul(x_input,w)+b\n",
    "        y_l1=tf.layers.batch_normalization(y_l1,training=traing)\n",
    "        y_l1=tf.nn.relu(y_l1)\n",
    "    with tf.variable_scope('layer_2'):\n",
    "        y_l1=tf.nn.dropout(y_l1,drop_rate)\n",
    "        w=tf.get_variable('weight',shape=[1024,512],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[512,]))\n",
    "        y_l2=tf.matmul(y_l1,w)+b\n",
    "        y_l2=tf.layers.batch_normalization(y_l2,training=traing)\n",
    "        y_l2=tf.nn.relu(y_l2)\n",
    "    with tf.variable_scope('layer_3'):\n",
    "        y_l2=tf.nn.dropout(y_l2,drop_rate)\n",
    "        w=tf.get_variable('weight',shape=[512,16],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[16,]))\n",
    "        y_l3=tf.matmul(y_l2,w)+b\n",
    "    return y_l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入 X: (N,8,8,2048)\n",
    "def model_cnn(x_input,traing):\n",
    "    drop_rate=0.3\n",
    "    #conv1 3*3/1 (8,8,2048)->(6,6,2048)\n",
    "    with tf.variable_scope('conv_1'):\n",
    "        w=tf.get_variable('weight',shape=[3,3,2048,2048],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[2048,]))\n",
    "        conv_=tf.nn.conv2d(x_input,w,[1,1,1,1],'VALID')+b\n",
    "        conv_=tf.layers.batch_normalization(conv_,training=traing)\n",
    "        conv_=tf.nn.relu(conv_)\n",
    "    #conv2 3*3/1 (6,6,2048)->(4,4,2048)\n",
    "    with tf.variable_scope('conv_2'):\n",
    "        w=tf.get_variable('weight',shape=[3,3,2048,2048],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[2048,]))\n",
    "        conv_=tf.nn.conv2d(conv_,w,[1,1,1,1],'VALID')+b\n",
    "        conv_=tf.layers.batch_normalization(conv_,training=traing)\n",
    "        conv_=tf.nn.relu(conv_)\n",
    "     #conv3 3*3/1 (4,4,2048)->(2,2,2048)\n",
    "    with tf.variable_scope('conv_3'):\n",
    "        w=tf.get_variable('weight',shape=[3,3,2048,2048],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[2048,]))\n",
    "        conv_=tf.nn.conv2d(conv_,w,[1,1,1,1],'VALID')+b\n",
    "        conv_=tf.layers.batch_normalization(conv_,training=traing)\n",
    "        conv_=tf.nn.relu(conv_)\n",
    "    #fc4 (N,8192)->(N,2048)\n",
    "    with tf.variable_scope('fc_4'):\n",
    "        x_flatten=tf.reshape(conv_,shape=[-1,2*2*2048]) # N*256\n",
    "        w=tf.get_variable('weight',shape=[2*2*2048,2048],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[2048,]))\n",
    "        y_l1=tf.matmul(x_flatten,w)+b\n",
    "        y_l1=tf.layers.batch_normalization(y_l1,training=traing)\n",
    "        y_l1=tf.nn.relu(y_l1)\n",
    "    #fc5 (N,2048)->(N,1024)\n",
    "    with tf.variable_scope('fc_5'):\n",
    "        y_l1=tf.nn.dropout(y_l1,drop_rate)\n",
    "        w=tf.get_variable('weight',shape=[2048,1024],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[1024,]))\n",
    "        y_l2=tf.matmul(y_l1,w)+b\n",
    "        y_l2=tf.layers.batch_normalization(y_l2,training=traing)\n",
    "        y_l2=tf.nn.relu(y_l2)\n",
    "    #fc6 (N,1024)->(N,16)\n",
    "    with tf.variable_scope('fc_6'):\n",
    "        y_l2=tf.nn.dropout(y_l2,drop_rate)\n",
    "        w=tf.get_variable('weight',shape=[1024,16],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b=tf.get_variable('biases',initializer=tf.constant(0.1,shape=[16,]))\n",
    "        y_l3=tf.matmul(y_l2,w)+b\n",
    "    return y_l3\n",
    "def ReloadData():\n",
    "    index=np.random.choice(range(1,10),2,replace=False)\n",
    "    \n",
    "    file_name=r'Feature_File/feature50k_pool3_'+str(index[0])+'_.pkl'\n",
    "    d=np.load(file_name)\n",
    "    fea_data=d['feature'].reshape((d['feature'].shape[0],d['feature'].shape[2],d['feature'].shape[3],d['feature'].shape[4],))\n",
    "    fea_label=d['label']\n",
    "    file_name=r'Feature_File/feature50k_pool3_'+str(index[1])+'_.pkl'\n",
    "    d=np.load(file_name)\n",
    "    f_=d['feature'].reshape((d['feature'].shape[0],d['feature'].shape[2],d['feature'].shape[3],d['feature'].shape[4],))\n",
    "    fea_data=np.concatenate((fea_data,f_),axis=0)\n",
    "    fea_label=np.concatenate((fea_label,d['label']),axis=0)\n",
    "    return fea_data,fea_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32,[None,8,8,2048])\n",
    "Y=tf.placeholder(tf.float32,[None,16])\n",
    "TRAINGING=tf.placeholder(tf.bool)\n",
    "#\n",
    "y_socre=model_cnn(X,TRAINGING)\n",
    "LOSS=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_socre,labels=Y))\n",
    "TRAIN=tf.train.AdamOptimizer(1e-4).minimize(LOSS)\n",
    "tf.summary.scalar('loss',LOSS)\n",
    "#ACC\n",
    "ACC_C=tf.equal(tf.arg_max(y_socre,1),tf.arg_max(Y,1))\n",
    "ACC=tf.reduce_mean(tf.cast(ACC_C,tf.float32))\n",
    "tf.summary.scalar('Accuracy',ACC)\n",
    "BN_OPS=tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "writer_tr=tf.summary.FileWriter('./mylog/CNN/train')\n",
    "writer_te=tf.summary.FileWriter('./mylog/CNN/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fea_mat=d['feature'].reshape((-1,2048))\n",
    "# y_label=d['label']\n",
    "# fea_mat=feature_data\n",
    "# y_label=label_data\n",
    "# index=np.arange(fea_mat.shape[0])\n",
    "# np.random.shuffle(index)\n",
    "# tr_index=index[:int(fea_mat.shape[0]*0.8)]\n",
    "# te_index=index[int(fea_mat.shape[0]*0.8):]\n",
    "# tr_data=fea_mat[tr_index]\n",
    "# te_data=fea_mat[te_index]\n",
    "# tr_label=y_label[tr_index]\n",
    "# te_label=y_label[te_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge=tf.summary.merge_all()\n",
    "init=sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=np.load('Feature_File/fea_validate65k.pkl')\n",
    "te_data,te_label=d['feature'],d['label']\n",
    "del d\n",
    "tr_data,tr_label=ReloadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1k 大概25min\n",
    "for i in range(1000*10,1000*10+1000*10*4):\n",
    "    if i%1000==0:\n",
    "        print('change traing data')\n",
    "        del tr_data\n",
    "        del tr_label\n",
    "        tr_data,tr_label=ReloadData()\n",
    "    mask=np.random.choice(range(tr_data.shape[0]),128,replace=False)\n",
    "    x_,y_=tr_data[mask],tr_label[mask]\n",
    "    sess.run([TRAIN,BN_OPS],{X:x_,Y:y_,TRAINGING:True })\n",
    "                  \n",
    "    if i%10==0:\n",
    "        loss_,acc_,m_,_=sess.run([LOSS,ACC,merge,BN_OPS],{X:x_,Y:y_,TRAINGING:True})\n",
    "        writer_tr.add_summary(m_,i)\n",
    "        print('epoch:{},loss:{},accuracy:{}'.format(i,loss_,acc_))\n",
    "    if i%20==0:\n",
    "        mask=np.random.choice(range(te_data.shape[0]),256,replace=False)\n",
    "        x_,y_=te_data[mask],te_label[mask]\n",
    "        loss_,acc_,m_,_=sess.run([LOSS,ACC,merge,BN_OPS],{X:x_,Y:y_,TRAINGING:True})\n",
    "        writer_te.add_summary(m_,i)\n",
    "        print('--epoch:{},loss:{},accuracy:{}'.format(i,loss_,acc_))\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_sum=0\n",
    "for j_ in range(10):\n",
    "    mask=np.random.choice(range(te_data.shape[0]),300,replace=False)\n",
    "    x_,y_=te_data[mask],te_label[mask]\n",
    "    loss_,acc_,m_,_=sess.run([LOSS,ACC,merge,BN_OPS],{X:x_,Y:y_,TRAINGING:False})\n",
    "    acc_sum+=acc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_sum/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存\n",
    "saver=tf.train.Saver()\n",
    "saver.save(sess,'./model_save/inception_pool3_cnn/modelacc_94``'+'.ckpt',global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#复原\n",
    "#saver.restore(sess,'./model_save/model_mit_cal_1017/model_conv310192042.ckpt-23708')\n",
    "saver=tf.train.Saver()\n",
    "saver.restore(sess,'./model_save/inception_pool3_cnn/modelacc_90.ckpt-9999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/***************************************************\n",
    "测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawline(img_,line_w=1,line_color=(0,0,0),wandh_num=4):\n",
    "        '''\n",
    "        在图片上格子\n",
    "        :param line_w: 线宽\n",
    "        :param line_color: 线颜色\n",
    "        :param wandh_num:  长宽线的数量\n",
    "        :return:  无\n",
    "        '''\n",
    "        h,w=img_.shape[0],img_.shape[1]\n",
    "        w_num,h_num=wandh_num,wandh_num\n",
    "        h_,w_=h//h_num,w//w_num\n",
    "\n",
    "        # 竖线 (w,h)\n",
    "        for i in range(1,w_num):\n",
    "            #print(i)\n",
    "            cv2.line(img_,(w_*i,0),(w_*i,h),line_color,line_w)\n",
    "        # 横线\n",
    "        for i in range(1,h_num):\n",
    "            cv2.line(img_,(0,h_*i),(w,h_*i),line_color,line_w)\n",
    "        return img_\n",
    "\n",
    "def drew_face_eye2(img):\n",
    "        '''\n",
    "        检测用户当前环境是否能够比较好的识别面部特征\n",
    "        辨识出脸部以及眼部，标记出来\n",
    "        :param img:\n",
    "        :return:\n",
    "        '''\n",
    "        face_cascade = cv2.CascadeClassifier(r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\haarcascade_frontalface_default.xml')\n",
    "        eye_cascade = cv2.CascadeClassifier(r'D:\\Proj_DL\\Code\\Proj_EyeTraker\\haarcascade_eye.xml')\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "        #确保画面中只有一个人脸识别出来\n",
    "        if(len(faces)!=1):\n",
    "            return None\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x-10,y-10),(x+w+10,y+h+10),(255,0,0),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "            #保存脸部图像\n",
    "            face_mat=roi_color.copy()\n",
    "            #检测视频中脸部的眼睛，并用vector保存眼睛的坐标、大小（用矩形表示）\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray,scaleFactor=1.1, minNeighbors=5, minSize=(27, 27),\n",
    "                                                flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "            if len(eyes)!= 2:\n",
    "                return None\n",
    "            eye_mat=[]\n",
    "            for e in eyes:\n",
    "                xe,ye,we,he=e\n",
    "                eye_mat.append(face_mat[ye:ye+he,xe:xe+we])\n",
    "                cv2.rectangle(roi_color,(xe-3,ye-3),(xe+we+3,ye+he+3),(0,0,255),2)\n",
    "        return  (img,face_mat,eye_mat)\n",
    "def drawblock(img,line_num,block_id=0,blockcolor=(46,218,255),blockwideth=5,show_rec=True):\n",
    "        '''\n",
    "        选定九宫格，在这个格子上填充矩形表示选定这个格子\n",
    "        :param img_: 图片\n",
    "        :param block: 九宫格序号 0-15\n",
    "        :param blockcolor: 矩形框颜色\n",
    "        :param blockwideth: 框的宽度\n",
    "        :return:\n",
    "        '''\n",
    "        h,w=img.shape[0],img.shape[1]\n",
    "        w_line,h_line=line_num,line_num\n",
    "        h_,w_=h//h_line,w//w_line\n",
    "        cor_h=block_id//line_num\n",
    "        cor_w=block_id%line_num\n",
    "        sx,sy=cor_w*w_,cor_h*h_\n",
    "        \n",
    "        if show_rec:\n",
    "        #将整个矩形填充为其他颜色\n",
    "            img[sy:sy+h_,sx:sx+w_,:]=blockcolor\n",
    "        else:\n",
    "            roi_=img[sy:sy+h_,sx:sx+w_]\n",
    "            cv2.circle(roi_,(roi_.shape[1]//2,roi_.shape[0]//2), 10, (255,128,120), -1)\n",
    "       \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tar_img=cv2.imread('test.jpg')\n",
    "tar_img=drawline(tar_img,wandh_num=4)\n",
    "tar_img=drawblock(tar_img,line_num=4,block_id=6)\n",
    "cap=cv2.VideoCapture(0)\n",
    "_,frame=cap.read()\n",
    "cap.release()\n",
    "v_test=tar_img.copy()\n",
    "tar_img[:480,1280:]=frame\n",
    "cv2.namedWindow('Capture001',cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Capture001', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "cv2.imshow('Capture001',tar_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyWindow('Capture001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob=tf.nn.softmax(y_socre)\n",
    "guess=tf.arg_max(prob,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fps=10\n",
    "\n",
    "fsize_desk=(1920,1080)\n",
    "# save video\n",
    "video_d=cv2.VideoWriter('demo_desk.flv',cv2.VideoWriter_fourcc('F','L','V','1'),fps,fsize_desk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "s_time=time.time()\n",
    "tar_img=cv2.imread('test.jpg')\n",
    "#设置window 为全屏\n",
    "cv2.namedWindow('Capture001',cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Capture001', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "#每16帧输出一个最常见结果\n",
    "frame_counter=0\n",
    "ret_counter=0\n",
    "frame_counter_dict={}\n",
    "block_16id=0\n",
    "s_time=time.time()\n",
    "random_show=np.random.randint(0,16,1)[0]\n",
    "while True:\n",
    "    ret,fram=cap.read()\n",
    "    if ret:\n",
    "        ret_counter+=1\n",
    "        #显示 内窥镜图像\n",
    "        tar_img=cv2.imread('test.jpg')\n",
    "        tar_img=drawline(tar_img,wandh_num=4)\n",
    "        if ret_counter%18==0:\n",
    "            random_show=np.random.randint(0,16,1)[0]\n",
    "        tar_img=drawblock(tar_img,line_num=4,block_id=random_show)\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "       \n",
    "        #预测注视方向\n",
    "        face_op=drew_face_eye(fram)\n",
    "        if face_op == None:\n",
    "            continue\n",
    "        _,f,_=face_op\n",
    "        f=f.reshape((1,f.shape[0],f.shape[1],f.shape[2]))\n",
    "        fea_=sess.run(feature_bottleneck,{jpeg_tensor:f})\n",
    "       \n",
    "        guess_=sess.run(guess,feed_dict={X:fea_,TRAINGING:False})\n",
    "        if frame_counter==1:\n",
    "            frame_counter=0\n",
    "            max_count=0\n",
    "            for k in frame_counter_dict:\n",
    "                if frame_counter_dict[k]>max_count:\n",
    "                    block_16id=k\n",
    "                    max_count=frame_counter_dict[k]\n",
    "            frame_counter_dict={}\n",
    "        else:\n",
    "            frame_counter+=1\n",
    "            frame_counter_dict[guess_[0]]=frame_counter_dict.get(guess_[0],0)+1\n",
    "        \n",
    "        tar_img=drawblock(tar_img,line_num=4,block_id=block_16id,show_rec=False)\n",
    "        v_img=tar_img.copy()\n",
    "        v_img[:480,1280:]=fram\n",
    "        cv2.imshow('Capture001',tar_img)\n",
    "        #print(time.time()-s_time)\n",
    "        #s_time=time.time()\n",
    "        video_d.write(v_img)\n",
    "        if cv2.waitKey(30)&0xff==27:\n",
    "            print('out')\n",
    "            break\n",
    "    if (time.time()-s_time)>60*5:\n",
    "        print('time out')\n",
    "        break\n",
    "video_d.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
